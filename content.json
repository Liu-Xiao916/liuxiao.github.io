{"meta":{"title":"XiÃ oBlog","subtitle":"","description":"The homepage for Xiao","author":"LiuXiao","url":"https://liuxiao916.github.io","root":"/"},"pages":[{"title":"æ‰€æœ‰åˆ†ç±»","date":"2022-05-06T11:56:25.899Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"categories/index.html","permalink":"https://liuxiao916.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2022-05-06T11:56:25.899Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"404.html","permalink":"https://liuxiao916.github.io/404.html","excerpt":"","text":"404 å¾ˆæŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ å¯èƒ½æ˜¯è¾“å…¥åœ°å€æœ‰è¯¯æˆ–è¯¥åœ°å€å·²è¢«åˆ é™¤"},{"title":"","date":"2022-05-06T11:56:25.899Z","updated":"2022-05-06T11:56:25.899Z","comments":false,"path":"about/index.html","permalink":"https://liuxiao916.github.io/about/index.html","excerpt":"","text":"Resume Liu Xiao (åˆ˜ç¬‘) BriefI am a master student majored in Robotics at Harbin Institute of Technology Shenzhen, supervised by Prof. Haoyao Chen. Before this, I got my bacher degree with honor in Harbin Institute of Technology."},{"title":"","date":"2022-05-06T11:56:25.899Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"comments/index.html","permalink":"https://liuxiao916.github.io/comments/index.html","excerpt":"","text":"ğŸ“¬ç•™è¨€ç‰ˆ è¯„è®ºæ”¿ç­– è¯„è®ºè¯·è‡ªè§‰éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„ï¼Œå‹å–„å‘è¨€ã€‚ ç½‘å‹è¯„è®ºä»…ä»£è¡¨å…¶ä¸ªäººè§‚ç‚¹ï¼Œå¹¶ä¸è¡¨æ˜æœ¬ç«™åŒæ„å…¶è§‚ç‚¹æˆ–è¯å®å…¶æè¿°"},{"title":"æˆ‘çš„æœ‹å‹ä»¬","date":"2022-05-13T12:44:41.816Z","updated":"2022-05-13T12:44:41.816Z","comments":true,"path":"friends/index.html","permalink":"https://liuxiao916.github.io/friends/index.html","excerpt":"è¿™é‡Œæ˜¯ç¬‘çš„æœ‹å‹ä»¬çš„åšå®¢ï¼","text":"è¿™é‡Œæ˜¯ç¬‘çš„æœ‹å‹ä»¬çš„åšå®¢ï¼ å‹é“¾ç”³è¯·æ–¹å¼blueå‰å¾€githubæ–°å»ºissueï¼Œæˆ–è€…åœ¨è¯¥é¡µé¢è¯„è®ºåŒºç•™è¨€ã€‚ æäº¤ä¿¡æ¯ï¼šï¼ˆåç§°ï¼Œå¤´åƒï¼Œé“¾æ¥ï¼Œç½‘ç«™æˆªå›¾ï¼Œæè¿°ï¼‰ï¼Œå…¶ä¸­å›¾ç‰‡è¯·ä¸Šä¼ å›¾åºŠï¼Œæä¾›é“¾æ¥å³å¯ã€‚12345title: avatar:url: screenshot: description:"},{"title":"","date":"2022-05-06T11:56:25.903Z","updated":"2022-05-06T11:56:25.903Z","comments":true,"path":"interests/index.html","permalink":"https://liuxiao916.github.io/interests/index.html","excerpt":"","text":"ğŸ“–ç¬‘çš„ä¹¦å• å¼€å·æœ‰ç›Š ä½›ç½—é‡Œè¾¾ ğŸ¥ç¬‘çš„ç”µå½± å¼€å·æœ‰ç›Š ä½›ç½—é‡Œè¾¾ âš”ï¸ç¬‘çš„æ¸¸æˆ å¼€å·æœ‰ç›Š ä½›ç½—é‡Œè¾¾"},{"title":"","date":"2022-05-06T11:56:25.903Z","updated":"2022-05-06T11:56:25.903Z","comments":false,"path":"photos/index.html","permalink":"https://liuxiao916.github.io/photos/index.html","excerpt":"","text":"ğŸ“¸ç¬‘çš„ç›¸å†Œ è®°å½•ç”Ÿæ´»ä¸­çš„ç¾å¥½ ä½›ç½—é‡Œè¾¾"},{"title":"","date":"2022-05-06T11:56:25.903Z","updated":"2022-05-06T11:56:25.903Z","comments":true,"path":"photos/florida/index.html","permalink":"https://liuxiao916.github.io/photos/florida/index.html","excerpt":"","text":"ä½›ç½—é‡Œè¾¾ è®°å½•ç”Ÿæ´»ä¸­çš„ç¾å¥½"},{"title":"æ‰€æœ‰æ ‡ç­¾","date":"2022-05-06T11:56:25.903Z","updated":"2022-05-06T11:56:25.903Z","comments":true,"path":"tags/index.html","permalink":"https://liuxiao916.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-05-06T11:56:25.903Z","updated":"2022-05-06T11:56:25.903Z","comments":true,"path":"interests/florida/index.html","permalink":"https://liuxiao916.github.io/interests/florida/index.html","excerpt":"","text":"ä½›ç½—é‡Œè¾¾ è®°å½•ç”Ÿæ´»ä¸­çš„ç¾å¥½"}],"posts":[{"title":"LOå­¦ä¹ ç¬”è®°","slug":"Lidar Odometryå­¦ä¹ ç¬”è®°","date":"2022-06-26T02:52:38.000Z","updated":"2022-06-26T03:34:10.998Z","comments":true,"path":"2022/06/26/Lidar Odometryå­¦ä¹ ç¬”è®°/","link":"","permalink":"https://liuxiao916.github.io/2022/06/26/Lidar%20Odometry%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"å­¦ä¹ äº†ç»å…¸çš„ALOAMä»¥åŠLego-LOAMæºä»£ç ï¼Œè¿™é‡Œåšä¸€ä¸‹ç¬”è®°ã€‚","text":"å­¦ä¹ äº†ç»å…¸çš„ALOAMä»¥åŠLego-LOAMæºä»£ç ï¼Œè¿™é‡Œåšä¸€ä¸‹ç¬”è®°ã€‚ Lidar Odometryå­¦ä¹ ç¬”è®°è¯´æ˜ï¼š æœ¬æ–‡å‚è€ƒäº†è®¸å¤šåšå®¢ï¼Œå‚è€ƒé“¾æ¥åˆ†æ•£åœ¨æ–‡ä¸­ï¼Œä¸ä¸€ä¸€åˆ—ä¸¾ã€‚ å…¬å¼ä»¥åŠæ’ç‰ˆçš„æ¸²æŸ“æœ‰äº›é—®é¢˜ï¼Œæ—¥åå†™çš„æ—¶å€™æ³¨æ„ï¼Œè¿™ä¸€ç¯‡å¯èƒ½å°±ä¸å¤„ç†äº†ã€‚ LOAMä½œä¸ºæœ€ç»å…¸çš„Lidar Odometryç®—æ³•ï¼Œæ˜¯ä¸€å®šè¦å­¦ä¹ ä¸€ä¸‹çš„ã€‚ æ ¸å¿ƒæ˜¯ä¸‹é¢è¿™ä¸ªç¨‹åºæµç¨‹å›¾ Point Cloud RegistrationPoint Cloud Registrationä¸­ï¼Œç¨‹åºçš„ä¸»è¦å·¥ä½œæ˜¯ï¼š æ ¹æ®æ‰«æé¢‘ç‡ï¼Œå°†æ¯ä¸ªæ¿€å…‰ç‚¹çš„scanIDä¿¡æ¯ä¸è·ç¦»æ‰«æèµ·å§‹ç‚¹çš„æ—¶é—´ä¿¡æ¯å­˜å‚¨åˆ°intensityä¸­ã€‚ è®¡ç®—æ¯ä¸ªç‚¹çš„æ›²åº¦ï¼Œå¯»æ‰¾æå¤§è¾¹ç¼˜ç‚¹ï¼Œæ¬¡æå¤§è¾¹ç¼˜ç‚¹ï¼Œæå°å¹³é¢ç‚¹ï¼Œæ¬¡æå°å¹³é¢ç‚¹ã€‚ç„¶åå°†ä»–ä»¬ publishå‡ºå»ã€‚ 1234567891011121314// è®¡ç®—æ¯ä¸€ä¸ªç‚¹çš„æ›²ç‡ï¼Œè¿™é‡Œçš„laserCloudæ˜¯æœ‰åºçš„ç‚¹äº‘ï¼Œæ•…å¯ä»¥ç›´æ¥è¿™æ ·è®¡ç®—ï¼ˆè®ºæ–‡ä¸­è¯´å¯¹æ¯æ¡çº¿æ‰«scanè®¡ç®—æ›²ç‡ï¼‰// ä½†æ˜¯åœ¨æ¯æ¡scançš„äº¤ç•Œå¤„è®¡ç®—å¾—åˆ°çš„æ›²ç‡æ˜¯ä¸å‡†ç¡®çš„ï¼Œè¿™å¯é€šè¿‡scanStartInd[i]ã€scanEndInd[i]æ¥é€‰å–for (int i = 5; i &lt; cloudSize - 5; i++)&#123; float diffX = laserCloud-&gt;points[i - 5].x + laserCloud-&gt;points[i - 4].x + laserCloud-&gt;points[i - 3].x + laserCloud-&gt;points[i - 2].x + laserCloud-&gt;points[i - 1].x - 10 * laserCloud-&gt;points[i].x + laserCloud-&gt;points[i + 1].x + laserCloud-&gt;points[i + 2].x + laserCloud-&gt;points[i + 3].x + laserCloud-&gt;points[i + 4].x + laserCloud-&gt;points[i + 5].x; float diffY = laserCloud-&gt;points[i - 5].y + laserCloud-&gt;points[i - 4].y + laserCloud-&gt;points[i - 3].y + laserCloud-&gt;points[i - 2].y + laserCloud-&gt;points[i - 1].y - 10 * laserCloud-&gt;points[i].y + laserCloud-&gt;points[i + 1].y + laserCloud-&gt;points[i + 2].y + laserCloud-&gt;points[i + 3].y + laserCloud-&gt;points[i + 4].y + laserCloud-&gt;points[i + 5].y; float diffZ = laserCloud-&gt;points[i - 5].z + laserCloud-&gt;points[i - 4].z + laserCloud-&gt;points[i - 3].z + laserCloud-&gt;points[i - 2].z + laserCloud-&gt;points[i - 1].z - 10 * laserCloud-&gt;points[i].z + laserCloud-&gt;points[i + 1].z + laserCloud-&gt;points[i + 2].z + laserCloud-&gt;points[i + 3].z + laserCloud-&gt;points[i + 4].z + laserCloud-&gt;points[i + 5].z; // å¯¹åº”è®ºæ–‡ä¸­çš„å…¬å¼ï¼ˆ1ï¼‰ï¼Œä½†æ˜¯æ²¡æœ‰è¿›è¡Œé™¤æ³• cloudCurvature[i] = diffX * diffX + diffY * diffY + diffZ * diffZ; cloudSortInd[i] = i; cloudNeighborPicked[i] = 0; cloudLabel[i] = 0;&#125; Lidar Odometry ä½¿ç”¨Ceresè¿›è¡Œä¸¤æ¬¡ä¼˜åŒ–ï¼Œå…ˆæŠŠæ‰€æœ‰ç‚¹æŠ•å½±åˆ°å½“å‰å¸§åˆå§‹çš„æ—¶åˆ»ï¼Œä¹‹åå¯¹è¾¹ç¼˜ç‚¹ï¼ˆå¹³é¢ç‚¹ï¼‰æœç´¢ä¸Šä¸€å¸§æœ€è¿‘é‚»çš„è¾¹æˆ–è€…é¢ï¼Œceres::CostFunctionå°±æ˜¯ä¸¤è€…è·ç¦»ï¼Œä¼˜åŒ–ä½å§¿ã€‚ä»£ä»·å‡½æ•°å®šä¹‰åœ¨lidarFactor.cppä¸­ æœ€åå°†å½“å‰å¸§æŠ•å½±åˆ°å½“å‰å¸§ç»“æŸçš„æ—¶åˆ»ï¼Œå°†å…¶ä¸­çš„è¾¹ç¼˜ä»¥åŠå¹³é¢å­˜å‚¨èµ·æ¥ä¸‹æ¬¡ç”¨ã€‚ Lidar Mapping LOç¨‹åºå‘å¸ƒçš„æ˜¯å½“å‰å¸§åœ¨Odomåæ ‡ç³»ä¸‹çš„ä½å§¿T_wodom_currï¼Œæˆ‘ä»¬è¿˜è§„å®šäº†ä¸€ä¸ªOdomåˆ°Mapä¹‹é—´çš„å˜æ¢å…³ç³»T_wmap_wodomï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å¾—åˆ°å½“å‰å¸§åœ¨Mapä¹‹ä¸‹çš„ä½å§¿T_w_curr = T_wmap_wodom * T_wodom_currã€‚è™½ç„¶æˆ‘ä»¬çœ‹èµ·æ¥ä¼˜åŒ–çš„æ˜¯T_w_currï¼Œå®é™…ä¸Šçš„é€»è¾‘æ˜¯ï¼æˆ‘ä»¬é€šè¿‡Cereså¾—åˆ°å½“å‰çš„T_w_currï¼Œä¹‹åè®¡ç®—å¾—åˆ°T_wmap_wodomï¼Œæˆ‘ä»¬å®é™…ä¸Šå®åœ¨ä¼˜åŒ–Odomåæ ‡ç³»ä¸Mapåæ ‡ç³»ä¹‹é—´çš„è½¬æ¢å…³ç³»T_wmap_wodomã€‚è¿™æ ·ä¸‹ä¸€å¸§çš„ä½å§¿T_wodom_curræ¥çš„æ—¶å€™ï¼Œåªéœ€è¦ç®€å•çš„å˜æ¢å°±å¯ä»¥å¾—åˆ°T_w_currã€‚ æ³¨æ„åœ¨Aloamç¨‹åºä¸­çš„åœ°å›¾æ˜¯åªä¿å­˜4851ä¸ªCubeçš„ï¼Œå¦‚æœæˆ‘ä»¬çš„ä½å§¿è¿‡äºé è¿‘åœ°å›¾çš„æŸä¸€è¾¹ï¼Œåœ°å›¾ä¼šå‘è¯¥æ–¹å‘ç§»åŠ¨ã€‚ 123456const int laserCloudWidth = 21; const int laserCloudHeight = 21;const int laserCloudDepth = 11;// the num of cubeconst int laserCloudNum = laserCloudWidth * laserCloudHeight * laserCloudDepth; //4851 æˆ‘ä»¬ä¼šåœ¨å½“å‰ä½å§¿çš„é™„è¿‘å–å‡ºä¸€ä¸ªsubmapï¼Œå³åœ¨å½“å‰çš„cubeå¾€å„ä¸ªæ–¹å‘å„æ‰©å±•ä¸¤ä¸ªcubeï¼Œæœ€ç»ˆèƒ½å–å‡ºæ¥125ä¸ªcubeã€‚ç„¶åæˆ‘ä»¬ä¼šå°†submapä¸­çš„è¾¹ç¼˜ç‚¹ä»¥åŠå¹³é¢ç‚¹æå–å‡ºæ¥ã€‚ è¾“å…¥çš„è¾¹ç¼˜ç‚¹å’Œå¹³é¢ç‚¹è¿›è¡Œé™é‡‡æ ·ã€‚ä¹‹åä¾ç„¶æ˜¯æ„é€ å…¶åˆ°submapä¸­å¯¹åº”çš„ç›´çº¿ä»¥åŠå¹³é¢çš„è·ç¦»çš„Costfunctionï¼Œä½¿ç”¨Ceresä¼˜åŒ–ä¸¤æ¬¡ã€‚è¿™é‡Œæœ‰ä¸€äº›ç»†å¾®çš„ä¸åŒï¼Œæ¯”å¦‚å¯»æ‰¾å¯¹åº”ç›´çº¿çš„æ—¶å€™è¦æ‰¾åˆ°å¯¹åº”çš„äº”ä¸ªç‚¹ï¼Œç„¶åé€šè¿‡åæ–¹å·®çŸ©é˜µåˆ¤æ–­ä»–å¤Ÿä¸å¤Ÿç›´ã€‚è®¡ç®—åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œç”¨äºåˆ¤æ–­è¿™5ä¸ªç‚¹æ˜¯ä¸æ˜¯å‘ˆçº¿çŠ¶åˆ†å¸ƒï¼Œæ­¤ä¸ºPCAçš„åŸç†ï¼Œå¦‚æœ5ä¸ªç‚¹å‘ˆçº¿çŠ¶åˆ†å¸ƒï¼Œæœ€å¤§çš„ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡å°±æ˜¯è¯¥çº¿çš„æ–¹å‘çŸ¢é‡ã€‚å¹³é¢çš„è¯åˆ™æ˜¯æ‹Ÿåˆå¹³é¢ï¼Œç„¶åè®¡ç®—ç‚¹åˆ°é¢çš„è·ç¦»ã€‚ ä¼˜åŒ–å®Œä¹‹åï¼Œå°†å½“å‰å¸§çš„è¾¹ç¼˜ç‚¹ä»¥åŠå¹³é¢ç‚¹åŠ å…¥cubeä¸­ï¼Œå³åŠ å…¥åˆ°åœ°å›¾ä¸­ã€‚ä¹‹åä¼šä»¥ä¸åŒé¢‘ç‡å‘å¸ƒå®Œæ•´çš„åœ°å›¾ä»¥åŠsubmapã€‚ è¯¥èŠ‚ç‚¹ä¼šå‘å¸ƒä¸¤ä¸ªä½å§¿ï¼Œ/aft_mapped_to_init_high_frecæ˜¯åœ¨æ¯æ¬¡æ¥æ”¶åˆ°æ–°çš„ä½å§¿åï¼Œç»“åˆå½“å‰çš„T_wmap_wodomï¼Œè¿›è¡Œä¸€ä¸ªOdomåˆ°Mapåæ ‡ç³»çš„å˜æ¢åå°±pubï¼Œå…¶é¢‘ç‡æ˜¯å’ŒLOç›¸åŒçš„ã€‚è€Œ/aft_mapped_to_initæ˜¯åœ¨æ¯æ¬¡ä¼˜åŒ–å®Œå¾—åˆ°æ–°çš„T_w_curråå†å‘é€,é¢‘ç‡è¾ƒä½. Lego-LOAM Segmentationè¿™ä¸ªèŠ‚ç‚¹ä¸»è¦å®Œæˆäº†ä¸¤ä¸ªå·¥ä½œ å°†ç‚¹äº‘å±•å¼€åˆ°2ç»´å›¾åƒä¸Šï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ ä»£è¡¨æ·±åº¦ã€‚ å¯¹ç‚¹äº‘è¿›è¡Œåˆ†å‰² é¦–å…ˆæ‰¾åˆ°æ‰€æœ‰çš„åœ°é¢ç‚¹ï¼Œé€šè¿‡å¯¹ä¸Šä¸‹ä¸¤çº¿ç›¸é‚»ç‚¹ä¹‹é—´ä¿¯ä»°è§’çš„è®¡ç®—ï¼Œå¦‚æœå°äºä¸€å®šé˜ˆå€¼å°±æ˜¯å¹³é¢ç‚¹ã€‚ ä½¿ç”¨BFSå¯¹å…¶ä»–ç‚¹äº‘è¿›è¡Œèšç±»ï¼Œå¦‚æœå¤§äº30ç‚¹åˆ™è®¤ä¸ºå¯ä»¥æ˜¯ä¸€ç±»ã€‚å¦‚æœèšç±»ç‚¹æ•°å°äº30å¤§äºç­‰äº5ï¼Œæ­¤æ—¶å¦‚æœç«–ç›´æ–¹å‘è¶…è¿‡3æ¡çº¿ï¼ˆæ¯”å¦‚16çº¿é›·è¾¾ï¼Œè¿™ä¸ªèšç±»å äº†ä¸‰æ¡çº¿ï¼‰ä¹Ÿè®¤ä¸ºæ˜¯æœ‰æ•ˆèšç±»ã€‚ èšç±»æ•°ç›®ä¸å¤Ÿ30ï¼Œä½†æ˜¯è¡Œæ•°è¾ƒå¤§ï¼Œå¯ä»¥è®¤ä¸ºéåœ°é¢ç‚¹çš„ï¼Œä¿å­˜åˆ°å¼‚å¸¸ç‚¹äº‘ï¼ˆç•Œå¤–ç‚¹äº‘ï¼‰ï¼ˆoutlierï¼‰ã€‚ å‘å¸ƒï¼š /full_cloud_projectedï¼šå°±æ˜¯è¢«æŠ•å½±çš„ç‚¹äº‘ï¼Œå…¶indexæŒ‰ç…§æŠ•å½±çš„åæ ‡æ’åˆ—ã€‚æ¯ä¸ªç‚¹çš„xyzæ˜¯åŸå§‹ç‚¹äº‘çš„xyzï¼Œintensityå€¼æ˜¯(float)rowIdn + (float)columnIdn / 10000.0å¾—åˆ°çš„ï¼Œå«æœ‰åæ ‡ä¿¡æ¯ã€‚ /full_cloud_infoï¼šå…¶indexæŒ‰ç…§æŠ•å½±çš„åæ ‡æ’åˆ—ï¼Œæ¯ä¸ªç‚¹intensityéƒ¨åˆ†æ˜¯æ¯ä¸ªç‚¹çš„æ·±åº¦ã€‚ /ground_cloudï¼šæ‰€æœ‰åœ°é¢ç‚¹çš„ç‚¹äº‘ /segmented_cloudï¼šæ‰€æœ‰åˆ†å‰²å‡ºæ¥çš„ç‚¹äº‘ä»¥åŠåˆ—æ•°ä¸ºç¬¬äº”åˆ—çš„åœ°é¢ç‚¹ /segmented_cloud_pureï¼šä¸æ˜¯åœ°é¢ç‚¹ä»¥åŠæ²¡æœ‰è¢«èˆå¼ƒçš„èšç±»ä¸­çš„ç‚¹ã€‚ /segmented_cloud_infoï¼šcloud_infoä¸­çš„ä¿¡æ¯ï¼ŒåŒ…å«ç‚¹äº‘èµ·å§‹è§’åº¦ï¼Œç»“æŸè§’åº¦ï¼Œè§’åº¦å·®ã€‚ç¬¬içº¿çš„ç‚¹äº‘èµ·å§‹åºåˆ—å’Œç»ˆæ­¢åºåˆ—ã€‚åˆ†å‰²ç‚¹ä¸­å…¶æ˜¯å¦æ˜¯åœ°é¢ç‚¹ï¼Œåˆ—çš„indexä»¥åŠæ·±åº¦ã€‚ /outlier_cloudï¼šä¸Šæ–‡æ‰€è¯´çš„å¼‚å¸¸ç‚¹äº‘ Feature AssociationIMUæ•°æ®å¤„ç†è¿™é‡Œå…ˆè®°å½•ä¸€ä¸‹IMUæ•°æ®çš„å¤„ç†ã€‚é¦–å…ˆIMUæ¥æ”¶å›æ¥çš„åŠ é€Ÿåº¦æ•°æ®æ˜¯ç›¸å¯¹äºIMUåæ ‡ç³»è€Œè¨€çš„ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»ã€‚IMUæ¥å—åˆ°çš„orientationæ•°æ®æ˜¯åœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹æ—‹è½¬çš„è§’åº¦ã€‚ è§£å¾—éšåæˆ‘ä»¬åœ¨IMUåæ ‡ç³»ä¸­æ¶ˆå»$g_i$çš„å½±å“ã€‚å¹¶å®Œæˆäº†ä¸€ä¸ªåæ ‡å˜æ¢(y-&gt;x;z-&gt;y;x-&gt;z)ï¼Œç»Ÿä¸€åˆ°zè½´å‘å‰ï¼Œxè½´å‘å·¦çš„å³æ‰‹åæ ‡ç³»ã€‚äº¤æ¢å $R_{IW} &#x3D; Ry(yaw)*Rx(pitch)*Rz(roll)$ã€‚ 12345678910111213141516171819202122232425262728293031void imuHandler(const sensor_msgs::Imu::ConstPtr&amp; imuIn) &#123; double roll, pitch, yaw; tf::Quaternion orientation; tf::quaternionMsgToTF(imuIn-&gt;orientation, orientation); tf::Matrix3x3(orientation).getRPY(roll, pitch, yaw); // åŠ é€Ÿåº¦å»é™¤é‡åŠ›å½±å“ï¼ŒåŒæ—¶åæ ‡è½´è¿›è¡Œå˜æ¢ float accX = imuIn-&gt;linear_acceleration.y - sin(roll) * cos(pitch) * 9.81; float accY = imuIn-&gt;linear_acceleration.z - cos(roll) * cos(pitch) * 9.81; float accZ = imuIn-&gt;linear_acceleration.x + sin(pitch) * 9.81; imuPointerLast = (imuPointerLast + 1) % imuQueLength; imuTime[imuPointerLast] = imuIn-&gt;header.stamp.toSec(); imuRoll[imuPointerLast] = roll; imuPitch[imuPointerLast] = pitch; imuYaw[imuPointerLast] = yaw; imuAccX[imuPointerLast] = accX; imuAccY[imuPointerLast] = accY; imuAccZ[imuPointerLast] = accZ; imuAngularVeloX[imuPointerLast] = imuIn-&gt;angular_velocity.x; imuAngularVeloY[imuPointerLast] = imuIn-&gt;angular_velocity.y; imuAngularVeloZ[imuPointerLast] = imuIn-&gt;angular_velocity.z; AccumulateIMUShiftAndRotation(); &#125; ä¹‹åæˆ‘ä»¬éœ€è¦å°†å…¶ä¸­çš„ä¿¡æ¯ï¼ˆä½ç§»ï¼Œé€Ÿåº¦ï¼Œè§’åº¦ï¼‰è½¬åˆ°ä¸–ç•Œåæ ‡ç³»ä¸­ã€‚$X_w&#x3D;R_yR_xR_z*X_{IMU}$ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void AccumulateIMUShiftAndRotation() &#123; float roll = imuRoll[imuPointerLast]; float pitch = imuPitch[imuPointerLast]; float yaw = imuYaw[imuPointerLast]; float accX = imuAccX[imuPointerLast]; float accY = imuAccY[imuPointerLast]; float accZ = imuAccZ[imuPointerLast]; // å…ˆç»•Zè½´(åŸxè½´)æ—‹è½¬,ä¸‹æ–¹åæ ‡ç³»ç¤ºæ„imuHandler()ä¸­åŠ é€Ÿåº¦çš„åæ ‡è½´äº¤æ¢ // z-&gt;Y // ^ // | ^ y-&gt;X // | / // | / // | / // -----&gt; x-&gt;Z // // |cosrz -sinrz 0| // Rz=|sinrz cosrz 0| // |0 0 1| // [x1,y1,z1]^T=Rz*[accX,accY,accZ] // å› ä¸ºåœ¨imuHandlerä¸­è¿›è¡Œè¿‡åæ ‡å˜æ¢ï¼Œ // æ‰€ä»¥ä¸‹é¢çš„rollå…¶å®å·²ç»å¯¹åº”äºæ–°åæ ‡ç³»ä¸­(X-Y-Z)çš„yaw float x1 = cos(roll) * accX - sin(roll) * accY; float y1 = sin(roll) * accX + cos(roll) * accY; float z1 = accZ; // ç»•Xè½´(åŸyè½´)æ—‹è½¬ // [x2,y2,z2]^T=Rx*[x1,y1,z1] // |1 0 0| // Rx=|0 cosrx -sinrx| // |0 sinrx cosrx| float x2 = x1; float y2 = cos(pitch) * y1 - sin(pitch) * z1; float z2 = sin(pitch) * y1 + cos(pitch) * z1; // æœ€åå†ç»•Yè½´(åŸzè½´)æ—‹è½¬ // |cosry 0 sinry| // Ry=|0 1 0| // |-sinry 0 cosry| accX = cos(yaw) * x2 + sin(yaw) * z2; accY = y2; accZ = -sin(yaw) * x2 + cos(yaw) * z2; // è¿›è¡Œä½ç§»ï¼Œé€Ÿåº¦ï¼Œè§’åº¦é‡çš„ç´¯åŠ  int imuPointerBack = (imuPointerLast + imuQueLength - 1) % imuQueLength; double timeDiff = imuTime[imuPointerLast] - imuTime[imuPointerBack]; if (timeDiff &lt; scanPeriod) &#123; imuShiftX[imuPointerLast] = imuShiftX[imuPointerBack] + imuVeloX[imuPointerBack] * timeDiff + accX * timeDiff * timeDiff / 2; imuShiftY[imuPointerLast] = imuShiftY[imuPointerBack] + imuVeloY[imuPointerBack] * timeDiff + accY * timeDiff * timeDiff / 2; imuShiftZ[imuPointerLast] = imuShiftZ[imuPointerBack] + imuVeloZ[imuPointerBack] * timeDiff + accZ * timeDiff * timeDiff / 2; imuVeloX[imuPointerLast] = imuVeloX[imuPointerBack] + accX * timeDiff; imuVeloY[imuPointerLast] = imuVeloY[imuPointerBack] + accY * timeDiff; imuVeloZ[imuPointerLast] = imuVeloZ[imuPointerBack] + accZ * timeDiff; imuAngularRotationX[imuPointerLast] = imuAngularRotationX[imuPointerBack] + imuAngularVeloX[imuPointerBack] * timeDiff; imuAngularRotationY[imuPointerLast] = imuAngularRotationY[imuPointerBack] + imuAngularVeloY[imuPointerBack] * timeDiff; imuAngularRotationZ[imuPointerLast] = imuAngularRotationZ[imuPointerBack] + imuAngularVeloZ[imuPointerBack] * timeDiff; &#125; &#125; runFeatureAssociation (Pipeline) åˆ¤æ–­æ¥æ”¶æ•°æ®çš„æ—¶é—´æˆ³æ˜¯å¦åŒæ­¥ï¼› å»é™¤ç‚¹äº‘ç•¸å˜ã€‚å°†ç‚¹äº‘æ•°æ®è¿›è¡Œåæ ‡å˜æ¢ï¼Œè¿›è¡Œæ’è¡¥ç­‰å·¥ä½œï¼› void adjustDistortion()ï¼šæ ¹æ®IMUçš„ä¿¡æ¯å®Œæˆäº†ä¸¤ä¸ªä»»åŠ¡ï¼Œé¦–å…ˆæ˜¯å°†å½“å‰æ—¶åˆ»ä¸–ç•Œåæ ‡ç³»ä¸‹çš„IMUé€Ÿåº¦æŠ•å½±åˆ°å½“å‰å¸§ç¬¬ä¸€ä¸ªæ—¶åˆ»çš„IMUçš„åæ ‡ç³»ä¸‹ï¼Œå…¶æ¬¡æ˜¯å°†è¯¥å¸§ç‚¹äº‘æ¯ä¸ªç‚¹æŠ•å½±åˆ°ç¬¬ä¸€ä¸ªç‚¹æ‰€åœ¨æ—¶åˆ»çš„IMUåæ ‡ä¸‹ï¼Œè¿™æ˜¯å»é™¤è¿åŠ¨ç•¸å˜ å…‰æ»‘åº¦è®¡ç®—ï¼› æ ‡è®°ä¸å¯é ç‚¹ï¼› å¤„ç†ä¸¤ç§ç‚¹ï¼Œ1.èˆå»å¤„åœ¨æ·±åº¦è·³è·ƒè¾¹ç¼˜çš„ç‚¹ã€‚2.èˆå»ä¸¤ä¸ªç‚¹ä¹‹é—´çªç„¶æœ‰è¾ƒå¤§æ·±åº¦å˜åŒ–çš„ç‚¹ ç‰¹å¾æŠ½å–ï¼Œç„¶ååˆ†åˆ«ä¿å­˜åˆ°cornerPointsSharpç­‰é˜Ÿåˆ—ä¸­å»ï¼› è¿™ä¸ªå°±æ˜¯æ ¹æ®ç‚¹çš„å¹³æ»‘åº¦ï¼Œç„¶åå°†è§’ç‚¹åˆ†ä¸ºcornerPointsSharpã€cornerPointsLessSharpã€surfPointsFlatã€surfPointsLessFlatã€‚æ³¨æ„å¹³é¢ç‚¹åªä»åœ°é¢ç‚¹ä¸­é€‰å–ã€‚ å‘å¸ƒcornerPointsSharpç­‰4ç§ç±»å‹çš„ç‚¹äº‘æ•°æ®ï¼› /laser_cloud_sharpï¼šå…‰æ»‘åº¦æœ€å°çš„ä¸¤ä¸ªè¾¹ç¼˜ç‚¹ /laser_cloud_less_sharpï¼šè¾¹ç¼˜ç‚¹ /laser_cloud_flatï¼šå››ä¸ªæœ€å¹³çš„å¹³é¢ç‚¹ /laser_cloud_less_flatï¼šå¹³é¢ç‚¹ é¢„æµ‹ä½å§¿ï¼› æ›´æ–°å˜æ¢ï¼›https://blog.csdn.net/weixin_44156680/article/details/118302975è¿™ä¸€æ­¥æœ‰äº›å›°éš¾ï¼Œå¯ä»¥åˆ†æˆä¸¤éƒ¨åˆ†æ¥çœ‹ã€‚ å…ˆå®Œæˆå¹³é¢ç‰¹å¾ç‚¹çš„åŒ¹é…ï¼Œè®¡ç®—æ¯ä¸ªå¹³é¢ç‚¹ä¸å¯¹åº”å¹³é¢ä¹‹é—´çš„è·ç¦»è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯TransformToStartè¿™ä¸ªå‡½æ•°ã€‚è¿™æ˜¯åˆ©ç”¨åŒ€é€Ÿæ¨¡å‹ä¿®æ­£å½“å‰ç‚¹äº‘ã€‚transformCuræ˜¯ä¸Šä¸€æ—¶åˆ»ä¸å½“å‰æ—¶åˆ»çš„è§’åº¦ä»¥åŠè·ç¦» 123456789101112131415161718192021222324tripod1 = laserCloudSurfLast-&gt;points[pointSearchSurfInd1[i]];tripod2 = laserCloudSurfLast-&gt;points[pointSearchSurfInd2[i]];tripod3 = laserCloudSurfLast-&gt;points[pointSearchSurfInd3[i]];float pa = (tripod2.y - tripod1.y) * (tripod3.z - tripod1.z)- (tripod3.y - tripod1.y) * (tripod2.z - tripod1.z);float pb = (tripod2.z - tripod1.z) * (tripod3.x - tripod1.x)- (tripod3.z - tripod1.z) * (tripod2.x - tripod1.x);float pc = (tripod2.x - tripod1.x) * (tripod3.y - tripod1.y)- (tripod3.x - tripod1.x) * (tripod2.y - tripod1.y);float pd = -(pa * tripod1.x + pb * tripod1.y + pc * tripod1.z);float ps = sqrt(pa * pa + pb * pb + pc * pc);pa /= ps;pb /= ps;pc /= ps;pd /= ps;// è·ç¦»æ²¡æœ‰å–ç»å¯¹å€¼// ä¸¤ä¸ªå‘é‡çš„ç‚¹ä¹˜ï¼Œåˆ†æ¯é™¤ä»¥psä¸­å·²ç»é™¤æ‰äº†ï¼Œ// åŠ pdåŸå› :pointSelä¸tripod1æ„æˆçš„çº¿æ®µéœ€è¦ç›¸å‡float pd2 = pa * pointSel.x + pb * pointSel.y + pc * pointSel.z + pd; è¿™å°±æ˜¯ä¸Šé¢é‚£ä¸ªå…¬å¼å¯¹åº”çš„ä»£ç ï¼Œå…¶ä¸­paï¼Œpbï¼Œpcå°±æ˜¯ä¸¤ç›¸é‡å‰ä¹˜å‡ºæ¥çš„iï¼Œjï¼Œkåæ ‡ç³»ä¸‹çš„åˆ†é‡ï¼Œé™¤pså°±æ˜¯é™¤å»åˆ†æ¯ã€‚åˆ†å­è¢«æ‹†æˆäº†ä¸¤é¡¹ï¼Œå‰é¡¹æ˜¯pa * pointSel.x + pb * pointSel.y + pc * pointSel.zï¼Œåé¢ä¸€å‘å°±æ˜¯å‡å»çš„pdã€‚æœ€ç»ˆå¾—åˆ°è·ç¦»pd2ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯æ··åˆç§¯ä»£è¡¨ä½“ç§¯ï¼Œå‰ä¹˜ä»£è¡¨é¢ç§¯ï¼Œä¸¤ä¸ªä¸€é™¤å°±æ˜¯ç‚¹åˆ°é¢çš„è·ç¦»ã€‚ å®Œæˆè¾¹ç¼˜ç‰¹å¾ç‚¹çš„åŒ¹é…ï¼Œè®¡ç®—æ¯ä¸ªè¾¹ç¼˜ç‰¹å¾ç‚¹ä¸å¯¹åº”è¾¹ç¼˜ä¹‹é—´çš„è·ç¦» æ¥ä¸‹æ¥å’Œè®ºæ–‡ä¸­ä¸€æ ·ï¼Œå¹³é¢ç‚¹åªæ±‚è§£zæ–¹å‘çš„å¹³ç§»ä»¥åŠpicthå’Œrollè§’åº¦ï¼Œè¾¹ç¼˜ç‚¹æ±‚è§£xã€yæ–¹å‘çš„å¹³ç§»ä»¥åŠyawè§’åº¦ã€‚https://blog.csdn.net/qq_35102059/article/details/123671942æ±‚è§£çš„æ–¹å¼æ˜¯è½¬æ¢ä¸ºä¸€ä¸ªæœ€å°äºŒä¹˜çš„ä¼˜åŒ–é—®é¢˜ï¼Œä½¿ç”¨LMæ³•è¿›è¡Œè¿­ä»£æ±‚è§£ã€‚(lossä¸ºç‰¹å¾ç‚¹è®¡ç®—å‡ºçš„è·ç¦»ï¼Œä»£ç ä¸­ç”¨BçŸ©é˜µè¡¨ç¤º)ä»£ç é‡Œé¢å®é™…ä¸Šæ˜¯é«˜æ–¯ç‰›é¡¿æ³•ï¼Œä¸æ˜¯LMï¼ é›…å¯æ¯”çŸ©é˜µ(ä»£ç ä¸­ç”¨AçŸ©é˜µè¡¨ç¤º)ä¸ºï¼šé›…ç§‘æ¯”çŸ©é˜µå®é™…ä¸Šæ˜¯è·ç¦»(ä¸¤å¸§ä¹‹é—´çš„è·ç¦»ï¼Œç‚¹åˆ°é¢æˆ–è€…ç‚¹åˆ°çº¿)å¯¹ä½å§¿(6DOF)çš„æ±‚å¯¼ $\\frac{\\partial{F}}{\\partial{\\tilde{X}_{k+1}}}$ ï¼šè‹¥æ˜¯çº¿ç‰¹å¾åˆ™ä¸ºç‚¹åˆ°ç›´çº¿æ–¹å‘çš„å•ä½å‘é‡ï¼Œè‹¥æ˜¯çº¿ç‰¹å¾åˆ™ä¸ºç‚¹åˆ°å¹³é¢æ–¹å‘çš„å•ä½å‘é‡ã€‚ $\\frac{\\partial{\\tilde{X}{k+1}}}{\\partial{T{k+1}}}$ ï¼šå¯åˆ†åˆ«å¯¹å¹³ç§»å’Œæ—‹è½¬æ±‚å¯¼ã€‚ å¯¹äºé€€åŒ–é—®é¢˜çš„åˆ†æï¼šhttps://blog.csdn.net/weixin_44156680/article/details/117999067 ç§¯åˆ†æ€»å˜æ¢ï¼› å…³äºAccumulateRotationä»¥åŠPluginIMURotationä½œç”¨ï¼šåšå®¢ è¿™éƒ¨åˆ†ä¸»è¦ä½œç”¨å°±æ˜¯å°†ä¸¤å¸§ä¹‹é—´çš„å˜æ¢ç´¯è®¡èµ·æ¥ï¼Œè®¡ç®—å‡ºå½“å‰å¸§åˆ°èµ·å§‹ç‚¹çš„å˜æ¢ã€‚è¿™é‡Œæœ‰ä¸ªç»†èŠ‚ï¼Œä½ ä¼šè§‰å¾—å¾ˆå¤šç¬¦å·å†™åäº†ï¼Œæ¯”å¦‚transformSum + (-transformCur) =(rx,ry,rz)ï¼Œå®é™…ä¸Šå°±æ˜¯è¿™æ ·çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ±‚è§£çš„transformCuræ˜¯ç‚¹äº‘ä¹‹é—´çš„å˜æ¢ï¼Œæ­£å¥½ä¸è½½å…·çš„å˜æ¢ç›¸åçš„ï¼Œè¿™ç‚¹ä¹‹å‰æˆ‘ä»¬æœ‰æ¨ç†è¿‡ã€‚æ³¨æ„è¿™é‡Œä¸€äº›å˜é‡çš„æƒ…å†µï¼Œ transformSum[]æ˜¯ä»ä¸€å¼€å§‹åˆ°ç°åœ¨çš„ä½å§¿ transformCur[]æ˜¯ä¸¤å¸§ä¹‹é—´çš„ä½å§¿ imuPitchStartè¿™å¸§å¼€å§‹æ—¶åˆ»çš„pitchè§’ imuPitchLastè¿™å¸§ç»“æŸæ—¶åˆ»çš„pitchè§’åº¦ã€‚ PluginIMURotation()å°±æ˜¯åˆ©ç”¨imuä¿®æ­£æ—‹è½¬è§’åº¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ±‚å‡ºæ¥çš„æ—‹è½¬è§’åº¦æ˜¯å½“å‰æ—¶åˆ»çš„ç¬¬ä¸€ä¸ªæ‰«æç‚¹çš„æ—¶åˆ»ä¸ä¸Šä¸€å¸§æœ€åä¸€ä¸ªç‚¹çš„æ—¶åˆ»çš„å˜æ¢è§’åº¦ã€‚ä½†æ˜¯å½“å‰æ—¶åˆ»æˆ‘ä»¬éœ€è¦è€ƒè™‘æˆ‘ä»¬æ‰«æçš„æ—¶é—´ï¼Œä¹Ÿå°±æ˜¯å½“å‰æ—¶åˆ»æœ€åä¸€ä¸ªæ‰«æç‚¹ä¸ç¬¬ä¸€ä¸ªæ‰«æç‚¹ä¹‹é—´çš„å˜æ¢ã€‚é€šè¿‡$\\left(R_{\\text {cur }}^{\\text {start }}\\right)^{\\prime}&#x3D;R_{\\text {end }} R_{\\text {start }}^{-1} R_{\\text {cur }}^{\\text {start }}$å³å¯å¾—åˆ°ã€‚ imuShiftFromStartXæ˜¯ç‚¹äº‘æœ€åä¸€ä¸ªç‚¹ç›¸å¯¹äºç¬¬ä¸€ä¸ªç‚¹ç”±äºåŠ å‡é€Ÿäº§ç”Ÿçš„ç•¸å˜ä½ç§» å‘å¸ƒé‡Œç¨‹è®¡ä¿¡æ¯åŠç‚¹äº‘ä¿¡æ¯ï¼› å‘å¸ƒï¼š /laser_cloud_surf_lastï¼šå˜æ¢åˆ°IMUæœ«ç«¯æ—¶åˆ»çš„å¹³é¢ç‚¹ /laser_cloud_corner_lastï¼šå˜æ¢åˆ°IMUæœ«ç«¯æ—¶åˆ»çš„è¾¹ç¼˜ç‚¹ /outlier_cloudï¼šä¸Šæ–‡æ‰€è¯´çš„å¼‚å¸¸ç‚¹äº‘ /laser_odom_to_initï¼šä»åˆå§‹åˆ°ç°åœ¨çš„odomä¿¡æ¯ Map Optimizationç‰¹åˆ«å¥½çš„å‚è€ƒåšå®¢ run()ä¸»ä½“æµç¨‹ transformAssociateToMap()ï¼šæ ¹æ®æˆ‘ä¸ªäººçš„ç†è§£ä»¥åŠä¸€äº›èµ„æ–™ï¼Œè¿™é‡Œçš„ä½œç”¨ä¸»è¦å®åœ¨ä¼˜åŒ–ä¹‹å‰ï¼Œå°†åæ ‡ä»odomåæ ‡ç³»è½¬åˆ°mapåæ ‡ç³»ä¸­ï¼Œå…·ä½“çš„æ“ä½œæ˜¯è¿™æ ·çš„ã€‚å…ˆä»‹ç»ä¸€ä¸‹å‡ ä¸ªä¸»è¦çš„å˜é‡ã€‚ transformSum[]æ˜¯å½“å‰æ—¶åˆ»Odometryæ¨¡å—è®¡ç®—å‡ºæ¥çš„åœ¨odomåæ ‡ç³»ä¸‹çš„çŸ©é˜µ transformBefMapped[]æ˜¯ä¸Šä¸€æ¬¡mappingä¹‹å‰çš„Odometryè®¡ç®—çš„ä¸–ç•Œåæ ‡ç³»ä¸‹çš„è½¬æ¢çŸ©é˜µï¼Œå³ä¸Šä¸€æ¬¡mappingæ—¶çš„transformSum[]ã€‚ transformAftMapped[]æ˜¯ä¸Šä¸€æ¬¡mappingå¾®è°ƒä¹‹åçš„è½¬æ¢çŸ©é˜µï¼Œåœ¨mapåæ ‡ç³»ä¸‹ã€‚ æˆ‘ä»¬ä½¿ç”¨$T_{cur}*T_{before}^{-1}$å¯ä»¥å¾—åˆ°ä¸Šä¸€æ¬¡mappingåï¼Œåœ¨odomåæ ‡ç³»ä¸‹è½¦çš„ä½å§¿å˜æ¢$T_{change}$ï¼Œä¹‹åé€šè¿‡$T_{tobe} &#x3D; T_{change}*T_{after}$ æ³¨æ„odomåæ ‡ç³»åˆ°mapåæ ‡ç³»ä¹‹é—´å­˜åœ¨çš„ä¿®æ­£å…³ç³»$T_{fix}$ï¼Œå³$T_{after}&#x3D;T_{before}*T_{fix}$ extractSurroundingKeyFrames()ï¼š cloudKeyPoses3Dä¸­ä¿å­˜çš„æ˜¯å…³é”®å¸§çš„xyzåæ ‡ï¼Œå¾ˆèªæ˜çš„ä½¿ç”¨ç‚¹äº‘çš„å½¢å¼ä¿æŒxyzï¼Œæ–¹ä¾¿æœç´¢ä»¥åŠé™é‡‡æ ·ã€‚ è¿™ä¸ªå‡½æ•°æ˜¯æ¥æ„é€ å½“å‰å¸§å¯¹åº”çš„ç”±å…³é”®å¸§æ„æˆçš„local_mapã€‚å…³é”®å¸§çš„æ·»åŠ åœ¨saveKeyFramesAndFactor()å‡½æ•°ä¸­ã€‚LeGo-LOAMæä¾›äº†ä¸€ä¸ªæ¯”è¾ƒç²—ç³™çš„é—­ç¯åŠŸèƒ½ï¼Œè‹¥å¼€å¯é—­ç¯åŠŸèƒ½ï¼Œlocal_mapæ˜¯ç”±ä¸€ç»„æ—¶é—´è¿‘é‚»å…³é”®å¸§æ„æˆçš„ï¼Œå³ç”±è·ç¦»å½“å‰å¸§æ—¶é—´æœ€è¿‘çš„50å¸§å…³é”®å¸§æ„æˆã€‚è‹¥å…³é—­é—­ç¯åŠŸèƒ½ï¼Œlocal_mapæ˜¯ç”±ä¸€ç»„ç©ºé—´è¿‘é‚»å…³é”®å¸§æ„æˆçš„ï¼Œå³ç”±è·ç¦»å½“å‰å¸§åŠå¾„50må†…çš„å…³é”®å¸§æ„æˆçš„ã€‚ä¸åŒäºLOAMä¸­ç»´æŠ¤ç©ºé—´èŒƒå›´åˆ’åˆ†çš„æ»‘åŠ¨çª—å£ï¼ŒLeGo-LOAMè¿™é‡Œå°±æ¯”è¾ƒç›´æ¥å¹²è„†ã€‚ æ»¡è¶³æ¡ä»¶çš„å…³é”®å¸§çš„æ¬¡æå¤§è¾¹çº¿ç‚¹é›†æ‹¼å‡‘èµ·æ¥ï¼Œæ„æˆäº†local_mapä¸­çš„æ¬¡æå¤§è¾¹çº¿ç‚¹ã€‚ï¼ˆlaserCloudCornerFromMapDSï¼‰ï¼›æ»¡è¶³æ¡ä»¶çš„å…³é”®å¸§çš„æ¬¡æå°å¹³é¢ç‚¹é›†ä¸å¤–ç‚¹ç‚¹é›†æ‹¼å‡‘åœ¨ä¸€å—ï¼Œæ„æˆäº†local_mapä¸­çš„æ¬¡æå°å¹³é¢ç‚¹é›†ï¼ˆlaserCloudSurfFromMapDSï¼‰ã€‚è¿™é‡Œæ˜¯æœ‰ç‚¹é—®é¢˜çš„ï¼ mapOptmizationèŠ‚ç‚¹æ¥æ”¶åˆ°çš„æ¬¡æå¤§è¾¹çº¿ç‚¹é›†ä¸æ¬¡æå°å¹³é¢ç‚¹é›†éƒ½æ˜¯ç»è¿‡å»ç•¸å˜å¤„ç†çš„ï¼Œä½†æ˜¯å¤–ç‚¹ç‚¹é›†å¹¶æ²¡æœ‰å»ç•¸å˜ï¼Œæ‰€ä»¥æ¬¡æå°å¹³é¢ç‚¹é›†ä¸å¤–ç‚¹ç‚¹é›†çš„å‚è€ƒåæ ‡ä¸ä¸€è‡´ï¼Œä»£ç ä¸­å°†è¿™ä¿©ç‚¹äº‘ç›´æ¥æ‹¼å‡‘èµ·æ¥ã€‚ downsampleCurrentScan()ï¼šå¯¹æ¥è‡ªmsgçš„ç‚¹äº‘è¿›è¡Œé™é‡‡æ ·ã€‚ scan2MapOptimization()ï¼šå½“å‰å¸§ä¸local_mapè¿›è¡Œä¼˜åŒ–çš„è¿‡ç¨‹ã€‚å…¶ä¸­æœ‰ä¸‰ä¸ªä¸»è¦çš„éƒ¨åˆ† cornerOptimization()ï¼šç”¨æ¥è®¡ç®—scanä¸­çš„è¾¹æ²¿ç‚¹åˆ°localmapçš„è¾¹æ²¿ç‚¹ä¸­æ‰€åŒ¹é…çš„ç›´çº¿çš„è·ç¦»ã€‚ä¼šå°†è·ç¦»ä»¥åŠè·ç¦»çš„æ–¹å‘å‘é‡ä¿å­˜ä¸‹æ¥ surfOptimization()ï¼šæ‰¾scanä¸­å¹³é¢ç‚¹ä¸local_mapä¸­çš„åŒ¹é…å¹³é¢ï¼Œä¿ç•™å¹³é¢çš„å‚æ•°ã€‚ LMOptimization()ï¼šå®é™…ä¸Šæ˜¯é«˜æ–¯ç‰›é¡¿æ³•ï¼Œè¿™æ¶‰åŠè¯ˆéª—å•Šã€‚ transformUpdate()ï¼š saveKeyFramesAndFactor()ï¼šæ·»åŠ å…³é”®å¸§ï¼Œä¸€èˆ¬ä¸ä¸Šä¸€å…³é”®å¸§è·ç¦»ç›¸å·®0.3måˆ™è®¤ä¸ºæ˜¯å…³é”®å¸§ã€‚åŒæ—¶è¦è¿›è¡Œå¹¶è¿›è¡Œå…¨å±€çš„å› å­å›¾ä¼˜åŒ–ã€‚ correctPoses()ï¼šå›ç¯æ£€æµ‹çº¿ç¨‹æ‰¾åˆ°é—­ç¯å¹¶è¿›è¡Œé—­ç¯å¸§ä¼˜åŒ–åï¼Œåœ¨è¿™ä¸ªçº¿ç¨‹é‡Œæ›´æ–°æ‰€æœ‰å…³é”®å¸§ç‚¹äº‘çš„ä½å§¿ã€‚ publishTF()ï¼šå‘å¸ƒç»“æœmap optimizationä¹‹åçš„ä½å§¿ã€‚ publishKeyPosesAndFrames()ï¼šå‘å¸ƒå…³é”®å¸§åæ ‡ï¼Œè¿˜å‘äº†å½“å‰å…³é”®å¸§é™„è¿‘local_mapä¸­çš„å¹³é¢ç‚¹ã€‚ å›ç¯æ£€æµ‹çº¿ç¨‹ detectLoopClosure()ï¼šåœ¨å…³é”®å¸§ä¸­æœç´¢ä¸å½“å‰å¸§ç›¸å·®è¶…è¿‡30sä½†æ˜¯è·ç¦»åœ¨7mä»¥å†…çš„ï¼Œè®¤ä¸ºæ˜¯å¯èƒ½çš„å›ç¯ã€‚å°†å½“å‰å¸§çš„è¾¹æ²¿ç‚¹ä»¥åŠå¹³é¢ç‚¹åˆå¹¶ã€‚å°†å¯èƒ½çš„å›ç¯å¸§å‰å25å¸§çš„åœ°å›¾åˆå¹¶æ„å»ºå±€éƒ¨åœ°å›¾ã€‚ performLoopClosure()ï¼šé€šè¿‡ICPæ±‚è§£å½“å‰å¸§ä¸å›ç¯å¸§ä¹‹é—´çš„ä½å§¿å˜åŒ–ï¼Œç„¶åå¡åˆ°å› å­å›¾ä¸­ä¼˜åŒ–ã€‚ ä¸¤ä¸ªgtsamæ¯”è¾ƒæœ‰ç”¨çš„ææ–™ï¼Œä¸ªäººç›®å‰çš„ç†è§£å› å­å›¾æ˜¯ç”¨äºåœ¨æœ‰å›ç¯çš„æ—¶å€™ä¼˜åŒ–ä½å§¿çš„ã€‚ https://programmer.group/gtsam-tutorial-learning-notes.html https://blog.csdn.net/lzy6041/article/details/107658568 å¯è§†åŒ–çº¿ç¨‹å‘å¸ƒè·ç¦»å½“å‰å¸§ä¸€å®šèŒƒå›´å†…çš„å…³é”®å¸§èŒƒå›´å†…çš„ç‚¹äº‘åœ°å›¾ï¼ŒåŒ…æ‹¬è¾¹æ²¿ç‚¹ã€å¹³é¢ç‚¹ä»¥åŠoutliers å‘å¸ƒçš„Topic /key_pose_originï¼šå…³é”®ç‚¹çš„ä½ç½®XYZ /laser_cloud_surroundï¼šå°±æ˜¯global_mapï¼Œå½“å‰å¸§å‘¨å›´ä¸€å®šèŒƒå›´å†…çš„åœ°å›¾ /aft_mapped_to_initï¼šä¼˜åŒ–è¿‡åçš„ä½å§¿ /history_cloudï¼šå›ç¯æ£€æµ‹æ—¶ï¼Œå¯èƒ½å›ç¯çš„é‚£ä¸€å¸§å’Œå‰å25å¸§çš„è¾¹æ²¿ç‚¹ä»¥åŠå¹³é¢ç‚¹æ„æˆçš„åœ°å›¾ã€‚ /corrected_cloudï¼šå›ç¯æ£€æµ‹è¿›è¡ŒICPåï¼Œå°†å½“å‰å¸§çš„ä½å§¿ä¿®æ­£åˆ°å›ç¯å¸§å¤„ã€‚ /recent_cloudï¼šå¹³é¢ç‚¹æ„æˆçš„local_map TransformFusionè¿™é‡Œæ ¸å¿ƒçš„äº‹æƒ…ï¼Œå°±æ˜¯å°†ä½é¢‘çš„Map Optimizationå¾—åˆ°çš„ä½å§¿ï¼Œä¸é«˜é¢‘çš„é›·è¾¾é‡Œç¨‹è®¡å‘çš„ä½å§¿èåˆã€‚ transformSum[]æ˜¯å½“å‰æ—¶åˆ»Odometryæ¨¡å—è®¡ç®—å‡ºæ¥çš„åœ¨odomåæ ‡ç³»ä¸‹çš„çŸ©é˜µ transformBefMapped[]æ˜¯ä¸Šä¸€æ¬¡mappingä¹‹å‰çš„Odometryè®¡ç®—çš„ä¸–ç•Œåæ ‡ç³»ä¸‹çš„è½¬æ¢çŸ©é˜µï¼Œå³ä¸Šä¸€æ¬¡mappingæ—¶çš„transformSum[]ã€‚ transformAftMapped[]æ˜¯ä¸Šä¸€æ¬¡mappingå¾®è°ƒä¹‹åçš„è½¬æ¢çŸ©é˜µï¼Œåœ¨mapåæ ‡ç³»ä¸‹ã€‚è®¡ç®—å…³ç³»è¿˜æ˜¯$T_{map}&#x3D;T_{cur}*T^{-1}{before}*T{after}$ï¼Œä¸»è¦å†…å®¹å°±æ˜¯ä¸€ä¸ªodomåæ ‡ç³»åˆ°mapåæ ‡ç³»çš„è½¬æ¢ã€‚ åæ ‡ç³»æ¢³ç† \\camera_initï¼šæ˜¯æ‰“å¼€ç›¸æœºçš„ä½ç½®ï¼Œä»–ä¸\\mapçš„é‡åˆï¼Œä»–ä»¬çš„ä½å§¿å…³ç³»åœ¨launchæ–‡ä»¶ä¸­å†™æ­» \\aft_mappedï¼šç»è¿‡Map Optimationåçš„ä½å§¿ï¼Œæ˜æ˜¾å¯ä»¥çœ‹å‡ºé¢‘ç‡ä½äº†ä¸€ç‚¹ã€‚ \\cameraï¼šæ˜¯ç»è¿‡ä¿®æ­£åçš„é«˜é¢‘é‡Œç¨‹è®¡çš„ä½å§¿ï¼Œå…¶ä¸\\base_linkçš„å…³ç³»åœ¨launchæ–‡ä»¶ä¸­å†™æ­»ã€‚ \\laser_odomï¼šæ˜¯LOä¸­è®¡ç®—å¾—åˆ°çš„é‡Œç¨‹è®¡ä½å§¿ï¼Œç¨‹åºä¸­çš„transformSum[]ã€‚","categories":[{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/categories/SLAM/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://liuxiao916.github.io/tags/C/"},{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"}],"author":"LiuXiao"},{"title":"Ceres","slug":"Ceres","date":"2022-03-21T07:19:38.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/03/21/Ceres/","link":"","permalink":"https://liuxiao916.github.io/2022/03/21/Ceres/","excerpt":"æœ‰å¿…è¦å­¦ä¹ ä¸€ä¸‹Ceresï¼Œå¾ˆå¤šSLAMç³»ç»Ÿä¸­éƒ½ç”¨Cereså®Œæˆéçº¿æ€§ä¼˜åŒ–ä»»åŠ¡ã€‚","text":"æœ‰å¿…è¦å­¦ä¹ ä¸€ä¸‹Ceresï¼Œå¾ˆå¤šSLAMç³»ç»Ÿä¸­éƒ½ç”¨Cereså®Œæˆéçº¿æ€§ä¼˜åŒ–ä»»åŠ¡ã€‚ ç®€ä»‹è¿™æ˜¯Cereså¯¹ä¸€ä¸ªé—®é¢˜çš„å®šä¹‰ã€‚ å…¶ä¸­$\\rho_{i}\\left(\\left|f_{i}\\left(x_{i 1}, \\ldots,x_{i_{k}}\\right)\\right|^{2}\\right)$æ˜¯ResidualBlockï¼Œæ®‹å·®å—ã€‚ $f_i(*)$ æ˜¯CostFunctionï¼Œä»£ä»·å‡½æ•°ã€‚ $\\rho_{i}$æ˜¯ä¸€ä¸ª LossFunction,æŸå¤±å‡½æ•°ã€‚ LossFunction æ˜¯ä¸€ä¸ªæ ‡é‡å‡½æ•°ï¼Œç”¨äºå‡å°‘å¼‚å¸¸å€¼å¯¹éçº¿æ€§æœ€å°äºŒä¹˜é—®é¢˜æ±‚è§£çš„å½±å“ã€‚ $[x_{i1},â€¦,x_{i2}]$æ˜¯ParameterBlockï¼Œå‚æ•°å—ã€‚ Problemè¿™ä¸ªæ˜¯æœ€é‡è¦çš„ç±»ã€‚å…¶ä¸­çš„AddResidualBlockæ˜¯æˆ‘ä»¬æœ€å¸¸ç”¨çš„ï¼Œç”¨äºæ·»åŠ æ®‹å·®å—ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950ResidualBlockId AddResidualBlock( CostFunction* cost_function, LossFunction* loss_function, const std::vector&lt;double*&gt;&amp; parameter_blocks);// Convenience methods for adding residuals with a small number of// parameters. This is the common case. Instead of specifying the// parameter block arguments as a vector, list them as pointers.ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3, double* x4);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3, double* x4, double* x5);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3, double* x4, double* x5, double* x6);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3, double* x4, double* x5, double* x6, double* x7);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3, double* x4, double* x5, double* x6, double* x7, double* x8);ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, double* x1, double* x2, double* x3, double* x4, double* x5, double* x6, double* x7, double* x8, double* x9); LocalParameterizationLocalParameterization æ¥å£å…è®¸ç”¨æˆ·å®šä¹‰å‚æ•°å—å¹¶ä¸å®ƒä»¬æ‰€å±çš„æµå½¢ç›¸å…³è”ã€‚å®ƒé€šè¿‡å®šä¹‰ Plus () è¿ç®—åŠå…¶é›…å¯æ¯”çŸ©é˜µæ¥å®ç°ã€‚ 1234567891011121314151617class LocalParameterization &#123; public: virtual ~LocalParameterization() &#123;&#125; // æµå‹ç©ºé—´ä¸­çš„åŠ æ³• virtual bool Plus(const double* x, const double* delta, double* x_plus_delta) const = 0; // è®¡ç®—é›…å…‹æ¯”çŸ©é˜µ virtual bool ComputeJacobian(const double* x, double* jacobian) const = 0; // local_matrix = global_matrix * jacobian virtual bool MultiplyByJacobian(const double* x, const int num_rows, const double* global_matrix, double* local_matrix) const; virtual int GlobalSize() const = 0; // å‚æ•°å— x æ‰€åœ¨çš„ç¯å¢ƒç©ºé—´çš„ç»´åº¦ã€‚ virtual int LocalSize() const = 0; // Î” æ‰€åœ¨çš„åˆ‡çº¿ç©ºé—´çš„ç»´åº¦&#125;; æ¯”å¦‚æˆ‘ä»¬åœ¨è®¡ç®—å››å…ƒæ•°çš„æ—¶å€™ï¼Œå‚è€ƒé“¾æ¥ï¼Œ å››å…ƒæ•°è¡¨ç¤ºçš„æ˜¯ä¸€ä¸ªSO3ï¼Œå››å…ƒæ•°è¡¨ç¤ºçš„è¿™ä¸ªä¸œè¥¿æ˜¯ä¸€ä¸ªæœ‰ä¸‰ä¸ªè‡ªç”±åº¦çš„ä¸œè¥¿ï¼Œç„¶è€Œå››å…ƒæ•°å´æœ‰å››ç»´ä¹Ÿå°±æ˜¯å››ä¸ªè‡ªç”±åº¦ï¼Œè¿™æ˜¾ç„¶æ˜¯ä¸åˆç†çš„ï¼Œæ‰€ä»¥ä¹Ÿå°±äº§ç”Ÿäº†ä¸€ä¸ªå•ä½å››å…ƒæ•°è¿™ä¹ˆä¸€ä¸ªä¸œè¥¿ï¼Œå•ä½å››å…ƒæ•°é¡¾åæ€ä¹‰ï¼Œå°±æ˜¯è¯´å››å…ƒæ•°çš„å››ä¸ªé‡çš„äºŒèŒƒæ•°æ˜¯1ã€‚è¿™ä¸ªå…¶å®æ˜¯ä¸€ä¸ªçº¦æŸï¼Œè¿™ä¸ªçº¦æŸå°±çº¦æŸäº†å››å…ƒæ•°çš„ä¸€ä¸ªè‡ªç”±åº¦ï¼Œè¿™æ ·å…¶å®å››å…ƒæ•°å°±åªå‰©ä¸‹ä¸‰ä¸ªè‡ªç”±åº¦äº†æ­£å¥½ç¬¦åˆä¸€ä¸ªSO3çš„ç»´æ•°ã€‚ ç„¶ååœ¨ceresé‡Œé¢ï¼Œå¦‚æœä½¿ç”¨çš„æ˜¯è‡ªåŠ¨æ±‚å¯¼ï¼Œç„¶åå†ç»“åˆçˆ¬å±±æ³•ï¼Œé‚£ä¹ˆæ¯æ­¥è¿­ä»£ä¸­éƒ½ä¼šäº§ç”Ÿä¸€ä¸ªå››ç»´çš„delta(è¿­ä»£çš„å¢é‡ï¼Œå‚è€ƒLMç­‰ç®—æ³•)ï¼Œé‚£ä¹ˆæ ¹æ®å¸¸è§„çš„çˆ¬å±±æ³•ï¼Œè¿™æ ·å°±ä»…ä»…éœ€è¦å°† åŸå››å…ƒæ•°â€œåŠ ä¸Šâ€è¿™ä¸ªè¿­ä»£äº§ç”Ÿçš„deltaå°±èƒ½å¤Ÿå¾—åˆ°æ–°çš„å››å…ƒæ•°äº†ï¼Œè¿™é‡Œé—®é¢˜å°±æ¥äº†ï¼Œç›´æ¥åŠ ä¸Šä»¥åè¿™ä¸ªå››å…ƒæ•°å°±ä¸åœ¨æ˜¯ä¸€ä¸ªå•ä½å››å…ƒæ•°äº†ï¼Œå°±æ²¡æœ‰æ„ä¹‰äº†ï¼Œå¦‚æœéå¾—è¿™ä¹ˆç”¨çš„è¯å°±å¾—æ¯æ¬¡è¿­ä»£è¿‡åéƒ½å°†è¿™ä¸ªå››å…ƒæ•°è¿›è¡Œä¸€ä¸ªå½’ä¸€åŒ–å¤„ç†ï¼Œè¿™æ˜¾ç„¶å¾ˆéº»çƒ¦ï¼Œäºæ˜¯å°±äº§ç”Ÿäº†LocalParameterizationã€‚ EigenQuaternionParameterization 1234567891011class CERES_EXPORT EigenQuaternionParameterization : public ceres::LocalParameterization &#123; public: virtual ~EigenQuaternionParameterization() &#123;&#125; virtual bool Plus(const double* x, const double* delta, double* x_plus_delta) const; virtual bool ComputeJacobian(const double* x, double* jacobian) const; virtual int GlobalSize() const &#123; return 4; &#125; virtual int LocalSize() const &#123; return 3; &#125;&#125;; GlobalSize å°±æ˜¯è¡¨ç¤ºä»–çœŸæ­£çš„ç»´æ•°æ˜¯ä¸€ä¸ª4ç»´çš„ï¼ŒLocalSizeæ˜¯å‘Šè¯‰Ceresä»–è¡¨ç¤ºçš„ä¸œè¥¿æ˜¯ä¸€ä¸ªä¸‰ç»´çš„ï¼Œç„¶åä»–å®šä¹‰äº†ä¸€ä¸ªâ€œPlusâ€å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°å°±æ˜¯å®šä¹‰çš„åŠ å–½ã€‚ é™¤æ­¤ä¹‹å¤–è¿˜æœ‰ IdentityParameterization() QuaternionParameterization() SubsetParameterization AddParameterBlock123456789101112131415void ProblemImpl::AddParameterBlock(double* values, int size) &#123; InternalAddParameterBlock(values, size);&#125;void ProblemImpl::AddParameterBlock( double* values, int size, LocalParameterization* local_parameterization) &#123; //è¿™è¡Œä»£ç å’Œä¸Šé¢çš„å‡½æ•°æ˜¯ä¸€æ ·çš„ ParameterBlock* parameter_block = InternalAddParameterBlock(values, size); if (local_parameterization != NULL) &#123; // ä¹‹åå†å¯¹å‚æ•°å—çš„è®¾ç½®local_parameterization parameter_block-&gt;SetParameterization(local_parameterization); &#125;&#125; ä½œç”¨éƒ½æ˜¯å°†å‚æ•°å—æ·»åŠ åˆ°problemä¸­ã€‚","categories":[{"name":"Programming","slug":"Programming","permalink":"https://liuxiao916.github.io/categories/Programming/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://liuxiao916.github.io/tags/C/"},{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"}],"author":"LiuXiao"},{"title":"C++çŸ¥è¯†æ¢³ç†","slug":"C++çŸ¥è¯†æ¢³ç†","date":"2022-03-19T12:27:00.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/03/19/C++çŸ¥è¯†æ¢³ç†/","link":"","permalink":"https://liuxiao916.github.io/2022/03/19/C++%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/","excerpt":"","text":"æŒ‡é’ˆä¸å¼•ç”¨123456789101112131415#include &lt;iostream&gt; using namespace std;int main()&#123; int num = 100; int&amp; ref_num = num; ref_num = 110; cout &lt;&lt; &amp;num &lt;&lt;&quot;\\t&quot;&lt;&lt;&amp;ref_num &lt;&lt;endl; int num1 = 100; int* rel_num1 = &amp; num1; *rel_num1 = 110; cout &lt;&lt; &amp;num1 &lt;&lt;&quot;\\t&quot;&lt;&lt;rel_num1&lt;&lt;endl;&#125; è¾“å‡ºä¸ºï¼š æˆ‘ä»¬çš„ç»“è®ºæ˜¯ï¼š å¼•ç”¨çš„åº•å±‚ä»ç„¶æ˜¯æŒ‡é’ˆï¼Œå¼•ç”¨æ˜¯å¯¹æŒ‡é’ˆçš„å°è£… è·å–å¼•ç”¨çš„åœ°å€æ—¶ï¼Œç¼–è¯‘å™¨å†…éƒ¨ä¼šè¿›è¡Œè½¬æ¢ï¼Œæ•…å¼•ç”¨åœ°å€ä¸åŸå˜é‡ä¸€æ ·ã€‚ å‡½æ•°ä¼ å‚Const12Void TransformToStart(PointType const *const pi, PointType *const po)&#123;&#125;Void TransformToStart(const PointType *const pi, PointType *const po)&#123;&#125; å…³é”®æ˜¯çœ‹conståœ¨*çš„å·¦è¾¹è¿˜æ˜¯å³è¾¹ï¼Œå·¦è¾¹çš„constä¿®é¥°PointTypeè¡¨ç¤ºä¸èƒ½é€šè¿‡æŒ‡é’ˆä¿®æ”¹ç‚¹äº‘ï¼Œå³è¾¹çš„constä¿®é¥°*è¡¨ç¤ºä¸èƒ½é€šè¿‡è¯¥æŒ‡é’ˆæŒ‡å‘æ–°çš„ç‚¹äº‘ã€‚ new ä½¿ç”¨newå¯ä»¥åœ¨è¿è¡Œé˜¶æ®µåˆ†é…æœªå‘½åçš„å†…å­˜ä»¥å­˜å‚¨å€¼ï¼Œåœ¨æ­¤æƒ…å†µä¸‹åªèƒ½é€šè¿‡æŒ‡é’ˆæ¥è®¿é—®å†…å­˜ã€‚ ä½¿ç”¨newå¯ä»¥é‡Šæ”¾å†…å­˜ã€‚ 12int * ptr_int = new int;delete ptr_int; åˆå§‹åŒ–å‚æ•°åˆ—è¡¨æ‡’äººæ„é€ æ³•ã€‚ 12345678class CExample &#123;public: int _a; float _b; //æ„é€ å‡½æ•°åˆå§‹åŒ–åˆ—è¡¨ CExample(int a, float b): _a(a),_b(b) &#123;&#125;&#125;; å¯ä»¥ä½¿ç”¨newæ¥åˆå§‹åŒ–ä¸€ä¸ªç±»ï¼Œnewå‡ºæ¥çš„æœ€åä¸€å®šè¦deleteã€‚ 1CExample* Exp = new CExample(1,2.22) ä¸newçš„æ˜¯åœ¨æ ˆå†…å­˜ä¸­ï¼Œnewçš„æ˜¯åŠ¨æ€åˆ†é…çš„å †å†…å­˜ã€‚","categories":[{"name":"Programming","slug":"Programming","permalink":"https://liuxiao916.github.io/categories/Programming/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://liuxiao916.github.io/tags/C/"}],"author":"LiuXiao"},{"title":"Epipolar Geometry","slug":"Epipolar-Geometry","date":"2022-02-20T02:49:00.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/20/Epipolar-Geometry/","link":"","permalink":"https://liuxiao916.github.io/2022/02/20/Epipolar-Geometry/","excerpt":"è¿™æ˜¯Stanford CS231Aä¸­å…³äºEpipolar Geometryçš„å†…å®¹ã€‚","text":"è¿™æ˜¯Stanford CS231Aä¸­å…³äºEpipolar Geometryçš„å†…å®¹ã€‚ å¯¹æå‡ ä½• Epipolar GeometryIntroductionä¸€èˆ¬æˆ‘ä»¬ä¸èƒ½ä»ä¸€å¼ å›¾åƒä¸­æ¢å¤3Dä¸–ç•Œçš„ä¿¡æ¯ã€‚å› ä¸ºæ·±åº¦ä¿¡æ¯çš„ä¸¢å¤±ã€‚ å›¾1ï¼šè¿™å¼ å›¾è®©æˆ‘ä»¬è§‰å¾—äººåœ¨æ‹–ç€å¡”ï¼Œå¤šè§’åº¦çš„ç…§ç‰‡å¯ä»¥è§£å†³è¿™ç§é”™è§‰ã€‚ ä¾‹å¦‚ï¼Œåœ¨å›¾ 1 ä¸­ï¼Œæˆ‘ä»¬æœ€åˆå¯èƒ½ä¼šè¯¯ä»¥ä¸ºè¿™ä¸ªäººæ­£åœ¨ä¸¾èµ·æ¯”è¨æ–œå¡”ã€‚ åªæœ‰ä»”ç»†è§‚å¯Ÿï¼Œæˆ‘ä»¬æ‰èƒ½çŸ¥é“æƒ…å†µå¹¶éå¦‚æ­¤ï¼Œè¿™åªæ˜¯ä¸€ç§åŸºäºä¸åŒæ·±åº¦æŠ•å½±åˆ°åƒå¹³é¢ä¸Šçš„é”™è§‰ã€‚ å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿä»ä¸€ä¸ªå®Œå…¨ä¸åŒçš„è§’åº¦è§‚çœ‹è¿™ä¸ªåœºæ™¯ï¼Œè¿™ç§é”™è§‰å°±ä¼šç«‹å³æ¶ˆå¤±ï¼Œæˆ‘ä»¬ä¼šç«‹å³å¾—åˆ°æ­£ç¡®çš„åœºæ™¯ã€‚ è¿™äº›è®²ä¹‰çš„é‡ç‚¹æ˜¯å±•ç¤ºå½“å­˜åœ¨å¤šä¸ªç›¸æœºæ—¶æŒæ¡å‡ ä½•çŸ¥è¯†æ˜¯å¦‚ä½•éå¸¸æœ‰å¸®åŠ©çš„ã€‚ å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†é¦–å…ˆä¸“æ³¨äºå®šä¹‰ä¸¤ä¸ªè§†ç‚¹æ‰€æ¶‰åŠçš„å‡ ä½•ï¼Œç„¶åä»‹ç»è¿™ç§å‡ ä½•å¦‚ä½•å¸®åŠ©è¿›ä¸€æ­¥äº†è§£æˆ‘ä»¬å‘¨å›´çš„ä¸–ç•Œã€‚ å¯¹æå‡ ä½• Epipolar Geometry å›¾2ï¼šå¯¹æå‡ ä½•çš„ä¸€èˆ¬å½¢å¼ã€‚ç°è‰²åŒºåŸŸæ˜¯æå¹³é¢ï¼ˆepipolar planeï¼‰ã€‚ æ©™è‰²çº¿æ˜¯åŸºçº¿ï¼ˆbaselineï¼‰ï¼Œè€Œä¸¤æ¡è“è‰²çº¿æ˜¯æçº¿ï¼ˆepipolar lines.ï¼‰ã€‚ é€šå¸¸åœ¨å¤šè§†å›¾å‡ ä½•ä¸­ï¼Œå¤šä¸ªç›¸æœºã€ä¸€ä¸ª 3D ç‚¹ä»¥åŠè¯¥ç‚¹åœ¨æ¯ä¸ªç›¸æœºå›¾åƒå¹³é¢ä¸­çš„æŠ•å½±ä¹‹é—´å­˜åœ¨æœ‰è¶£çš„å…³ç³»ã€‚ å°†ç›¸æœºã€3D ä¸­çš„ç‚¹å’Œç›¸åº”çš„è§‚å¯Ÿç›¸å…³è”çš„å‡ ä½•ç§°ä¸ºç«‹ä½“å¯¹çš„å¯¹æå‡ ä½•(epipolar geometry of a stereo pair)ã€‚ å¦‚å›¾ 2 æ‰€ç¤ºï¼Œé€šå¸¸å¯¹æå‡ ä½•åŒ…å«ä¸¤ä¸ªç›¸æœºè§‚å¯Ÿç›¸åŒçš„ 3D ç‚¹ $P$ï¼Œå…¶åœ¨æ¯ä¸ªå›¾åƒå¹³é¢ä¸­çš„æŠ•å½±åˆ†åˆ«ä½äº $p$ å’Œ $p_0$ã€‚ æ‘„åƒæœºä¸­å¿ƒä½äº $O_1$ å’Œ $O_2$ï¼Œå®ƒä»¬ä¹‹é—´çš„çº¿ç§°ä¸ºåŸºçº¿ã€‚ æˆ‘ä»¬ç§°ç”±ä¸¤ä¸ªç›¸æœºä¸­å¿ƒå’Œ P å®šä¹‰çš„å¹³é¢ä¸ºæå¹³é¢ã€‚åŸºçº¿ä¸ä¸¤ä¸ªå›¾åƒå¹³é¢ç›¸äº¤çš„ä½ç½®ç§°ä¸ºæç‚¹ $e$ å’Œ $eâ€™$ ã€‚ æœ€åï¼Œç”±æå¹³é¢å’Œä¸¤ä¸ªå›¾åƒå¹³é¢çš„äº¤ç‚¹å®šä¹‰çš„çº¿ç§°ä¸ºæçº¿ã€‚ æçº¿å…·æœ‰åœ¨å›¾åƒå¹³é¢ä¸­çš„å„ä¸ªæç‚¹å¤„ä¸åŸºçº¿ç›¸äº¤çš„ç‰¹æ€§ã€‚ å›¾3ï¼šæçº¿ä»¥åŠå…¶å¯¹åº”ç‚¹çš„ä¸€ä¸ªä¾‹å­ å›¾4ï¼šå½“ä¸¤ä¸ªå›¾åƒå¹³é¢å¹³è¡Œæ—¶ï¼Œæç‚¹$e$ä¸$eâ€™$åœ¨æ— ç©·è¿œå¤„ã€‚æ­¤æ—¶æçº¿ä¸å›¾åƒå¹³é¢çš„$u$è½´å¹³è¡Œã€‚ å›¾ 4 æ˜¾ç¤ºäº†ä¸€ä¸ªæœ‰è¶£çš„å¯¹æå‡ ä½•æ¡ˆä¾‹ï¼Œå®ƒå‘ç”Ÿåœ¨å›¾åƒå¹³é¢å½¼æ­¤å¹³è¡Œæ—¶ã€‚ å½“å›¾åƒå¹³é¢å½¼æ­¤å¹³è¡Œæ—¶ï¼Œæç‚¹$e$å’Œ$eâ€™$å°†ä½äºæ— ç©·è¿œå¤„ï¼Œå› ä¸ºè¿æ¥ç›¸æœºä¸­å¿ƒ$O_1$ã€$O_2$çš„åŸºçº¿å¹³è¡Œäºå›¾åƒå¹³é¢ã€‚ è¿™ç§æƒ…å†µçš„å¦ä¸€ä¸ªé‡è¦æ€§è´¨æ˜¯æçº¿å¹³è¡Œäºæ¯ä¸ªå›¾åƒå¹³é¢çš„è½´ã€‚ è¿™ä¸ªæ¡ˆä¾‹ç‰¹åˆ«æœ‰ç”¨ï¼Œå°†åœ¨éšåçš„å›¾åƒæ ¡æ­£éƒ¨åˆ†ä¸­æ›´è¯¦ç»†åœ°ä»‹ç»ã€‚ ç„¶è€Œï¼Œåœ¨ç°å®ä¸–ç•Œçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ²¡æœ‰å¾—åˆ° 3D ä¸–ç•Œä¸­ç‚¹ P çš„ç¡®åˆ‡ä½ç½®ï¼Œä½†å¯ä»¥ç¡®å®šå…¶åœ¨å›¾åƒå¹³é¢ p ä¸­çš„æŠ•å½±ã€‚æˆ‘ä»¬è¿˜åº”è¯¥èƒ½å¤ŸçŸ¥é“ç›¸æœºçš„ä½ç½®ã€æ–¹å‘å’Œç›¸æœºçŸ©é˜µã€‚ æˆ‘ä»¬å¯ä»¥ç”¨è¿™äº›çŸ¥è¯†åšä»€ä¹ˆï¼Ÿå€ŸåŠ©ç›¸æœºä½ç½®$O_1$ã€$O_2$å’Œå›¾åƒç‚¹$p$çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰æå¹³é¢ã€‚æœ‰äº†è¿™ä¸ªæå¹³é¢ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç¡®å®šæçº¿ã€‚æ ¹æ®å®šä¹‰ï¼Œ$P$åœ¨ç¬¬äºŒå¹…å›¾åƒä¸­çš„æŠ•å½±$pâ€™$å¿…é¡»ä½äºç¬¬äºŒå¹…å›¾åƒçš„æçº¿ä¸Šã€‚å› æ­¤ï¼Œå¯¹æçº¿å‡ ä½•ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å›¾åƒå¯¹ä¹‹é—´åˆ›å»ºå¼ºçº¦æŸï¼Œè€Œæ— éœ€äº†è§£åœºæ™¯çš„ 3D ä¿¡æ¯ã€‚ å›¾5ï¼šç¡®å®šåŸºæœ¬çŸ©é˜µå’ŒåŸºæœ¬çŸ©é˜µï¼Œè¿™æœ‰åŠ©äºè·¨å¤šä¸ªè§†å›¾æ˜ å°„ç‚¹å’Œæçº¿ã€‚ï¼ˆThe setup for determining the essential and fundamental matrices, which help map points and epipolar lines across views.ï¼‰ æˆ‘ä»¬ç°åœ¨å°†å°è¯•å¼€å‘æ— ç¼ï¼ˆ seamlessï¼‰çš„æ–¹æ³•æ¥è·¨è§†å›¾æ˜ å°„ç‚¹å’Œæçº¿ã€‚å¦‚æœæˆ‘ä»¬é‡‡ç”¨åŸå§‹å¯¹æå‡ ä½•æ¡†æ¶ï¼ˆå›¾ 5ï¼‰ä¸­ç»™å‡ºçš„é…ç½®ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†è¿›ä¸€æ­¥å®šä¹‰$M$å’Œ$Mâ€™$ä¸ºå°†3Dç‚¹æ˜ å°„åˆ°å®ƒä»¬å„è‡ªçš„2Då›¾åƒå¹³é¢ä½ç½®çš„ç›¸æœºæŠ•å½±çŸ©é˜µã€‚è®©æˆ‘ä»¬å‡è®¾ä¸–ç•Œå‚è€ƒç³»ç»Ÿä¸ç¬¬ä¸€ä¸ªç›¸æœºç›¸å…³è”ï¼Œç¬¬äºŒä¸ªç›¸æœºé¦–å…ˆé€šè¿‡æ—‹è½¬ R åç§»ï¼Œç„¶åé€šè¿‡å¹³ç§» Tã€‚è¿™æŒ‡å®šç›¸æœºæŠ•å½±çŸ©é˜µä¸ºï¼š$$M &#x3D; K\\begin{bmatrix} I &amp; 0 \\end{bmatrix} \\quad \\ \\ Mâ€™&#x3D; Kâ€™\\begin{bmatrix} R^T &amp; -R^TT \\end{bmatrix} \\quad$$ æœ¬è´¨çŸ©é˜µ The Essential Matrixæœ¬è´¨çŸ©é˜µEï¼ˆEssiential Matrixï¼‰ï¼šåæ˜ ç©ºé—´ä¸€ç‚¹Påœ¨ä¸åŒç›¸æœºä¸‹ç›¸æœºåæ ‡ç³»ä¸­çš„è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ã€‚ æœ€ç®€å•çš„æƒ…å†µï¼Œæ™®é€šçš„ç›¸æœºæ¨¡å‹ï¼Œå†…å‚ç›¸ç­‰ã€‚æ‰€ä»¥å…¬å¼1å˜æˆã€‚$$M &#x3D; \\begin{bmatrix} I &amp; 0 \\end{bmatrix} \\quad \\ \\ Mâ€™&#x3D; \\begin{bmatrix} R^T &amp; -R^TT \\end{bmatrix} \\quad$$è¿™è¡¨æ˜$pâ€™$çš„ä½ç½®åœ¨ç¬¬ä¸€ä¸ªç›¸æœºåæ ‡ç³»ä¸­ä¸º$Rpâ€™+T$ã€‚å› æ­¤å‘é‡$Rpâ€™+T$ä¸$T$éƒ½åœ¨æå¹³é¢ï¼Œä¹‹åæˆ‘ä»¬è¿›è¡Œå‰ä¹˜$T\\times(Rpâ€™+T)&#x3D;T\\times(Rpâ€™)$ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå‚ç›´äºæå¹³é¢çš„å‘é‡ã€‚è¿™ä¹Ÿæ„å‘³ç€$p$åœ¨æå¹³é¢ä¸­å‚ç›´äº$T\\times(Rpâ€™)$ï¼Œç»™äº†æˆ‘ä»¬ä¸€ä¸ªé™åˆ¶æ˜¯ä»–ä»¬çš„ç‚¹ä¹˜ä¸º0ï¼š$$p^T[T\\times(Rpâ€™)]&#x3D;0$$æˆ‘ä»¬å¯ä»¥ç”¨æ–œå¯¹ç§°çŸ©é˜µï¼ˆskew-symmetricï¼‰è¡¨ç¤ºå‰ä¹˜ã€‚ $$a\\times b&#x3D; \\begin{bmatrix} 0 &amp; -a_z &amp;a_y\\\\a_z &amp;0 &amp;-a_x\\\\-a_y&amp;a_x&amp;0\\end{bmatrix} \\begin{bmatrix} b_x\\\\b_y\\\\b_z\\end{bmatrix}&#x3D;[a_\\times]b$$ å› æ­¤æˆ‘ä»¬å¯ä»¥å¾—åˆ°$$p^T[T_\\times]Rpâ€™&#x3D;0$$çŸ©é˜µ$E&#x3D;[T_\\times]R$æ˜¯æœ¬è´¨çŸ©é˜µï¼Œä¸ºæçº¿çº¦æŸåˆ›å»ºä¸€ä¸ªç´§å‡‘çš„è¡¨è¾¾å¼ï¼š$$p^TEpâ€™&#x3D;0$$å…¶è‡ªç”±åº¦ä¸º5ï¼ˆ5DOFï¼‰ã€‚å…¶ç§©ä¸º2ä¸”æ˜¯å¥‡å¼‚çš„ã€‚ï¼ˆå¯ä»¥è¿™æ ·ç†è§£ï¼Œæ—‹è½¬ä»¥åŠå¹³ç§»å„ä¸‰ä¸ªè‡ªç”±åº¦ï¼Œå»æ‰å°ºåº¦åªå‰©5ä¸ªï¼‰ã€‚ æœ¬è´¨çŸ©é˜µç”¨äºè®¡ç®—ä¸$p$å’Œ$pâ€™$ç›¸å…³è”çš„æçº¿ã€‚æ¯”å¦‚ï¼Œ$\\ellâ€™&#x3D;E^Tp$å¾—åˆ°åœ¨ç›¸æœº2çš„å›¾åƒå¹³é¢ä¸­çš„æçº¿ã€‚ç±»ä¼¼çš„ï¼Œ$\\ell&#x3D;Epâ€™$å¾—åˆ°ç›¸æœº1çš„å›¾åƒå¹³é¢ä¸­çš„æçº¿ã€‚å¦ä¸€ä¸ªæœ‰è¶£çš„æ€§è´¨æ˜¯æœ¬è´¨çŸ©é˜µä¸æç‚¹çš„ä¹˜ç§¯ä¸º0ã€‚$E^T &#x3D; Eeâ€™ &#x3D;0$ã€‚å› ä¸ºå¯¹äºä»»æ„åœ¨ç›¸æœº1çš„å›¾åƒå¹³é¢ä¸­çš„ç‚¹ï¼ˆé™¤äº†æç‚¹eï¼‰ï¼Œå¯¹åº”åœ¨ç›¸æœº2çš„å›¾åƒä¸­çš„æçº¿ï¼Œ$lâ€™&#x3D;E^Tx$éƒ½åŒ…å«æç‚¹$eâ€™$ã€‚å› æ­¤$eâ€™$æ»¡è¶³$eâ€™^T(E^Tx)&#x3D;(eâ€™^TE^T)x&#x3D;0$å¯¹äºæ‰€æœ‰çš„xï¼Œæ‰€ä»¥$Eeâ€™ &#x3D;0$ã€‚ç±»ä¼¼çš„$E^Te&#x3D;0$ã€‚ åŸºç¡€çŸ©é˜µ The Fundamental MatrixåŸºç¡€çŸ©é˜µFï¼ˆFundamental Matrixï¼‰ï¼šåæ˜ ç©ºé—´ä¸€ç‚¹Påœ¨ä¸åŒç›¸æœºä¸‹å›¾åƒåæ ‡ç³»ä¸­çš„è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ã€‚ å½“æˆ‘ä»¬çš„ç›¸æœºå‚æ•°ä¸ä¸€è‡´æ—¶ã€‚$$M &#x3D; K\\begin{bmatrix} I &amp; 0 \\end{bmatrix} \\quad \\ \\ Mâ€™&#x3D; Kâ€™\\begin{bmatrix} R^T &amp; -R^TT \\end{bmatrix} \\quad$$é¦–å…ˆæˆ‘ä»¬å®šä¹‰$p_c&#x3D;K^{-1}p$ä»¥åŠ$p_câ€™ &#x3D; Kâ€™^{-1}pâ€™$ä½œä¸ºPåœ¨ç›¸æœºåæ ‡ç³»ä¸‹é¢çš„æŠ•å½±ã€‚æ ¹æ®ä¸Šä¸€èŠ‚çš„æ¨å¯¼ã€‚$$P_c^T[T_\\times]Rpâ€™_c&#x3D;0$$æˆ‘ä»¬ä»£å…¥å¯çŸ¥ï¼Œå¾—åˆ°åœ¨åƒç´ åæ ‡ç³»ä¸‹çš„è¡¨ç¤ºã€‚$$p^TK^{-T}[T_\\times]R*Kâ€™^{-1}pâ€™&#x3D;0$$çŸ©é˜µ$F&#x3D;Kâ€™^{-T}[T_\\times]RK^{-1}$ä½œä¸ºåŸºç¡€çŸ©é˜µï¼Œå®ƒçš„ä½œç”¨ç±»ä¼¼äºä¸Šä¸€èŠ‚ä¸­çš„åŸºæœ¬çŸ©é˜µï¼Œä½†åŒ…å«æœ‰å…³ç›¸æœºå†…å‚çŸ©é˜µ$K,Kâ€™$ä»¥åŠç›¸æœºä¹‹é—´çš„æ—‹è½¬$R$ä»¥åŠå¹³ç§»$T$çš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œä»–ä¹Ÿæœ‰åŠ©äºè®¡ç®—å…³è”$p$å’Œ$pâ€™$çš„æçº¿ï¼Œå³ä½¿å½“ç›¸æœºå†…å‚ä»¥åŠç›¸å¯¹å˜æ¢$R,T$æœªçŸ¥çš„æ—¶å€™ã€‚ä¸æœ¬è´¨çŸ©é˜µç±»ä¼¼ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åŸºç¡€çŸ©é˜µä»¥åŠå…¶å¯¹åº”çš„ç‚¹è®¡ç®—æçº¿$\\ellâ€™&#x3D;F^Tp$ä»¥åŠ$\\ell&#x3D;Fpâ€™$ã€‚åŸºç¡€çŸ©é˜µæœ‰ä¸ƒä¸ªè‡ªç”±åº¦ã€‚ï¼ˆä»–æ¯”å•åº”çŸ©é˜µå°‘ä¸€ä¸ªè‡ªç”±åº¦ï¼Œå› ä¸ºskew symmetric matrixçš„ç§©ä¸º2ï¼‰ ä½†æ˜¯åŸºæœ¬çŸ©é˜µæœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿ ä¸åŸºæœ¬çŸ©é˜µä¸€æ ·ï¼Œå¦‚æœæˆ‘ä»¬çŸ¥é“åŸºæœ¬çŸ©é˜µï¼Œé‚£ä¹ˆåªéœ€çŸ¥é“å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹å°±å¯ä»¥ä¸ºæˆ‘ä»¬æä¾›å¦ä¸€ä¸ªå›¾åƒä¸­å¯¹åº”ç‚¹çš„ç®€å•çº¦æŸï¼ˆæçº¿ï¼‰ã€‚ å› æ­¤ï¼Œåœ¨ä¸çŸ¥é“ P åœ¨ 3D ç©ºé—´ä¸­çš„å®é™…ä½ç½®æˆ–ç›¸æœºçš„ä»»ä½•å¤–åœ¨æˆ–å†…åœ¨ç‰¹å¾çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å»ºç«‹ä»»ä½• $p$ä¸$pâ€™$ä¹‹é—´çš„å…³ç³»ã€‚ å…«ç‚¹æ³•æˆ‘ä»¬åœ¨ä¸çŸ¥é“ç›¸æœºçš„å¤–åœ¨æˆ–å†…åœ¨å‚æ•°çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥é€šè¿‡ç»™å®šåŒä¸€åœºæ™¯çš„ä¸¤å¹…å›¾åƒï¼Œä¼°è®¡åŸºæœ¬çŸ©é˜µã€‚è¿™ç§æ–¹æ³•å«å…«ç‚¹æ³•ã€‚å…«ç‚¹æ³•å‡è®¾ä¸¤ä¸ªå›¾åƒä¹‹é—´æœ‰ä¸€ç»„è‡³å°‘ 8 ç»„å¯¹åº”ç‚¹å¯ç”¨ã€‚ å›¾å…­ï¼šä¸¤å¹…å›¾åƒä¸­å¯¹åº”çš„å…«ä¸ªç‚¹ã€‚ æ¯å¯¹ç‚¹åœ¨å¯¹æçº¦æŸä¸‹å¯å¾—åˆ°å¯¹åº”å…³ç³»$p_i&#x3D;(u_i,v_i,1)$ä¸$p_iâ€™&#x3D;(u_iâ€™,v_iâ€™,1)$ï¼Œ$p_i^TFpâ€™_i&#x3D;0$ã€‚æˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š ç”±äºè¿™ä¸ªçº¦æŸæ˜¯ä¸€ä¸ªæ ‡é‡æ–¹ç¨‹ï¼Œå®ƒåªçº¦æŸä¸€ä¸ªè‡ªç”±åº¦ã€‚ å› æ­¤æˆ‘ä»¬åªèƒ½éœ€è¦å…¶ä¸­å…«ä¸ªçº¦æŸæ¥ç¡®å®šåŸºæœ¬çŸ©é˜µï¼š è¿™å¯ä»¥å†™æˆ$$Wf&#x3D;0$$å…¶ä¸­$W$æ˜¯$N\\times9$çš„çŸ©é˜µï¼Œfæ˜¯æˆ‘ä»¬è¦æ±‚çš„åŸºç¡€çŸ©é˜µã€‚ å®è·µä¸­ï¼Œæˆ‘ä»¬å¸¸ç”¨å¤šäº8ä¸ªç‚¹å¯¹æ¥æ±‚è§£åŸºç¡€çŸ©é˜µå› ä¸ºè¿™æ ·å¯ä»¥å‡å°‘å™ªå£°ã€‚è¿™ä¸ªé½æ¬¡æ–¹ç¨‹ç»„çš„è§£å¯ä»¥é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£ (SVD) åœ¨æœ€å°äºŒä¹˜æ„ä¹‰ä¸Šæ‰¾åˆ°ã€‚SVDèƒ½å¾—åˆ°å¯¹åŸºç¡€çŸ©é˜µçš„ä¼°è®¡$\\hat{F}$ï¼Œå®ƒå¯èƒ½æ˜¯æ»¡ç§©çš„ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çŸ¥é“åŸºç¡€çŸ©é˜µçš„ç§©æ˜¯2ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æœ€å¥½çš„2é˜¶çŸ©é˜µæ¥è¿‘ä¼¼$\\hat{F}$ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è§£å†³äº†ä»¥ä¸‹ä¼˜åŒ–é—®é¢˜ï¼š SVDè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ$\\hat{F}&#x3D;U\\Sigma V^T$ï¼Œåˆ™äºŒé˜¶è¿‘ä¼¼ä¸ºï¼š å›¾åƒæ ¡æ­£å›æƒ³ä¸€ä¸‹ï¼Œå½“ä¸¤ä¸ªå›¾åƒå½¼æ­¤å¹³è¡Œæ—¶ï¼Œä¼šå‡ºç°ä¸€ä¸ªæœ‰è¶£çš„å¯¹æå‡ ä½•æ¡ˆä¾‹ã€‚ è®©æˆ‘ä»¬é¦–å…ˆè®¡ç®—å¹³è¡Œå›¾åƒå¹³é¢æƒ…å†µä¸‹çš„åŸºæœ¬çŸ©é˜µ Eã€‚æˆ‘ä»¬å¯ä»¥å‡è®¾ä¸¤ä¸ªç›¸æœºå…·æœ‰ç›¸åŒçš„ K å¹¶ä¸”ç›¸æœºä¹‹é—´æ²¡æœ‰ç›¸å¯¹æ—‹è½¬ (R &#x3D; I)ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®©æˆ‘ä»¬å‡è®¾åªæœ‰æ²¿ x è½´çš„å¹³ç§»ï¼Œç»™å®š T &#x3D; (Tx, 0, 0)ã€‚ å¾—å‡ºï¼š ä¸€æ—¦Eå·²çŸ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ‰¾åˆ°ä¸å›¾åƒå¹³é¢ä¸­çš„ç‚¹ç›¸å…³è”çš„æçº¿çš„æ–¹å‘ã€‚ è®©æˆ‘ä»¬è®¡ç®—ä¸ç‚¹$pâ€™$ç›¸å…³çš„æçº¿$\\ellâ€™$çš„æ–¹å‘ æˆ‘ä»¬å¯ä»¥çœ‹å‡º$\\ell$çš„æ–¹å‘æ˜¯æ°´å¹³çš„ï¼Œ$\\ellâ€™$ä¹Ÿæ˜¯ã€‚ å›¾ 7ï¼šå›¾åƒæ ¡æ­£çš„è¿‡ç¨‹æ¶‰åŠè®¡ç®—ä¸¤ä¸ªå•åº”æ€§ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶åº”ç”¨äºä¸€å¯¹å›¾åƒä»¥ä½¿å®ƒä»¬å¹³è¡Œã€‚ å›¾ 8ï¼šå›¾åƒæ ¡æ­£é—®é¢˜ï¼šæˆ‘ä»¬è®¡ç®—ä¸¤ä¸ªå•åº”æ€§ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬åº”ç”¨äºå›¾åƒå¹³é¢ä»¥ä½¿ç”Ÿæˆçš„å¹³é¢å¹³è¡Œã€‚","categories":[{"name":"Courese","slug":"Courese","permalink":"https://liuxiao916.github.io/categories/Courese/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"},{"name":"Computer Visoon","slug":"Computer-Visoon","permalink":"https://liuxiao916.github.io/tags/Computer-Visoon/"}],"author":"LiuXiao"},{"title":"Vision Algorithm for Mobile Roboticsè¯¾ç¨‹æ€»ç»“(7~10)èŠ‚","slug":"Vision-Algorithm-for-Mobile-Roboticsè¯¾ç¨‹æ€»ç»“-7-10-èŠ‚","date":"2022-02-18T13:18:56.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/18/Vision-Algorithm-for-Mobile-Roboticsè¯¾ç¨‹æ€»ç»“-7-10-èŠ‚/","link":"","permalink":"https://liuxiao916.github.io/2022/02/18/Vision-Algorithm-for-Mobile-Robotics%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93-7-10-%E8%8A%82/","excerpt":"ç¬¬ä¸ƒè®²æ˜¯è¯´ç«‹ä½“è§†è§‰ä»¥åŠå¯¹æå‡ ä½•ï¼Œç¬¬å…«è®²æ˜¯æœ¬è´¨çŸ©é˜µä»¥åŠå…«ç‚¹æ³•ï¼Œç¬¬ä¹è®²æ˜¯è¯´RANSACï¼Œç¬¬åè®²æ˜¯è¯´SFMä»¥åŠå¸¸è§çš„å¼€æºSLAMæ¡†æ¶ã€‚","text":"ç¬¬ä¸ƒè®²æ˜¯è¯´ç«‹ä½“è§†è§‰ä»¥åŠå¯¹æå‡ ä½•ï¼Œç¬¬å…«è®²æ˜¯æœ¬è´¨çŸ©é˜µä»¥åŠå…«ç‚¹æ³•ï¼Œç¬¬ä¹è®²æ˜¯è¯´RANSACï¼Œç¬¬åè®²æ˜¯è¯´SFMä»¥åŠå¸¸è§çš„å¼€æºSLAMæ¡†æ¶ã€‚ ç¬¬ä¸ƒè®² Multiple View Geometry 1Stereo Vision ![](https://xiao-pic.oss-cn-shenzhen.aliyuncs.com/pic/img/æˆªå±2022-01-15 ä¸‹åˆ3.36.16.png) Depth from StereoGoal: recover the 3D structure by computing the intersection of corresponding rays The Human Binocular System Stereopsys is the principle by which our brain allows us to perceive depth from the left and right images Images project on our retinas up-side-down but our brains lets us perceive them as straight. Radial distortion is also removed. This process is called rectification Triangulation Goal: find an expression of the 3D point coordinates as a function of the 2D image coordinates Assumptions: cameras are calibrated: both intrinsic and extrinsic parameters are known point correspondences are given ä¸ºä»€ä¹ˆå¤§åŸºçº¿ï¼Œæ·±åº¦è¯¯å·®å°ï¼Ÿï¼ˆSLAMåå››è®²7.6.2ï¼‰ ç”±å…¬å¼$Z &#x3D; bf&#x2F;(u_l-u_r)$ï¼Œå¯çŸ¥ï¼Œæ¯”å¦‚å½“ç‰©ä½“åœ¨10må¤„ï¼Œ å¤§åŸºçº¿$b_1f&#x3D;100$ï¼Œ$d &#x3D; u_l-u_r&#x3D;10$ï¼Œè‹¥æ­¤æ—¶é”™è¯¯æµ‹é‡$d &#x3D; 11$ï¼Œåˆ™Z&#x3D;9.09ã€‚è‹¥æ­¤æ—¶é”™è¯¯æµ‹é‡$d &#x3D; 9$ï¼Œåˆ™Z&#x3D;11.11 å°åŸºçº¿$b_2f&#x3D;20$ï¼Œ$d &#x3D; u_l-u_r&#x3D;2$ï¼Œè‹¥æ­¤æ—¶é”™è¯¯æµ‹é‡$d &#x3D; 1$ï¼Œåˆ™Z&#x3D;20ã€‚è‹¥æ­¤æ—¶é”™è¯¯æµ‹é‡$d &#x3D; 3$ï¼Œåˆ™Z&#x3D;6.66 ä¸ºä»€ä¹ˆå¤§åŸºçº¿ï¼Œè¿‘å¤„ç›²åŒºå¤§ï¼Ÿ åŸºçº¿$b$å¤§çš„æ—¶å€™ã€‚å½“è·ç¦»$Z$å°ï¼Œè§†å·®$d$ä¹Ÿæ¯”è¾ƒå¤§ã€‚å› ä¸ºè§†å·®ä¸Šé™å›ºå®šï¼Œæ•…å¯¹åº”çš„æœ€å°è·ç¦»Zå˜å°ã€‚ ä¸ºä»€ä¹ˆå¤§åŸºçº¿ã€‚æœç´¢å›°éš¾ã€‚ ç›¸åŒè·ç¦»ä¸‹ï¼ŒåŸºçº¿è¶Šå¤§ï¼Œè§†å·®è¶Šå¤§ã€‚è§†å·®å¤§çš„è¯ï¼Œå·¦å³ç›¸æœºå›¾ç‰‡ä¸­å¯¹åº”çš„ä½ç½®è·ç¦»è¾ƒè¿œï¼Œè¾ƒéš¾æœç´¢ã€‚ Triangulationï¼ˆä¸‰è§’åŒ–ï¼‰çŸ¥é“ç‚¹åœ¨ä¸¤ä¸ªç›¸æœºä¸Šçš„ä½ç½®ï¼ŒçŸ¥é“ä½å§¿å˜æ¢ï¼Œæ±‚è§£å®é™…åæ ‡ã€‚ Triangulation is the problem of determining the 3D position of a point given a set of corresponding imagelocations and known camera poses We want to intersect the two visual rays corresponding to $p_1$ and $p_2$, but, because of noise and numericalerrors, they wonâ€™t meet exactly, so we can only compute an approximation Epipolar GeometryCorrespondence problem The Epipolar Constraint Stereo Rectification å°†Rï¼ŒTæ¢æˆä»worldåæ ‡ç³»åˆ°cameraåæ ‡ç³»çš„è½¬æ¢ã€‚ Things to Remember Disparity Triangulation: simplified and general case, linear and non linear approach Choosing the baseline Correspondence problem: epipoles, epipolar lines, epipolar plane Stereo rectification Understanding Check Can you relate Structure from Motion to 3D reconstruction? Whatâ€™s their difference? 3Dé‡å»ºåŒ…å«SFMã€ä¸‰ç»´é‡å»ºåŒ…æ‹¬å¤šç§æ–¹å¼ï¼ŒSFMæ˜¯å…¶ä¸­ä¸€ç§ã€‚ Can you define disparity in both the simplified and the general case? ç®€åŒ–æƒ…å†µä¸‹ï¼Œç›¸æœºå›¾åƒå¹³é¢æ˜¯å¹³è¡Œçš„ï¼Œè§†å·®æ˜¯3Dç‚¹åœ¨ä¸¤ä¸ªå›¾åƒå¹³é¢ä¸ŠæŠ•å½±ä½ç½®ä¹‹é—´çš„å·®ã€‚ä¸€èˆ¬æƒ…å†µä¸‹å›¾åƒå¹³é¢æ˜¯ä¸å¹³è¡Œçš„ï¼Œéœ€è¦å…ˆä¿®æ­£ã€‚ Can you provide a mathematical expression of depth as a function of the baseline, the disparity and the focal length? $$Z&#x3D;\\frac{bf}{u_l-u_r}$$ Can you apply error propagation to derive an expression for depth uncertainty? How can we improve the uncertainty? è¿™ä¸ªè¯¯å·®åˆ†ææˆ‘çœŸçš„ä¸ä¼šã€‚åªèƒ½çœ‹ä¹‹å‰æˆ‘ä¸¾å¾—ä¾‹å­ã€‚Zå›ºå®šï¼Œbè¶Šå¤§ï¼Œdè¶Šå¤§ï¼Œdçš„å°æ‰°åŠ¨å¯¹æ•´ä½“å½±å“è¶Šå°ã€‚ å˜å¤§åŸºçº¿ é«˜æ¸…å›¾åƒã€‚ Can you analyze the effects of a large&#x2F;small baseline? å¤§åŸºçº¿ï¼Œè¯¯å·®æ¯”è¾ƒå° What is the closest depth that a stereo camera can measure? ä½äºæœ€å¤§è§†å·®å¤„ Are you able to show mathematically how to compute the intersection of two lines (linearly and non-linearly)? ä¸‰è§’æ³•å—ï¼Ÿé—®çš„è¿™æ˜¯ã€‚çº¿æ€§çš„è¯æœ‰ä¸¤ç§ 14è®²ä¸­çš„æ–¹æ³•ï¼Œæ„å»ºä¸¤ä¸ªæŠ•å½±ç‚¹ä¹‹é—´çš„å…³ç³»ï¼Œç„¶åå‰ä¹˜æ¶ˆå»ä¸€ä¸ªï¼Œå¾—åˆ°ä¸€ä¸ªçº¿æ€§æ–¹ç¨‹ç»„ã€‚ slideä¸­çš„æ–¹æ³•ï¼Œ å†™å‡ºä¸¤ä¸ªç›¸æœºçš„æŠ•å½±æ–¹ç¨‹ï¼Œä¹‹åå‰ä¹˜å¯¹åº”çš„æŠ•å½±ç‚¹ï¼Œå¾—åˆ°æŠ•å½±ç‚¹ä¸ä¸–ç•Œåæ ‡ä¹‹é—´çš„å…³ç³»ï¼Œå› ä¸ºç›¸æœºå†…å‚å¤–å‚å·²çŸ¥ï¼Œä½¿ç”¨æœ€å°äºŒä¹˜æ±‚è§£å³å¯ã€‚ éçº¿æ€§ L-Mä¼˜åŒ–é‡æŠ•å½±è¯¯å·® What is the geometric interpretation of the linear and non-linear approaches and what error do they minimize? çº¿æ€§æ–¹æ³•ç±»ä¼¼ä¼˜åŒ–Ax&#x3D;0ï¼Œé€šè¿‡SVDæ±‚è§£ã€‚ éçº¿æ€§é€šè¿‡L-Mä¼˜åŒ–é‡æŠ•å½±è¯¯å·® Are you able to provide a definition of epipole, epipolar line and epipolar plane? æå¹³é¢æ˜¯3Dç‚¹ä¸ä¸¤ä¸ªç›¸æœºä¸­å¿ƒæ„æˆçš„å¹³é¢ã€‚æçº¿æ˜¯æå¹³é¢ä¸ä¸¤ä¸ªç›¸æœºå¹³é¢ä¹‹é—´çš„äº¤çº¿ã€‚æç‚¹æ˜¯æçº¿ä¸åŸºçº¿çš„äº¤ç‚¹ Are you able to draw the epipolar lines for two converging cameras, for a forward motion situation, and for a side-moving camera? OKï¼Œä¸»è¦æ˜¯æŠŠæå¹³é¢è§„å®šå‡ºæ¥ï¼Œæ¥ä¸‹æ¥éƒ½easyã€‚ Are you able to define stereo rectification and to derive mathematically the rectifying homographies? stereo rectificationæ˜¯å°†ä¸¤å¼ å›¾åƒé€šè¿‡æ„å»ºå•åº”çŸ©é˜µé‡æŠ•å½±åˆ°æçº¿ä¸æ‰«æçº¿å¯¹é½çš„æƒ…å†µä¸‹ How is the disparity map computed? ä¿®æ­£ç«‹ä½“å›¾åƒ å¯»æ‰¾å¯¹åº”ç‚¹ è®¡ç®—è§†å·® How can one establish stereo correspondences with subpixel accuracy? ä¿®æ­£ç«‹ä½“å›¾åƒåï¼Œå°†æœç´¢è½¬æ¢æˆä¸€ç»´æœç´¢é—®é¢˜ï¼Œæ„å»ºçª—å£ã€‚æ»‘åŠ¨çª—å£æ¯”è¾ƒä¸¤ä¸ªçª—å£ä¹‹é—´çš„å·®è·ï¼ˆNCCï¼Œç”¨äºè¡¡é‡ä¸¤å¼ å›¾åƒé—´çš„ç›¸å…³ç¨‹åº¦ï¼‰ã€‚ éœ€è¦å¦¥å–„æ—‹è½¬çª—å£å¤§å°ã€‚ å¤§çª—å£ï¼Œè¶Šå…‰æ»‘ï¼Œç‰¹å¾å°‘ å°çª—å£ï¼Œç‰¹å¾å¤šï¼Œå™ªå£°å¤šã€‚ Describe one or more simple ways to reject outliers in stereo correspondences. å”¯ä¸€æ€§ï¼ŒåŒä¸€ä¸ªç‚¹åœ¨æ¯ä¸ªç›¸æœºå¹³é¢çš„æŠ•å½±æ˜¯å”¯ä¸€çš„ï¼Œä¹Ÿå°±æ˜¯å·¦ä¾§çš„ç›¸æœºåªèƒ½å¯¹åº”å³ä¾§çš„ç›¸æœºä¸­çš„ä¸€ä¸ªç‚¹ã€‚ é¡ºåºï¼Œç‚¹åœ¨ç›¸æœºå¹³é¢ä¸­çš„æ’åˆ—é¡ºåºæ˜¯ä¸€æ ·çš„ã€‚ æ¢¯åº¦ã€‚è§†å·®æ˜¯å¹³æ»‘å˜åŒ–çš„ã€‚ Is stereo vision the only way of estimating depth information? If not, are you able to list alternative options? (make link to other lectures) ä¸æ˜¯å”¯ä¸€çš„æ–¹æ³•ï¼Œè¿˜æœ‰æ·±åº¦å­¦ä¹ çš„æ–¹æ³•ã€‚ ç¬¬å…«è®² Multiple View Geometry 2ä¸Šä¸€èŠ‚è¯´çš„æ˜¯åœ¨ç›¸æœºå†…å¤–å‚å·²çŸ¥çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å¯¹æçº¦æŸæœç´¢å¯¹åº”ç‚¹çš„å…³ç³»ï¼Œæœ€åé€šè¿‡ä¸‰è§’åŒ–å¾—åˆ°æ·±åº¦ä¿¡æ¯ã€‚è¿™ä¸€èŠ‚è¦è¯´SFMã€‚ 2-view Structure From Motion: Assumptions: none (K, T, and R are unknown). Goal: Recover simultaneously 3D scene structure and camera poses (up to scale) from two images Structure from Motion (SFM) Two variants exist: Calibrated camera(s) â‡’ ğ‘²ğŸ, ğ‘²ğŸ are known Uncalibrated camera(s) â‡’ ğ‘²ğŸ, ğ‘²ğŸ are unknown å…ˆè€ƒè™‘å†…å‚å·²çŸ¥çš„æƒ…å†µä¸‹ Scale Ambiguity é¦–å…ˆæ˜¯è¿™ä¹ˆä¸€ä¸ªæƒ…å†µï¼Œæˆ‘ä»¬æ²¡æœ‰åŠæ³•é€šè¿‡æ™®é€šçš„æ‰‹æ®µï¼Œåœ¨æ²¡æœ‰å…¶ä»–çº¦æŸçš„æƒ…å†µä¸‹ï¼Œç›´æ¥ç”±ï¼’ï¼¤ç‚¹æ¢å¤å‡ºç›¸æœºä½å§¿ï¼Œå› ä¸ºä¼šæœ‰ä¸€ä¸ªScale Ambiguityï¼Œæ‰€ä»¥åªèƒ½æ¢å¤äº”ä¸ªè‡ªç”±åº¦ã€‚ä½†æ˜¯å¦‚æœç»“åˆæçº¿çº¦æŸï¼Œå°±å¯ä»¥é€šè¿‡æœ¬è´¨çŸ©é˜µæ¢å¤å‡ºï¼²ä¸ï¼´ã€‚ è¿™é‡Œå°±å¯ä»¥æ¨å¯¼å‡ºæœ¬è´¨çŸ©é˜µçš„è¡¨è¾¾å¼äº†ã€‚ Essential Matrix The 8-point algorithm æ³¨æ„ï¼šè¿™é‡Œéƒ½æ˜¯å½’ä¸€åŒ–å¹³é¢ä¸­çš„ç‚¹ï¼Œæœ¬è´¨çŸ©é˜µéƒ½æ˜¯å¯¹å½’ä¸€åŒ–å¹³é¢ä¸Šçš„ç‚¹è¿›è¡Œæ“ä½œçš„ï¼Œå› ä¸ºæˆ‘ä»¬å·²çŸ¥ç›¸æœºçŸ©é˜µï¼Œæ‰€ä»¥å¯ä»¥ç”±åƒç´ åæ ‡æ¢å¤å‡ºæ¥å½’ä¸€åŒ–å¹³é¢åæ ‡ã€‚ è¯´å®è¯ï¼Œè¿™é‡Œæœ€ç»ˆçš„Rä¸Tä¸ºä»€ä¹ˆå«æœ‰å†…å‚ï¼Œæˆ‘æ²¡æœ‰ææ¸…æ¥šã€‚æ‰€ä»¥å¯¹äºEçš„åˆ†è§£ï¼Œå·²SLAMåå››è®²ä¸ºä¸»ï¼Œæ¨å¯¼å¦‚ä¸‹ã€‚ æœ¬è´¨çŸ©é˜µçš„åˆ†è§£https://gutsgwh1997.github.io/2020/05/26/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%86%E8%A7%A3/ å†è€ƒè™‘å†…å‚ä¸çŸ¥é“çš„æƒ…å†µä¸‹ Fundamental Matrix The 8-point Algorithm for the Fundamental Matrix Error Measures Things to remember SFM from 2 view Calibrated and uncalibrated case Proof of Epipolar Constraint 8-point algorithm and algebraic error Normalized 8-point algorithm Algebraic, directional, Epipolar line distance, Reprojection error Understanding Check Whatâ€™s the minimum number of correspondences required for calibrated SFM and why? ç†è®ºä¸Šäº”ä¸ªç‚¹ï¼Œå› ä¸ºæœ‰4nä¸ªå·²çŸ¥æ•°è§£å†³3n+5ä¸ªæœªçŸ¥æ•°ï¼Œè‡³å°‘éœ€è¦äº”ä¸ªç‚¹çš„ä¿¡æ¯ã€‚ Are you able to derive the epipolar constraint? è§åšå®¢å¯¹æå‡ ä½• Are you able to define the essential matrix? æœ¬è´¨çŸ©é˜µEï¼ˆEssiential Matrixï¼‰ï¼šåæ˜ ç©ºé—´ä¸€ç‚¹Påœ¨ä¸åŒç›¸æœºä¸‹ç›¸æœºåæ ‡ç³»ä¸­çš„è¡¨ç¤ºä¹‹é—´çš„å…³ç³»ã€‚$E&#x3D;[T_\\times]R$ Are you able to derive the 8-point algorithm? Yes How many rotation-translation combinations can the essential matrix be decomposed into? 4 Are you able to provide a geometrical interpretation of the epipolar constraint? å‘é‡P1ä¸P2è¿˜æœ‰åŸºçº¿å¿…é¡»å…±å¹³é¢ Are you able to describe the relation between the essential and the fundamental matrix? ç›¸å·®äº†ç›¸æœºå†…å‚ Why is it important to normalize the point coordinates in the 8-point algorithm? å› ä¸ºå…«ç‚¹æ³•å„å‚æ•°ä¹‹é—´æ•°é‡çº§çš„å·®å¼‚ä¼šå¯¹æœ€å°äºŒä¹˜é€ æˆå¾ˆå¤§çš„è¯¯å·®ã€‚ Describe one or more possible ways to achieve this normalization. å°†å›¾åƒçš„åæ ‡å½’ä¸€åŒ–åˆ°-1~1çš„èŒƒå›´ Are you able to describe the normalized 8-point algorithm? å…ˆåˆ©ç”¨å½’ä¸€åŒ–çš„åæ ‡è®¡ç®—å½’ä¸€åŒ–åçš„$\\hat{F}$ï¼Œåªæœ‰ä¸å½’ä¸€åŒ–çŸ©é˜µä¸€èµ·æ±‚è§£åŸºç¡€çŸ©é˜µF Are you able to provide quality metrics and their interpretation for the essential and fundamental matrix estimation? Algebraic Errorä¸Directional Erroréƒ½å¯ä»¥ç›´æ¥è¡¡é‡ï¼Œä»–ä»¬æ˜¯è¡¡é‡P1ã€P2ä»¥åŠåŸºçº¿æ˜¯å¦åœ¨åŒä¸€å¹³é¢ã€‚ ç¬¬ä¹è®² Multiple View Geometry 3Robust Structure from Motion Matched points are usually contaminated by outliers (i.e., wrong image matches). Causes of outliers are: Repetitive features changes in view point (including scale) and illumination image noise Occlusions Moving objects blur For reliable and accurate visual odometry, outliers must be removed This is the task of Robust Estimation Expectation Maximization (EM) algorithm EM is a simple method for model fitting in the presence of outliers (very noisy points or wrong data) It can be applied to all sorts of problems where the goal is to estimate the parameters of a model from the data (e.g., camera calibration, Structure from Motion, DLT, PnP, P3P, Homography, etc.) Letâ€™s review EM applied to the line fitting problem Very sensitive to initial condition This is because EM selects the initial condition by minimizing the sum of squared residuals $\\sum r_i^2$. While this is a convex function, the result is strongly influenced by a few large error values (e.g., outliers). Thus, EM converges to the wrong solution if initial condition is far from the true one Alternative options: GNC algorithm RANSAC algorithm Graduated Non-Convexity algorithm (GNC) RANSAC (RAndom SAmple Consensus) RANSAC is the standard method for model fitting in the presence of outliers (very noisy points or wrong data) It is non-deterministic: you get a different result everytime you run it It is not sensitive to the initial condition, and does not get stuck in local maxima It can be applied to all sorts of problems where the goal is to estimate the parameters of a model from the data (e.g., camera calibration, Structure from Motion, DLT, PnP, P3P, Homography, etc.) Letâ€™s review RANSAC for line fitting and see how we can use it to do Structure from Motion In order to implement RANSAC for Structure From Motion (SFM), we need three key ingredients: Whatâ€™s the model in SFM? The Essential Matrix (for calibrated cameras) or the Fundamental Matrix (for uncalibrated cameras) Alternatively, R and T Whatâ€™s the minimum number of points to estimate the model? We know that 5 points is the theoretical minimum number of points for calibrated cameras However, if we use the 8-point algorithm, then 8 is the minimum (for both calibrated or uncalibrated cameras) How do we compute the distance of a point from the model? In other words, can we define a distance metric that measures how well a point fits the model? Algebraic error 2. Directional error 3. Epipolar line distance 4. Reprojection error Ransacæ¬¡æ•°ä¸å¹²æ‰°ç‚¹æ¯”ä¾‹ä»¥åŠæ¨¡å‹éœ€è¦ç‚¹çš„ä¸ªæ•°ç›¸å…³ ä¸€äº›å…¶ä»–å·¥ä½œ Bundle Adjustment Good to know: Like in the formula, we typically assume the first camera as the world frame, but itâ€™s arbitrary Occasionally, the residual terms are weighted In order to not get stuck in local minima, the initial values of $P_i$, $R$, $ğ‘‡$ should be close to the optimum Can be minimized using Levenbergâ€“Marquardt (more robust than Gauss-Newton to local minima) Can be modified to also optimize the intrinsic parameters What is the key difference with the reprojection error minimization seen in previous lectures (03 and 07)? ç¬¬ä¸‰è®²æ˜¯é‡æŠ•å½±è¯¯å·®æ˜¯åœ¨ç›¸æœºå®šä½éƒ¨åˆ†ï¼Œæ­¤æ—¶ä¸‰ç»´ç‚¹åæ ‡ä¸å˜ï¼Œä¸æ–­ä¼˜åŒ–æ—‹è½¬ä»¥åŠå¹³ç§»ã€‚ ç¬¬ä¸ƒè®²æ˜¯ä¸‰è§’åŒ–é—®é¢˜ï¼Œæ­¤æ—¶æ—‹è½¬ä»¥åŠå¹³ç§»æ˜¯ä¸å˜çš„ï¼Œä¸æ–­ä¼˜åŒ–ä¸‰ç»´ç‚¹åæ ‡ã€‚ å› ä¸ºé‡æŠ•å½±è¯¯å·®è¾ƒå¤§æ—¶ï¼Œå¦‚æœè®¡ç®—å…¶å¹³æ–¹ä¼šæ¯”è¾ƒå¤§ï¼Œä¸åˆ©äºä¼˜åŒ–ï¼Œè¿™é‡Œé‡‡ç”¨åˆ†æ®µå‡½æ•°æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ Things to remember EM algorithm RANSAC algorithm and its application to SFM 8 vs 5 vs 1 point RANSAC, pros and cons Bundle Adjustmen Understanding Check What are the causes of outliers? Repetitive features changes in view point (including scale) and illumination image noise Occlusions Moving objects blur What effects may outliers have on VO? ä¼°è®¡å‡ºæ¥çš„é‡Œç¨‹è®¡è¯¯å·®ä¼šå¾ˆå¤§ How does EM work? What are the issues? é€šè¿‡è®¡ç®—ç‚¹åœ¨æ¨¡å‹ä¸Šçš„å¯èƒ½æ€§æ¥è¿›è¡Œ åŠ æƒï¼Œä¹‹åä¸æ–­ä¼˜åŒ–ã€‚ é—®é¢˜æ˜¯å¯¹åˆå€¼æ¯”è¾ƒæ•æ„Ÿ Why do we need RANSAC? RANSACå¯ä»¥å¾ˆå¥½çš„è§£å†³outliersï¼Œè€Œä¸”å‡†ç¡®ç‡å¾ˆé«˜ What is the theoretical maximum number of combinations to explore? $N*(N-1)&#x2F;2$ After how many iterations can RANSAC be stopped to guarantee a given success probability? $k&#x3D;\\frac{log(1-p)}{log(1-w^2)}$ï¼Œpæ˜¯æœŸæœ›å‡†ç¡®ç‡ï¼Œwæ˜¯å†…ç‚¹inlinesçš„æ¯”ä¾‹ What is the trend of RANSAC vs. iterations, vs. the fraction of outliers, vs. the number of points to estimate the model? å¤–ç‚¹æ¯”ä¾‹è¶Šå¤§ï¼Œéœ€è¦è¿­ä»£æ¬¡æ•°è¶Šå¤šï¼ŒæŒ‡æ•°å¢é•¿ã€‚ æ¨¡å‹éœ€è¦ç‚¹è¶Šå¤šï¼Œè¿­ä»£æ¬¡æ•°è¶Šå¤šã€‚ How do we apply RANSAC to the 8-point algorithm, DLT, P3P? å…«ç‚¹æ³• éšæœºé€‰å…«ä¸ªç‚¹ è®¡ç®—æ‰€æœ‰ç‚¹ä¸è¿™ä¸ªæ¨¡å‹ä¸Šçš„è·ç¦»ï¼Œå†³å®šå†…ç‚¹ä¸ªæ•° è¿­ä»£ How can we reduce the number of RANSAC iterations for the SFM problem? (1- and 2-point RANSAC) é€šè¿‡è¿åŠ¨æ¨¡å‹çš„çº¦æŸï¼Œé™ä½éœ€è¦ç‚¹çš„æ¯”ä¾‹ Bundle Adjustment. Mathematical expression and illustration. Tukey and Huber norms. BAæ˜¯åŒæ—¶ä¼˜åŒ–ä¸‰ç»´ç‚¹çš„åæ ‡ä»¥åŠç›¸æœºçš„Rä¸Tã€‚ ç¬¬åè®² Multiple View Geometry 4ğ‘›-View Structure From Motion Compute initial structure and motion using either: Hierarchical SFM Sequential SFM â†’ Visual Odometry (VO) Refine simultaneously structure and motion through BA Hierarchical SFM Sequential SFM (also called Visual Odometry (VO)) Initialize structure and motion from 2 views (bootstrapping) For each additional view Determine pose (localization) Extend structure, i.e., extract and triangulate new features (mapping) Refine structure and motion through Bundle Adjustment (BA) (optimization) VO Flow Chart Motion Estimation Monocular VO Local Optimization ##### Place Recognition VO vs. Visual SLAM Open Source Algorithms Things to remember Hierarchical SFM VO flowchart Monocular VO Stereo VO Keyframe selection Bundle adjustment vs pose-graph optimization Indirect vs direct methods Direct methods: Dense, semi-dense, and sparse formulations Popular open-source VO algorithms Understanding Check Bundle Adjustment and Pose Graph Optimization. Mathematical expressions and illustrations. Pros and cons. BAæ˜¯åŸºäºé‡æŠ•å½±è¯¯å·®ï¼Œä¼˜åŒ–ä¸‰ç»´ç‚¹åæ ‡ä»¥åŠç›¸æœºä½å§¿ã€‚è¿ç®—é‡å¤§ã€‚ Graphæ˜¯ä¼˜åŒ–ä½å§¿ä¹‹é—´çš„å…³ç³»ã€‚æ¯”å¦‚T02&#x3D;T01*T12ã€‚ Are you able to describe hierarchical and sequential SFM for monocular VO? â€‹ hierarchical SFMæ˜¯æ— åºçš„æ•°æ®ï¼Œå…ˆå®ç°ä¸¤ä¸¤ä¹‹é—´çš„å…³è”ï¼Œä¹‹åå†é€å±‚è¿›è¡Œä¸‰è§’åŒ–ï¼Œæœ€ç»ˆæ‹¼åœ¨ä¸€èµ·è¿›è¡ŒBAã€‚ â€‹ sequential SFMæ˜¯æœ‰åºçš„æ•°æ®ï¼Œè®¡ç®—ä¸¤å¸§ä¹‹é—´çš„ä½ç§»ã€‚ What are the building blocks of visual odometry and SLAM? VOçš„è¯ï¼Œç‰¹å¾æ£€æµ‹ï¼Œç‰¹å¾åŒ¹é…ï¼Œä½å§¿ä¼°è®¡ï¼Œä½å§¿ä¼˜åŒ–ï¼ŒSLAMå†åŠ ä¸€ä¸ªå›ç¯æ£€æµ‹ What are keyframes? Why do we need them and how can we select them? å…³é”®å¸§æ˜¯SLAMç³»ç»Ÿä¸­ï¼Œä¸ºäº†æå‡æ•ˆç‡è€Œé€‰å–çš„è¾ƒä¸ºç‰¹æ®Šçš„å¸§ï¼Œä»–ä»¬å¯ä»¥ä¿è¯æ—¢æœ‰è¶³å¤Ÿçš„ç‚¹æ¥è®¡ç®—ç›¸æœºä½å§¿ï¼Œä¹Ÿæœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å®Œæˆä¸‰è§’åŒ–ã€‚ ä¸€èˆ¬æ˜¯é€šè¿‡ä¸‰ç»´ç‚¹çš„å¹³å‡æ·±åº¦é™¤ä»¥ä¸¤å¸§ä¹‹é—´çš„è·ç¦»ï¼Œä¸ä¸€ä¸ªé˜ˆå€¼è¿›è¡Œæ¯”è¾ƒã€‚ Are you able to define loop closure detection? Why do we need loops? How can we detect loop closures? (make link to other lectures) å›ç¯æ£€æµ‹å°±æ˜¯å½“æœºå™¨äººç»è¿‡ä¹‹å‰èµ°è¿‡çš„åœ°æ–¹æ—¶ï¼Œåˆ¤æ–­è‡ªå·±ä¹‹å‰èµ°è¿‡ï¼Œå¹¶å¯¹å½“å‰ä½å§¿è¿›è¡Œä¼˜åŒ–ï¼Œæ¶ˆé™¤ç´¯è®¡è¯¯å·®ã€‚ å› ä¸ºé‡Œç¨‹è®¡éƒ½æœ‰ç´¯è®¡è¯¯å·®ï¼Œå› æ­¤éœ€è¦æ¶ˆé™¤ã€‚ Are you able to describe the differences between feature-based methods and direct methods? åŸºäºç‰¹å¾çš„æ–¹æ³•æ˜¯å…ˆæ£€æµ‹ç‰¹å¾ç‚¹ï¼Œå®ŒæˆåŒ¹é…ï¼Œä¹‹åè®¡ç®—ä½å§¿ã€‚ ç›´æ¥æ³•æ˜¯è®¡ç®—å…‰åº¦è¯¯å·®ï¼Œä¹‹åç›´æ¥ä¼˜åŒ–ä½å§¿ã€‚ Sparse vs semi-dense vs dense. What are their pros and cons? ç¨€ç–çš„è®¡ç®—æ›´å¿«ï¼Œæ¶ˆè€—èµ„æºæ›´å°‘ã€‚ åŠç¨ å¯†å’Œç¨ å¯†è¡¨ç°å·®ä¸å¤šã€‚ä»–ä»¬åœ¨æ¨¡ç³Šã€å°‘çº¹ç†ç­‰åœºåˆè¡¨ç°æ›´å¥½ã€‚ Are you able to provide a list of the most popular open source VO and VSLAM algorithms? å¯ä»¥","categories":[{"name":"Course","slug":"Course","permalink":"https://liuxiao916.github.io/categories/Course/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"},{"name":"Robotics","slug":"Robotics","permalink":"https://liuxiao916.github.io/tags/Robotics/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://liuxiao916.github.io/tags/Computer-Vision/"}],"author":"LiuXiao"},{"title":"Vision Algorithm for Mobile Roboticsè¯¾ç¨‹æ€»ç»“(5~6)èŠ‚","slug":"Vision-Algorithm-for-Mobile-Roboticsè¯¾ç¨‹æ€»ç»“-5-6-èŠ‚","date":"2022-02-18T04:15:56.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/18/Vision-Algorithm-for-Mobile-Roboticsè¯¾ç¨‹æ€»ç»“-5-6-èŠ‚/","link":"","permalink":"https://liuxiao916.github.io/2022/02/18/Vision-Algorithm-for-Mobile-Robotics%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93-5-6-%E8%8A%82/","excerpt":"ç¬¬äº”ç« ä¸ç¬¬å…­ç« æ˜¯åœ¨è¯´ç‰¹å¾ç‚¹çš„æ£€æµ‹ã€‚é‡ç‚¹æ˜¯Harrisè§’ç‚¹æ£€æµ‹ä»¥åŠSIFTç‰¹å¾ç‚¹æ£€æµ‹ä¸­çš„ç»†èŠ‚ã€‚","text":"ç¬¬äº”ç« ä¸ç¬¬å…­ç« æ˜¯åœ¨è¯´ç‰¹å¾ç‚¹çš„æ£€æµ‹ã€‚é‡ç‚¹æ˜¯Harrisè§’ç‚¹æ£€æµ‹ä»¥åŠSIFTç‰¹å¾ç‚¹æ£€æµ‹ä¸­çš„ç»†èŠ‚ã€‚ Point Feature Detection and Matching â€“ Part 1Filters for Feature detection Goal: reduce amount of data to process in later stages, discard redundancy to preserve only what is useful (leads to lower bandwidth and memory storage) Edge detection (we have seen this already; edges can enable line or shape detection) Template matching Keypoint detection Filters for Template Matching Template Matching will only work if scale, orientation, illumination, and, in general, the appearance of the template (including anything in background) and the object to detect are very similar. Point-feature extraction What features are repeatable and distinctive? è¿™ä¸ªå®šä¹‰å¾ˆæœ‰æ„æ€ Corner Detection Key observation: in the region around a corner, image gradient has two or more dominant directions Corners are repeatable and distinctive The Harris Corner detector MçŸ©é˜µå¾ˆé‡è¦ï¼Œä»ä¸­å°±èƒ½å¾—åˆ°æˆ‘ä»¬éœ€è¦çš„ä¿¡æ¯ã€‚å¯ä»¥ä»ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡åˆ†æå‡ºSSDçš„å˜åŒ–ç¨‹åº¦ã€‚ Harris workflow Harris Detector: Some Properties Repeatability: How does the Harris detector behave with geometric and photometric changes, i.e. can it re-detect the same corners when the image exhibits changes in Rotation, Scale (zoom), View-point, Illumination ? Summary Filters as templates Correlation as a scalar product Similarity metrics: NCC (ZNCC), SSD (ZSSD), SAD (ZSAD), Census Transform Point feature detection Properties and invariance to transformations Challenges: rotation, scale, view-point, and illumination changes Extraction Moravec Harris and Shi-Tomasi Invariance to rotation, scale, illumination changes Understanding Check Explain what is template matching and how it is implemented? whatï¼šæ¨¡æ¿åŒ¹é…å°±æ˜¯é€šè¿‡ç°æœ‰çš„æ¨¡æ¿å»ä¸å›¾ç‰‡è¿›è¡Œæ¯”è¾ƒæ‰¾å‡ºå›¾ä¸­æ‰€åŒ¹é…çš„å›¾åƒ howï¼šæ¨¡æ¿ä»å›¾åƒå·¦ä¸Šè§’å¼€å§‹æ»‘åŠ¨ï¼Œä¸€ç›´åˆ°å³ä¸‹è§’ã€‚ä¹‹åè®¡ç®—æ¨¡æ¿ä¸å½“å‰åŒºåŸŸçš„ç›¸å…³ç¨‹åº¦ï¼Œé€šè¿‡ä¸€äº›è¡¡é‡æ–¹æ³•æ¥ç¡®å®šå½“å‰åŒºåŸŸä¸æ¨¡æ¿æ˜¯ä¸æ˜¯ç›¸ä¼¼ã€‚NCCè¶Šæ¥è¿‘1è¶ŠåŒ¹é…ã€‚SSDä¸SADè¶Šæ¥è¿‘0è¶ŠåŒ¹é…ã€‚ Explain what are the limitations of template matching? Can you use it to recognize cars? æ²¡æœ‰ä¿è¯å°ºåº¦ï¼ˆscaleï¼‰ã€æ—‹è½¬ï¼ˆorientationï¼‰ã€å…‰ç…§ï¼ˆilluminationï¼‰ä¸å˜æ€§ã€‚åŒæ—¶è¦ä¿è¯æ¨¡æ¿ä¸å¾…æ£€æµ‹ç‰©ä½“ä¸€æ¨¡ä¸€æ ·ã€‚ä¸èƒ½ç”¨æ¥æ£€æµ‹è½¦ã€‚è½¦æœ‰å¾ˆå¤šç§ç±»å‹ï¼Œä¸”è½¦åœ¨æœ‰ç§»åŠ¨çš„æ—¶å€™ï¼Œå¯èƒ½ä¼šå°ºåº¦ã€æ—‹è½¬ç­‰æ¡ä»¶ä¼šå‘ç”Ÿå˜åŒ–ã€‚ Illustrate the similarity measures: SSD, SAD, NCC, and Census transform? SSD, SAD, NCCéƒ½æ˜¯æŒ‰ç…§å…¬å¼è®¡ç®—æ¨¡æ¿ä¸å¾…åŒ¹é…åŒºåŸŸä¹‹é—´æ¯ä¸ªåƒç´ çš„å…³ç³»ï¼Œæœ€ç»ˆå¾—åˆ°ç›¸åº”çš„ç»“æœã€‚ census transformæ˜¯å…ˆæŒ‰ç…§å›¾åƒå—æ¯ä¸ªåƒç´ ä¸ä¸­å¿ƒåƒç´ çš„å…³ç³»å°†å…¶ç¼–ç æˆä¸€ä¸²01çš„æ•°æ®ï¼Œç„¶åè®¡ç®—ä¸¤ä¸²æ•°æ®ä¹‹é—´çš„æ±‰æ˜è·ï¼Œè¶Šå°è¡¨æ˜è¶ŠåŒ¹é…ã€‚ What is the intuitive explanation behind SSD and NCC? å°†æ¨¡æ¿ä¸å¾…åŒ¹é…å›¾åƒå—è§†ä¸ºä¸¤ä¸ªå‘é‡ï¼Œå‘é‡è¶Šæ¥è¿‘è¯´æ˜è¶ŠåŒ¹é…ã€‚ è‡ªå·±é—®è‡ªå·±çš„ï¼Œä»€ä¹ˆæ˜¯ç‰¹å¾ï¼Ÿ ä¸å‘¨å›´åƒç´ æœ‰ç€æ˜¾è‘—å˜åŒ–çš„åƒç´ å—ã€‚ Explain what are good features to track? In particular, can you explain what are corners and blobs together with their pros and cons? How is their localization accuracy. å¥½çš„ç‰¹å¾éœ€è¦ä¸¤ä¸ªæ€§è´¨ é‡å¤æ€§ï¼ˆrepetitionï¼‰ï¼šåŒä¸€ä¸ªç‰¹å¾å¯åœ¨ä¸åŒçš„ç…§ç‰‡ä¸­æ£€æµ‹å‡ºæ¥ ç‹¬ç‰¹æ€§ï¼ˆdistinctiveï¼‰ï¼šæ¯ä¸ªç‰¹å¾çš„æè¿°å­ä¸åŒã€‚ä¸åŒç…§ç‰‡ä¸­åŒä¸€ä¸ªç‰¹å¾æœ‰ç›¸åŒçš„æè¿°å­ï¼ŒåŒä¸€ä¸ªå›¾ç‰‡ä¸­æ¯ä¸ªç‰¹å¾çš„æè¿°å­éƒ½ä¸å…¶ä»–ç‰¹å¾ä¸åŒã€‚æè¿°å­éœ€è¦å…·æœ‰å‡ ä½•ä»¥åŠå…‰ç…§ä¸å˜æ€§ã€‚ï¼ˆå°ºåº¦ã€æ—‹è½¬ã€è§†è§’ã€å…‰ç…§ï¼‰ Cornersï¼šæ˜¯ä¸¤ä¸ªæˆ–å¤šä¸ªè¾¹çš„äº¤ç‚¹ã€‚ä¼˜ç‚¹æ˜¯æ¯”blobå®šä½æ›´å‡†ç¡®ï¼Œç¼ºç‚¹æ˜¯æ¯”blobæ›´éš¾ä»¥åŒºåˆ†ï¼ˆless distinctiveï¼‰ã€‚ blobï¼šæ˜¯ä¸€ç§å›¾åƒç±»å‹ï¼Œé¦–å…ˆä»–ä¸æ˜¯cornerï¼Œç„¶åä»–ä¸å‘¨å›´çš„åƒç´ æœ‰æ˜¾è‘—ä¸åŒã€‚ä»–çš„ç¼ºç‚¹æ˜¯æ¯”corneréš¾ä»¥å®šä½ï¼ˆless localization accuracyï¼‰ï¼Œä¼˜ç‚¹æ˜¯æ›´æœ‰åŒºåˆ†åº¦ï¼ˆmore distinctive than cornersï¼‰ï¼Œæœ‰åŠ©äºåœºæ™¯è¯†åˆ«ã€‚ Explain the Harris corner detector? In particular: Use the Moravec definition of corner, edge and flat region. æ¯”è¾ƒçª—å£æ»‘åŠ¨ï¼ˆwindows shiftï¼‰ä¹‹åçš„åƒç´ å˜åŒ–ï¼ˆsum of squared difference, SSDï¼‰ cornerï¼šmore distinctive than corners edgeï¼šno change along the edge direction no intensity change Show how to get the second moment matrix from the definition of SSD and first order approximation (show that this is a quadratic expression) and what is the intrinsic interpretation of the second moment matrix using a paraboloid and using an ellipseï¼Ÿ $$SSD(\\Delta x,\\Delta y)&#x3D;\\sum_{x,y \\in \\Omega}(I(x,y)-I(x+\\Delta x,y+\\Delta y))^2\\\\&#x3D;\\sum_{x,y \\in \\Omega}(I(x,y)-I(x,y)-I_x(x,y)\\Delta x-I_y(x,y)\\Delta y)^2 \\\\&#x3D;\\sum_{x,y \\in \\Omega}(I_x(x,y)\\Delta x+I_y(x,y)\\Delta y)^2&#x3D;\\sum_{x,y \\in \\Omega}\\begin{bmatrix}\\Delta x&amp;\\Delta y\\end{bmatrix}\\begin{bmatrix}I_x^2 &amp; I_xI_y \\\\ I_xI_y &amp; I_y^2\\end{bmatrix}\\begin{bmatrix}\\Delta x \\\\ \\Delta y\\end{bmatrix}\\\\&#x3D;\\begin{bmatrix}\\Delta x&amp;\\Delta y\\end{bmatrix}\\begin{bmatrix}\\sum I_x^2 &amp; \\sum I_xI_y \\\\ \\sum I_xI_y &amp; \\sum I_y^2\\end{bmatrix}\\begin{bmatrix}\\Delta x \\\\ \\Delta y\\end{bmatrix}$$ Mæ˜¯ä¸€ä¸ªå¯¹ç§°é˜µï¼Œå¯ä»¥è¿›è¡Œ$S &#x3D; Q\\Lambda Q^T$åˆ†è§£ï¼Œå…¶ä¸­Qçš„åˆ—å‘é‡æ˜¯ç‰¹å¾å‘é‡ï¼Œä»£è¡¨æ¤­åœ†çš„è½´çš„æ–¹å‘ï¼Œç‰¹å¾å€¼å†³å®šè½´çš„é•¿çŸ­ï¼Œç‰¹å¾å€¼è¶Šå¤§ï¼Œè½´è¶ŠçŸ­ï¼Œçƒå¾„è¶Šå°ï¼Œä¸Šå‡è¶Šå¿«ï¼Œæ¢¯åº¦è¶Šå¤§ã€‚ What is the M matrix like for an edge, for a flat region, for an axis-aligned (90-degree) corner and for a non-axis aligned corner? edgeåªæœ‰ä¸€ä¸ªç‰¹å¾å€¼å¤§ï¼Œflatæ²¡æœ‰ç‰¹å¾å€¼å¤§ï¼Œcornerä¸¤ä¸ªç‰¹å¾å€¼å¤§ã€‚é€šè¿‡ç‰¹å¾å‘é‡åŒºåˆ† axis-aligned (90-degree) corner and for a non-axis aligned corner What do the eigenvalues of M reveal? ç‰¹å¾å€¼è¶Šå¤§ï¼Œè½´è¶ŠçŸ­ï¼Œçƒå¾„è¶Šå°ï¼Œä¸Šå‡è¶Šå¿«ï¼Œæ¢¯åº¦è¶Šå¤§ã€‚è¯´æ˜è¿™ä¸ªæ–¹å‘ä¸Šåƒç´ å€¼çš„å˜åŒ–æ˜æ˜¾ã€‚ Can you compare Harris detection with Shi-Tomasi detection? $$Harris:R &#x3D; \\lambda_1 \\lambda_2-k(\\lambda_1+\\lambda_2)^2&#x3D;det(M)-k(trace(M))^2\\\\Shi-Tomasi: R&#x3D;min(\\lambda_1,\\lambda_2)$$ Can you explain whether the Harris detector is invariant to illumination or scale changes? Is it invariant to view point changes? invariant to illumination. å› ä¸ºåƒç´ é—´çš„æ¢¯åº¦ä¸å˜ ä¸å…·æœ‰å°ºåº¦ä¸å˜æ€§ï¼Œå°ºåº¦ä¼šæ”¹å˜SSDï¼Œå³æ”¹å˜æ¢¯åº¦ã€‚ ä¸ä¸€å®šå…·æœ‰è§†è§’ä¸å˜æ€§ã€‚å› ä¸ºè§†è§’å˜äº†ä¹‹åï¼Œä¸€ä¸ªcornerå¯èƒ½å°±ä¸æ˜¯corneräº† What is the repeatability of the Harris detector after rescaling by a factor of 2? 18% Point Feature Detection and Matching â€“ Part 2Automatic Scale SelectionScale changesHow can we match image patches corresponding to the same feature but belonging to images taken at different scales? Possible solution: rescale the patch Scale search is time consuming (needs to be done individually for all patches in one image) Complexity is $(NS)^2$ assuming $N$ features per image and $S$ rescalings per feature Solution: automatic scale selection: automatically assign each feature its own â€œscaleâ€ (i.e., size) Automatic Scale Selectionä¸€ç§å°ºåº¦é€‰æ‹©å‡½æ•°ï¼Œå˜é‡æ˜¯$(x,y,\\sigma)$ï¼Œæ¨ªè½´æ˜¯å›¾åƒå—çš„å¤§å°ã€‚å¯ä»¥è®¤ä¸ºåœ¨æå€¼ç‚¹å¤„ï¼Œä¸¤ä¸ªå›¾åƒå—æ˜¯ç›¸å¯¹åº”çš„ï¼Œå³åœ¨ä¸åŒå°ºåº¦ä¸‹ä»£è¡¨ç›¸åŒåŒºåŸŸã€‚ Feature descriptors Feature Descriptor Invariance The ideal feature descriptor should be invariant to geometric changes: rotation, scale, view point photometric changes: illumination Most feature methods are designed to be invariant to 2D translation, 2D rotation, Scale Some of them can also handle View-point changes (e.g., SIFT &amp; LIFT work with up to 50 degrees of viewpoint changes) Affine illumination changes HOG descriptor (Histogram of oriented gradients) è¿™ä¸ªä¸œè¥¿æœ‰äº›å‰å®³ï¼Œä»–ä½¿ç”¨Harrisè§’ç‚¹æ£€æµ‹ä¸­ä½¿ç”¨çš„MçŸ©é˜µï¼Œç”¨å…¶ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡å†³å®šçš„æ¤­åœ†ä¸­çš„åŒºåŸŸã€‚ç»è¿‡å½’ä¸€åŒ–åå¯ä»¥å½¢æˆç›¸åŒè§†è§’çš„åœ†å½¢åŒºåŸŸã€‚ ç¨å¾®æ³¨æ„ä¸€ä¸‹è¿™ä¸ªæ’å€¼å…¬å¼ï¼Œå› ä¸ºI(1,1)ç¦»å¾—æœ€è¿œï¼Œæ‰€ä»¥æ’å€¼æ—¶å çš„æ¯”ä¾‹ä¹Ÿè¶Šå°ã€‚ Disadvantage of Patch Descriptors Disadvantage of patch descriptors: If the warp is not estimated accurately, very small errors in rotation, scale, and viewpoint will affect matching score significantly Computationally expensive (need to unwarp every patch) The SIFT blob detector and descriptorSIFT Descriptor SIFT Detector SIFTï¼šRecap SIFT: Scale Invariant Feature Transform An approach to detect and describe regions of interest in an image. SIFT detector &#x3D; DoG detector SIFT features are invariant to 2D rotation, and reasonably invariant to rescaling, viewpoint changes (up to 50 degrees), and illumination It runs in real-time but expensive (10 Hz on an i7 laptop) The expensive steps are the scale detection and descriptor extraction Feature Matching Other corner and blob detectors and descriptors Summary Similarity metrics: NCC (ZNCC), SSD (ZSSD), SAD (ZSAD), Census Transform Point feature detection Properties and invariance to transformations Challenges: rotation, scale, view-point, and illumination changes Extraction Moravec Harris and Shi-Tomasi Rotation invariance Automatic Scale selection Descriptor Intensity patches Canonical representation: how to make them invariant to transformations: rotation, scale, illumination, and viewpoint (affine) Better solution: Histogram of oriented gradients: SIFT descriptor Matching (Z)SSD, SAD, NCC, Hamming distance (last one only for binary descriptors) ratio 1st &#x2F;2nd closest descriptor Depending on the task, you may want to trade off repeatability and robustness for speed: approximated solutions, combinations of efficient detectors and descriptors Fast corner detector: FAST; Keypoint descriptors faster than SIFT: SURF, BRIEF, ORB, BRISK Understanding Check How does automatic scale selection work? æ„é€ äº†ä¸€ä¸ªå’Œå°ºåº¦æœ‰å…³çš„å‡½æ•°ï¼Œç„¶åä»£å…¥ä¸åŒå°ºåº¦çš„è¿›è¡Œè®¡ç®—ï¼Œå¯»æ‰¾æå€¼ç‚¹ã€‚åŒä¸€æå€¼ç‚¹ä»£è¡¨ä¸åŒå°ºåº¦ä¸‹çš„å›¾ç‰‡çš„åŒä¸€ä½ç½®ã€‚ What are the good and the bad properties that a function for automatic scale selection should have or not have? æå€¼ç‚¹è¿‡äºæ¥è¿‘ï¼Œæå€¼ç‚¹å¤„æ¢¯åº¦å°ã€‚ å¥½çš„å‡½æ•°éœ€è¦å‰§çƒˆçš„å¼ºåº¦å˜åŒ–ï¼Œä¾¿äºè¯†åˆ«ã€‚ How can we implement scale invariant detection efficiently? (show that we can do this by resampling the image vs rescaling the kernel). reshape kernelæ›´å¥½ï¼Œreshape imageè®¡ç®—é‡æ›´å¤§ã€‚ What is a feature descriptor? (patch of intensity value vs histogram of oriented gradients). How do we match descriptors? æè¿°å­å¯èƒ½æ˜¯å¤šç§å½¢å¼ï¼Œæ¯”å¦‚ä¸€å—intensityä¿¡æ¯ï¼Œæˆ–è€…æ˜¯æ¢¯åº¦æ–¹å‘çš„ç›´æ–¹å›¾ï¼ˆHOGï¼‰ï¼Œç”¨äºåŒ¹é…åœ¨ä¸åŒå›¾åƒä¸­çš„åŒä¸€ç‰¹å¾ç‚¹ã€‚ é€šè¿‡è®¡ç®—æè¿°å­ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼ˆè·ç¦»ï¼‰æ¥å®ŒæˆåŒ¹é…ã€‚ How is the keypoint detection done in SIFT and how does this differ from Harris? Harrisä¸»è¦æ˜¯é€šè¿‡æ£€æµ‹å›¾åƒxä¸yæ–¹å‘æ¢¯åº¦ï¼Œå®Œæˆå¯¹cornerçš„æ£€æµ‹ã€‚SIFTæ˜¯é€šè¿‡DoFæ£€æµ‹ä¸åŒå°ºåº¦ä¸‹çš„è¾¹ç¼˜ã€‚ How does SIFT achieve orientation invariance? SIFTåœ¨è®¡ç®—æè¿°å­ä¹‹å‰ä¼šå…ˆè®¡ç®—ç‰¹å¾ç‚¹æ–¹å‘ï¼Œç„¶åå°†åæ ‡ç³»æ—‹è½¬åˆ°ç‰¹å¾ç‚¹æ–¹å‘è®¡ç®—æè¿°å­ï¼Œä¿è¯æ—‹è½¬ä¸å˜æ€§ã€‚ How is the SIFT descriptor built? åœ¨4*4çš„å¤§ç½‘æ ¼ä¸­ï¼Œå¯¹æ¯ä¸ªå¤§ç½‘æ ¼å†…çš„16ä¸ªåƒç´ è®¡ç®—æ¢¯åº¦æ–¹å‘ä¸å¼ºåº¦ï¼Œç„¶åè®¡ç®—æ¯ä¸ªå¤§ç½‘æ ¼çš„æ¢¯åº¦æ–¹å‘ç›´æ–¹å›¾ï¼Œä¸€èˆ¬ä¸º8ä½ï¼Œæ¯ä¸€ä½ä»£è¡¨45åº¦è§’ã€‚æœ€åå¾—åˆ°é•¿åº¦ä¸º4*4*8çš„æè¿°å­ã€‚ What is the repeatability of the SIFT detector after a rescaling of 2? And for a 50 degrees viewpoint change? éƒ½è¿˜ä¸é”™ Illustrate the 1st to 2nd closest ratio of SIFT detection: whatâ€™s the intuitive reasoning behind it? Where does the 0.8 factor come from? å› ä¸ºè¿‡é«˜çš„ç»´åº¦å¯èƒ½å¯¼è‡´å‘é‡ä¹‹é—´çš„æ¬§å¼è·ç¦»æ¯”è¾ƒæ¥è¿‘ã€‚è¿™ä¸ªè¦æ±‚æ˜¯ä¸ºäº†ä¿è¯è·ç¦»æœ€å°çš„æè¿°å­æ˜¾è‘—æ¥è¿‘äºå¾…åŒ¹é…çš„æè¿°å­ã€‚ How does the FAST detector work? What are its pros and cons compared with Harris? ç•¥","categories":[{"name":"Course","slug":"Course","permalink":"https://liuxiao916.github.io/categories/Course/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"},{"name":"Robotics","slug":"Robotics","permalink":"https://liuxiao916.github.io/tags/Robotics/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://liuxiao916.github.io/tags/Computer-Vision/"}],"author":"LiuXiao"},{"title":"Ubuntu QTç¨‹åºæ‰“åŒ…appimage","slug":"Ubuntu-QTç¨‹åºæ‰“åŒ…appimage","date":"2022-02-17T12:27:00.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/17/Ubuntu-QTç¨‹åºæ‰“åŒ…appimage/","link":"","permalink":"https://liuxiao916.github.io/2022/02/17/Ubuntu-QT%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85appimage/","excerpt":"åœ¨ä¹‹å‰ç”¨qtåšçš„ä¸€ä¸ªé¡¹ç›®éœ€è¦å°†å¼€å‘å¥½çš„releaseæ–‡ä»¶æ‰“åŒ…æˆappimageå¯æ‰§è¡Œæ–‡ä»¶ï¼Œè®°å½•ä¸€ä¸‹è¿‡ç¨‹ä»¥åŠé‡åˆ°çš„å‘ã€‚","text":"åœ¨ä¹‹å‰ç”¨qtåšçš„ä¸€ä¸ªé¡¹ç›®éœ€è¦å°†å¼€å‘å¥½çš„releaseæ–‡ä»¶æ‰“åŒ…æˆappimageå¯æ‰§è¡Œæ–‡ä»¶ï¼Œè®°å½•ä¸€ä¸‹è¿‡ç¨‹ä»¥åŠé‡åˆ°çš„å‘ã€‚ å·¥å…·ä¸‹è½½ linuxdeployqthttps://github.com/probonopd/linuxdeployqt/releases patchelfhttps://nixos.org/releases/patchelf/patchelf-0.9/patchelf-0.9.tar.gz appimagetoolhttps://github.com/AppImage/AppImageKit/releases å·¥å…·å®‰è£…linuxdeployqt1234sudo mv linuxdeployqt-continuous-x86_64.AppImage linuxdeployqtchmod 777 linuxdeployqtsudo mv ./linuxdeployqt /usr/local/binsudo linuxdelpoyqt --version patchelf1234cd patchelf-0.9./configuremakesudo make install appimagetool123sudo mv appimagetool-x86_64.AppImage appimagetoolchmod 777 appimagetoolsudo mv ./appimagetool /usr/local/bin ç¨‹åºæ‰“åŒ…åˆ›å»ºæ–‡ä»¶å¤¹æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹ï¼Œå…¶ä¸­binæ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶ä¸ºQTåœ¨releaseæ¨¡å¼ä¸‹ç”Ÿæˆçš„å¯æ‰§è¡Œæ–‡ä»¶ã€‚libæ–‡ä»¶å¤¹ä¸­ä¸ºç¨‹åºçš„ä¾èµ–åº“ã€‚ program.destopï¼ˆæ²¡çœ‹å‡ºæ¥æœ‰ä»€ä¹ˆå…·ä½“ä½œç”¨ï¼Œä½†æ²¡æœ‰.destopæ–‡ä»¶ä¼šæŠ¥é”™ï¼‰ 1234567891011[Desktop Entry]Version=1.0Name=appDesignerExec=Terminal=falseType=ApplicationCategories=Development;Icon=programStartupNotify=true Name[en_US]=program.desktop program.pngä¸ºå›¾æ ‡ å¼€å§‹æ‰“åŒ…^112cd /home/liuxiao/code/Kim_Lab/APP/usr/binlinuxdeployqt program -appimage è¿™æ—¶å€™ä¼šç”Ÿæˆä¸€ä¸ªAppRunï¼Œæ­£å¸¸åº”è¯¥å¯ä»¥ç›´æ¥åŒå‡»å®ƒè¿è¡Œç¨‹åºäº†ã€‚ 1appimagetool APP (APPæ˜¯æ–‡ä»¶å¤¹å)ï¼Œæ‰“åŒ…æˆä¸€ä¸ª.appimageæ–‡ä»¶ã€‚å¤§åŠŸå‘Šæˆã€‚ å¸¸è§é—®é¢˜ä¾èµ–soæ–‡ä»¶çš„æå–1ldd program | awk &#x27;&#123;print $3&#125;&#x27; | xargs -i cp -L &#123;&#125; path å…¶ä¸­programæ˜¯å¯æ‰§è¡Œæ–‡ä»¶ï¼Œpathæ˜¯ä¿å­˜è·¯å¾„ qmakeè·¯å¾„é—®é¢˜1ERROR: qmake not found on the $PATH ä½¿ç”¨qtchooserå®‰è£…qmakeï¼Œè·¯å¾„ä¸ºqmakeæ‰€åœ¨è·¯å¾„ã€‚ 12qtchooser -install qt5.12 ./Qt5.12.12/5.12.12/gcc_64/bin/qmakeexport QT_SELECT=qt5.12 å‚è€ƒ","categories":[{"name":"Tool","slug":"Tool","permalink":"https://liuxiao916.github.io/categories/Tool/"}],"tags":[{"name":"Qt","slug":"Qt","permalink":"https://liuxiao916.github.io/tags/Qt/"}],"author":"LiuXiao"},{"title":"Vision Algorithm for Mobile Roboticsè¯¾ç¨‹æ€»ç»“(1~4)èŠ‚","slug":"Vision-Algorithm-for-Mobile-Roboticsè¯¾ç¨‹æ€»ç»“-1-4-èŠ‚","date":"2022-02-15T12:51:56.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/15/Vision-Algorithm-for-Mobile-Roboticsè¯¾ç¨‹æ€»ç»“-1-4-èŠ‚/","link":"","permalink":"https://liuxiao916.github.io/2022/02/15/Vision-Algorithm-for-Mobile-Robotics%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93-1-4-%E8%8A%82/","excerpt":"Introduction to Computer Vision and Visual Odometryè¿™é—¨è¯¾æ˜¯ETHZçš„muzzaæ•™æˆçš„ï¼Œè¯¾ç¨‹è®¾è®¡å¾ˆæ£’ï¼Œä¸Šå®Œå¯ä»¥è‡ªå·±æ‰‹å†™ä¸€ä¸ªVOï¼Œç‰¹æ­¤è®°å½•ä¸€ä¸‹ã€‚ ç¬¬ä¸€ç« æ˜¯ç®€ä»‹ï¼Œç¬¬äºŒç« æ˜¯ç›¸æœºæ¨¡å‹ä¸é€è§†æŠ•å½±ï¼Œç¬¬ä¸‰ç« æ˜¯ç›¸æœºæ ‡å®šä¸PnPé—®é¢˜ï¼Œç¬¬å››ç« æ˜¯å›¾åƒçš„ä¸€äº›æ»¤æ³¢ä»¥åŠè¾¹ç¼˜æ£€æµ‹ã€‚","text":"Introduction to Computer Vision and Visual Odometryè¿™é—¨è¯¾æ˜¯ETHZçš„muzzaæ•™æˆçš„ï¼Œè¯¾ç¨‹è®¾è®¡å¾ˆæ£’ï¼Œä¸Šå®Œå¯ä»¥è‡ªå·±æ‰‹å†™ä¸€ä¸ªVOï¼Œç‰¹æ­¤è®°å½•ä¸€ä¸‹ã€‚ ç¬¬ä¸€ç« æ˜¯ç®€ä»‹ï¼Œç¬¬äºŒç« æ˜¯ç›¸æœºæ¨¡å‹ä¸é€è§†æŠ•å½±ï¼Œç¬¬ä¸‰ç« æ˜¯ç›¸æœºæ ‡å®šä¸PnPé—®é¢˜ï¼Œç¬¬å››ç« æ˜¯å›¾åƒçš„ä¸€äº›æ»¤æ³¢ä»¥åŠè¾¹ç¼˜æ£€æµ‹ã€‚ ç¬¬ä¸€è®² Introduction to Computer Vision and Visual OdometryIntroductionè¿™ä¸€èŠ‚ä¸»è¦ä»‹ç»äº†ä»€ä¹ˆæ˜¯VOã€‚ VO overviewå®šä¹‰ï¼šVO is the process of incrementally estimating the pose of the vehicle by examining the changes that motion induces on the images of its onboard cameras å‡è®¾ï¼š Sufficient illumination in the environment Dominance of static scene over moving objects Enough texture to allow apparent motion to be extracted Sufficient scene overlap between consecutive frames VO&amp;VSLAM&amp;SFM SFM is more general than VO and tackles the problem of 3D reconstruction and 6DOF pose estimation from unordered image sets VO focuses on estimating the 6DoF motion of the camera sequentially (as a new frame arrives) and in real time VO fucus on incremental estimation and guarantees local consistency (i.e., estimated trajectory is locally correct, but not globally, i.e. from the start to the end) Visual SLAM &#x3D; visual odometry + loop detection &amp; closure and guarantees global consistency (the estimated trajectory is globally correct, i.e. from the start to the endï¼‰ VO Flow ChartVO computes the camera path incrementally (pose after pose) Understanding Check Provide a definition of Visual Odometry? Explain the most important differences between VO, VSLAM, and SFM? VO è¾“å…¥å›¾åƒæ˜¯åºåˆ— ä¸»è¦æ˜¯ä½å§¿ä¼°è®¡ VSLAM è¾“å…¥å›¾åƒæ˜¯åºåˆ— VSLAMä¸VOç›¸æ¯”ï¼Œéœ€è¦ä¿è¯å…¨å±€ä¸€è‡´æ€§ï¼Œå³è€ƒè™‘å›ç¯ SFM è¾“å…¥å›¾åƒæ˜¯æ— åºçš„ ä¸“æ³¨äºä¸‰ç»´é‡å»º What assumptions does VO rely on? Illustrate the flow chart of VO? ä¸»è¦åˆ†ä¸ºå‰ç«¯å’Œåç«¯ï¼Œå‰ç«¯éƒ¨åˆ†ç”¨äºä¼°è®¡ä¸¤å¸§ä¹‹é—´çš„ä½å§¿ï¼Œåç«¯ç”¨äºä¼˜åŒ–ä½å§¿ã€‚ ç¬¬äºŒè®² Image Formation: perspective projection and camera modelsIntroductionè¿™ä¸€è®²çš„é‡ç‚¹æ˜¯ç›¸æœºæ¨¡å‹ï¼Œé‡ç‚¹æ˜¯å…³æ³¨é€è§†æ¨¡å‹ä»¥åŠç•¸å˜æ¨¡å‹ã€‚ Image FormationEffects of the Aperture Sizeï¼ˆå…‰åœˆï¼‰ A large aperture makes the image blurry because a cone of light is let through from each world point Shrinking the aperture makes the image sharper The ideal aperture is a pinhole that only lets through one ray of light from each world point Focal length (ç„¦è·) A thin converging lens focuses light onto the film satisfying two properties: Rays passing through the Optical Center are not deviated All rays parallel to the Optical Axis converge at the Focal Point For a given point on the object, there is a specific distance between the lens and the film, at which the object appears in focus in the image Other points project to a blur circle in the image The blur circle has radius: $R&#x3D;L\\delta&#x2F;(2e)$ To capture a sharp image, we must adjust the camera settings such that R remains smaller than the 1 pixel The Pin-hole approximation $Z\\gg f$ and $Z\\gg L$ is known as Pinhole Approximation The relation between the image and object becomes:$x &#x3D; -fX&#x2F;Z$ This is called Perspective Projectionï¼ˆé€è§†æŠ•å½±ï¼‰ Other camera parametersFocus and Depth of Field Depth of Field is the distance between the nearest and farthest objects in a scene that appear acceptably sharp in an image A smaller aperture increases the depth of field but reduces the amount of light into the camera: recall the definition of blur circle (it reduces with aperture) Field of VIew (FOV) FOV is the angular portion of 3D scene seen by the camera As focal length $f$ gets smaller, image becomes more wide angle As focal length $f$ gets larger, image becomes more narrow angle Relation between field of view, $\\theta$, image size, $W$, and focal length, $f$ : $f &#x3D; \\frac{W}{2}[tan\\frac{\\theta}{2}]^{-1}$ Digital cameraDigital Image In a digital camera the film is an array of photodiodes (CCD or CMOS) that convert photons (light energy) into electrons Pixel Intensity with 8 bits ranges between [0,255] Color sensing in digital cameras(äº†è§£) Perspective camera modelPerspective Camera For convenience, the image plane is usually represented in front of the lens, ğ‘ªğ‘ª, such that the image preserves the same orientation (i.e. not flippedï¼‰ From World to Pixel coordinatesè¿™é‡Œæœ‰ä¸€ç‚¹å¾ˆé‡è¦ï¼Œçœ‹å›¾ç‰‡ä¸­çš„ç»¿çº¿ï¼Œç›¸æœºåæ ‡ç³»åˆ°ä¸–ç•Œåæ ‡ç³»çš„è½¬æ¢å…³ç³»ï¼Œå¯ä»¥å°†ä¸–ç•Œåæ ‡ç³»ä¸­ç‚¹çš„åæ ‡è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»ã€‚ Perspective ProjectionCamera to image Image to pixel Homogeneous Coordinatesé½æ¬¡åæ ‡ World to pixel Normalized image coordinates å½’ä¸€åŒ–å¹³é¢ä¹˜ä»¥ç„¦è·få°±å¯ä»¥è½¬æ¢æˆæˆåƒå¹³é¢ã€‚ Lens distortionRadial Distortion å¾„å‘ç•¸å˜ The standard model of radial distortion is a transformation from the ideal (non-distorted) coordinates (u,v) to the real (distorted) coordinates ($u_d$, $v_d$) For a given non distorted image point (u,v) , the amount of distortion is a nonlinear function of its distance $r$ from the principal point. For most lenses, this simple quadratic model of radial distortion is sufficient: $$\\begin{gathered}{\\left[\\begin{array}{l}u_{d} \\\\v_{d}\\end{array}\\right]&#x3D;\\left(1+k_{1} r^{2}\\right)\\left[\\begin{array}{l}u-u_{0} \\\\v-v_{0}\\end{array}\\right]+\\left[\\begin{array}{l}u_{0} \\\\v_{0}\\end{array}\\right]} \\\\r^{2}&#x3D;\\left(u-u_{0}\\right)^{2}+\\left(v-v_{0}\\right)^{2}\\end{gathered}$$ Tangential Distortion åˆ‡å‘ç•¸å˜ Radial Distortion: Depending on the amount of distortion (an thus on the camera field of view), higherorder terms can be introduced for the radial distortion Tangential Distortion: if the lens is misaligned (not perfectly parallel to the image sensor), a non-radial(tangential) distortion is introduced Summary This-lens equation From the thin lens to the pinhole camera Perspective Projection Equation Vanishing points and lines Intrinsic and extrinsic parameters (ğ‘²,ğ‘¹, ğ‘») Homogeneous coordinates Normalized image coordinates Radial distortion Understanding Check Explain what a blur circle is â€‹ ç‰©ä½“æ²¡æœ‰æ­£ç¡®æˆåƒåœ¨æˆåƒå¹³é¢ä¸Šå¯¼è‡´çš„æ¨¡ç³Šã€‚ Derive the thin lens equation and perform the pinhole approximation Explain how to build an Ames room Derive a relation between the field of view and the focal length ç„¦è·çŸ­ï¼ŒFOVå¤§ Proof the perspective projection equation, including lens distortion and world-to-camera projection? Explain normalized image coordinates and their geometric explanation normalized imageï¼šè™šæ‹Ÿçš„æˆåƒå¹³é¢ï¼Œç„¦è·ä¸º1ã€‚ Define vanishing points and lines å¹³è¡Œçº¿ç»è¿‡é€è§†æŠ•å½±åï¼Œç›¸äº¤äºç­ç‚¹ å¹³è¡Œå¹³é¢ç»è¿‡é€è§†æŠ•å½±åï¼Œç›¸äº¤äºç­é¢ Prove that parallel lines intersect at vanishing points ç¬¬ä¸‰è®² Camera calibrationCamera calibration Calibration is the process to determine the intrinsic ($K$ plus lens distortion) and extrinsic ($R$, $T$) parameters of a camera. For now, we will neglect the lens distortion and see later how it can be determined. $K,R,T$ can be determined by applying the perspective projection equation to known 3D-2D point correspondences: There are two popular methods: Tsaiâ€™s method: uses 3D objects Zhangâ€™s method: uses planar grids Tsaiâ€™s Method: Calibration from 3D ObjectsThis method was proposed in 1987 by Tsai and consists of measuring the 3D position of ğ’ â‰¥ ğŸ” control points on a 3D calibration target and the 2D coordinates of their projection in the image Direct Linear Transform (DLT) algorithm ç›´æ¥æ³•The idea of the DLT is to rewrite the perspective projection equation as a homogeneous linear equation (é½æ¬¡çº¿æ€§æ–¹ç¨‹) and solve it by standard methods. Letâ€™s write the perspective equation for a generic 3D-2D point correspondence: Conversion back from homogeneous coordinates to pixel coordinates leads to: By re-arranging the terms, we obtain For $n$ points, we can stack all these equations into a big matrix: å…³äºæ–¹ç¨‹çš„è§£ Once we have determined M, we can recover the intrinsic and extrinsic parameters by remembering that: $$\\mathrm{M}&#x3D;\\mathrm{K}(\\mathrm{R} | \\mathrm{T})$$ However, notice that we are not enforcing the constraint that $R$ is orthogonal, i.e., $R*R^T&#x3D;I$ To do this, we can use the so-called QR factorization of $M$, which decomposes $M$ into a $R$ (orthogonal), T,and an upper triangular matrix (i.e., $K$) Reprojection Error The reprojection error is the Euclidean distance (in pixels) between an observed image point and the corresponding 3D point reprojected onto the camera frame. The reprojection error gives us a quantitative measure of the accuracy of the calibration (ideally it should be zero). What reprojection error is acceptable? As lower as possible What are the sources of the reprojection error? distortion ç¦»æ•£åŒ–å¯¼è‡´çš„ï¼Œä¸€ä¸ªåƒç´ å¾€å¾€å¯¹åº”ç°å®ä¸­çš„å‡ æ¯«ç±³ã€‚ Non-Linear Calibration Refinement Zhangâ€™s method: from planar grids Tsaiâ€™s calibration requires that the worldâ€™s 3D points are non-coplanar, which is not very practical Todayâ€™s camera calibration toolboxes (Matlab, OpenCV) use multiple views of a planar grid (e.g., a checker board) They are based on a method developed in 2000 by Zhang (Microsoft Research) DLTAs in Tsaiâ€™s method, we start by writing the perspective projection equation (again, we neglect the radialdistortion). However, in Zhangâ€™s method the points are all coplanar, i.e., $Z_w &#x3D; 0$, and thus we can write: HçŸ©é˜µå°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„å•åº”çŸ©é˜µ Conversion back from homogeneous coordinates to pixel coordinates leads to: For n points (from a single view), we can stack all these equations into a big matrix: Homography Camera localization This is the problem of determining the 6DoF pose of a camera (position and orientation) with respect to the world frame from a set of 3D-2D point correspondences. It assumes that the camera is already calibrated The DLT can be used to solve this problem but is suboptimal. We want to study algebraic solutions to the problem. 1 Point: infinite solutions 2 Points: infinite solutions, but bounded 3 Points (non collinear): up to 4 solution It is known that $n$ independent polynomial equations, in $n$ unknowns, can have no more solutions than the product of their respective degrees. Thus, the system can have a maximum of 8 solutions. However, because every term in the system is either a constant or of second degree, for every real positive solution there is a negative solution. Thus, with 3 points, there are at most 4 valid (positive) solutions. 4 Points: Unique solution Robust Estimation in Presence of Outliers All PnP problems (solved by DLT, EPnP, or P3P algorithms) are prone to errors if there are outliers in the set of 3D-2D point correspondences. The RANSAC algorithm (Lecture 08) can be used, in conjunction with the PnP algorithm, to remove the outliers. PnP with RANSAC can be found in OpenCVâ€™s (solvePnPRansac) EPnP vs. DLT Non conventional camera models: fisheye and catadioptric cameras Central vs Non-Central Omnidirectional Cameras æ¨¡å‹è¿˜æ˜¯å¾—çœ‹è¿™å¼ å›¾ï¼Œç›¸æ¯”é’ˆå­”ç›¸æœºæ¨¡å‹å¯ä»¥å°†ä¸‰ç»´ç‚¹ç›´æ¥æŠ•å½±åˆ°å½’ä¸€åŒ–å¹³é¢ï¼Œé±¼çœ¼ç›¸æœºåˆ™å¤šäº†ä¸€ä¸ªä¸­é—´è¿‡ç¨‹ï¼šå…ˆå°†ä¸‰ç»´ç‚¹æŠ•å½±åˆ°å•ä½çƒé¢ï¼Œå†å°†å•ä½çƒé¢ä¸Šçš„ç‚¹æŠ•å½±åˆ°å½’ä¸€åŒ–å¹³é¢ä¸Šã€‚ Understanding Check Describe the differences between Tsaiâ€™s and Zhangâ€™s calibration methods Tsaiâ€™s calibration requires that the worldâ€™s 3D points are non-coplanar, which is not very practical in Zhangâ€™s method the points are all coplanar Explain and derive the DLT in both Tsaiâ€™s and Zhangâ€™s methods? What is the minimum number of point correspondences they require? Tsaiï¼š6ä¸ªç‚¹ Zhangï¼š4ä¸ªéå…±çº¿çš„ Describe the general PnP problem and derive the behavior of its solutions? PnPæ˜¯ä¸ºäº†è®²è§£ä»¥åŠ2Dç‚¹ï¼Œä¼°è®¡ç›¸æœºçš„3Dä½å§¿çš„ä»»åŠ¡ã€‚ä¸€èˆ¬æœ‰DLTï¼ŒP3Pï¼ŒEPnPçš„è§£æ³• Explain the working principle of the P3P algorithm? P3Pä¸»è¦ç”¨çš„æ˜¯ä½™å¼¦å®šç†çš„çº¦æŸæ¥ç»§ç»­æ±‚è§£ï¼Œä¼šæœ‰4ä¸ªè§£ï¼Œéœ€è¦ç”¨å¦ä¸€ä¸ªç‚¹æ¥æ‰¾åˆ°çœŸæ­£çš„è§£ã€‚ What is the reprojection error and how is it used for refining the calibration? ç°å®ä¸­çš„ç‚¹é€šè¿‡è®¡ç®—çš„å†…å¤–å‚æŠ•å½±åˆ°åƒç´ åæ ‡ç³»ä¸­çš„è¯¯å·®ï¼Œå¯ä»¥ç”¨ä½œéçº¿æ€§ä¼˜åŒ–çš„æŒ‡æ ‡ã€‚ Define central and non central omnidirectional cameras? What kind of mirrors ensure central projection? ç¬¬å››è®² Image FilteringDefinationï¼š The word filter comes from frequency-domain processing, where â€œfilteringâ€ refers to the process of accepting or rejecting certain frequency components We distinguish between low-pass and high-pass filtering A low-pass filter smooths an image (retains low-frequency components) A high-pass filter retains the contours (also called edges) of an image (high frequency) Low-pass filteringLinear filters Salt and pepper noise: random occurrences of black and white pixels Impulse noise: random occurrences of white pixels Gaussian noise: variations in intensity drawn from a Gaussian distribution Moving average Replaces each pixel with an average of all the values in its neighborhood Assumptions: Expect pixels to be like their neighbors Expect noise process to be independent from pixel to pixel Convolutionå°†è¾“å…¥ä¿¡å·aåè¿‡æ¥ï¼Œåœ¨ä¿¡å·bä¸Šé¢æ»‘åŠ¨å¾—åˆ°ç»“æœã€‚ Box Filter(average) Gaussian Filter é€šè¿‡å¯¹æ¯”ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°å‡å€¼æ»¤æ³¢ç›¸æ¯”é«˜æ–¯æ»¤æ³¢å…·æœ‰ç½‘æ ¼åŒ–æ•ˆåº”ã€‚åŸå› æ˜¯æ‰€æœ‰çš„å…ƒç´ ä¸è®ºç¦»ä¸­å¿ƒæœ‰å¤šè¿œï¼Œæƒé‡éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤è¿œç¦»çš„åƒç´ ä¿¡æ¯å¤„ç†åä¼šèå…¥åˆ°ä¸­å¿ƒåƒç´ ä¸­ã€‚æ‰€ä»¥æˆ‘ä»¬å¼•å…¥é«˜æ–¯æ»¤æ³¢ä¼šæ˜¾å¾—æ›´åŠ å…‰æ»‘ã€‚ å¯ä»¥çœ‹åˆ°é«˜æ–¯æ»¤æ³¢çš„æ»¤æ³¢æ ¸é¢‘è°±å¾ˆé›†ä¸­ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„ä½é€šæ»¤æ³¢å™¨ã€‚æ‰€ä»¥å…¶ç»“æœå›¾åƒçš„é¢‘è°±ä¹Ÿä¸»è¦é›†ä¸­åœ¨é¢‘è°±å›¾çš„ä¸­å¿ƒéƒ¨åˆ†ã€‚ å†æ¥çœ‹çœ‹boxæ»¤æ³¢ï¼Œå¾ˆæ˜æ˜¾ï¼Œå®ƒçš„æ»¤æ³¢æ ¸çš„é¢‘è°±ç›¸æ¯”é«˜æ–¯æ»¤æ³¢æ ¸çš„é¢‘è°±æœ‰æ›´å¤šçš„é«˜é¢‘ä¿¡æ¯ï¼Œæ‰€ä»¥å…¶æ»¤æ³¢åçš„ç»“æœä¹ŸåŒ…å«æ›´å¤šçš„é«˜é¢‘ä¿¡æ¯ã€‚ è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå…¶æ»¤æ³¢ç»“æœä¸å¤Ÿå…‰æ»‘ï¼Œæœ‰æ›´å¤šæ¡çº¹çŠ¶çš„æ•ˆåº”ã€‚ Separable Filters Boundary issues Non-linear filters Median Filter Bilateral Filter åŒè¾¹æ»¤æ³¢å¯ä»¥ä¿ç•™è¾¹ç¼˜ Edge DetectionGoal: to find the boundaries (edges) of objects within images Derivative of Gaussian filter Laplacian of Gaussian filter (LOG) Difference of gaussian filter (DOG)DOG å¯ä»¥å¾ˆå¥½çš„è¿‘ä¼¼LOGï¼Œä¸”è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚ Summary on (linear) smoothing filters Smoothing filter has positive values (also called coefficients) sums to 1 â†’ preserve brightness of constant regions removes â€œhigh-frequencyâ€ components; â€œlow-passâ€ filter Derivative filter: has opposite signs used to get high response in regions of high contrast sums to 0 â†’ no response in constant regions highlights â€œhigh-frequencyâ€ components: â€œhigh-passâ€ filter Canny edge detector Understanding Check Explain the differences between convolution and cross-correlation? è¿ç®—æ–¹å¼ä¸åŒã€‚å·ç§¯éœ€è¦ç¿»è½¬è¿‡æ¥ã€‚ Explain the differences between a box filter and a Gaussian filter? kernelä¸ä¸€æ ·ã€‚box filterçš„kernelæ¯ä¸ªå…ƒç´ éƒ½ä¸€æ ·ï¼ŒGaussiançš„kernelåˆ™æ˜¯é€šè¿‡é«˜æ–¯é‡‡æ ·è·å¾—çš„ã€‚box filterçš„ç»“æœæœ‰ç½‘æ ¼åŒ–æ•ˆåº”ï¼Œå› ä¸ºå…¶ä¿ç•™äº†æ›´å¤šé«˜é¢‘çš„ä¿¡æ¯ï¼Œå…‰æ»‘æ•ˆæœä¸è‡ªç„¶ã€‚ Explain why one should increase the size of the kernel of a Gaussian filter if 2ğœ is close to the size of the kernel? ä¸ºäº†èƒ½å¤Ÿæ›´å¥½çš„å¯¹é«˜æ–¯æ ¸å‡½æ•°è¿›è¡Œé‡‡æ ·ï¼Œæ–¹å·®ä¸kernelçš„å¤§å°è¿‡äºæ¥è¿‘çš„è¯ï¼Œé‡‡æ ·çš„ç»“æœä¸èƒ½å¾ˆå¥½çš„è¿‘ä¼¼é«˜æ–¯åˆ†å¸ƒã€‚ Explain when we would need a median &amp; bilateral filter? éçº¿æ€§æ»¤æ³¢ï¼Œåœ¨å»é™¤å™ªå£°çš„åŒæ—¶è¿˜èƒ½å¾ˆå¥½çš„ä¿ç•™è¾¹ç¼˜ä¿¡æ¯ã€‚ Explain how to handle boundary issues? zero padding wrap around copy edge reflect across edge Explain the working principle of edge detection with a 1D signal? åœ¨ä¸€é˜¶å¯¼æ•°çªå˜çš„åœ°æ–¹å¾€å¾€æ˜¯è¾¹ç¼˜ã€‚ Explain how noise does affect this procedure? å™ªéŸ³ä¼šå¯¼è‡´ä¸€é˜¶å¯¼æ•°å¤„å¤„çªå˜ï¼Œéš¾ä»¥åˆ†è¾¨ä¸€é˜¶å¯¼æ•°çªå˜çš„åœ°æ–¹ã€‚ Explain the differential property of convolution? Show how to compute the first derivative of an image intensity function along ğ‘¥ and ğ‘¦? Use sobel filter Explain why the Laplacian of Gaussian operator is useful? æ‹‰æ™®æ‹‰æ–¯ç®—å­æ˜¯äºŒé˜¶å¯¼æ•°ç®—å­ï¼Œç”¨äºå¯¹å›¾åƒäºŒé˜¶å¯¼æ•°è¿›è¡Œè¿‘ä¼¼ä¼°è®¡ã€‚ç”±äºæ‹‰æ™®æ‹‰æ–¯ç®—å­å¯¹å™ªå£°æ•æ„Ÿï¼Œå› æ­¤åœ¨è¿›è¡Œæ‹‰æ™®æ‹‰æ–¯æ“ä½œä¹‹å‰å…ˆå¯¹å›¾åƒè¿›è¡Œé«˜æ–¯å¹³æ»‘æ»¤æ³¢å¤„ç†ã€‚ äº‹å®ä¸Šç”±äºå·ç§¯æ“ä½œå…·æœ‰ç»“åˆå¾‹ï¼Œå› æ­¤æˆ‘ä»¬å…ˆå°†é«˜æ–¯å¹³æ»‘æ»¤æ³¢å™¨ä¸æ‹‰æ™®æ‹‰æ–¯æ»¤æ³¢å™¨è¿›è¡Œå·ç§¯ï¼Œç„¶ååˆ©ç”¨å¾—åˆ°çš„æ··åˆæ»¤æ³¢å™¨å»å¯¹å›¾ç‰‡è¿›è¡Œå·ç§¯ä»¥å¾—åˆ°æ‰€éœ€çš„ç»“æœã€‚ List the properties of smoothing and derivative filters? Smoothing filter has positive values (also called coefficients) sums to 1 â†’ preserve brightness of constant regions removes â€œhigh-frequencyâ€ components; â€œlow-passâ€ filter derivative filter has opposite signs used to get high response in regions of high contrast sums to 0 â†’ no response in constant regions highlights â€œhigh-frequencyâ€ components: â€œhigh-passâ€ filter Illustrate the Canny edge detection algorithm? Take a grayscale image Convolve the image ğ¼ with ğ‘¥ and ğ‘¦ derivatives of Gaussian filter Calculating the direction and strength of edge Thining (Non-maximum suppression): look for local-maxima in the edge strength in the direction of the gradient Linking and Thresholding Explain what non-maxima suppression is and how it is implemented? non-maxima suppressionå°±æ˜¯æœç´¢å±€éƒ¨æœ€å¤§å€¼ï¼Œå¯»æ‰¾è¾¹ç¼˜æ¢¯åº¦æ–¹å‘ä¸Šæ¢¯åº¦å¼ºé˜Ÿæœ€å¤§çš„åƒç´ ã€‚","categories":[{"name":"Course","slug":"Course","permalink":"https://liuxiao916.github.io/categories/Course/"}],"tags":[{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"},{"name":"Robotics","slug":"Robotics","permalink":"https://liuxiao916.github.io/tags/Robotics/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://liuxiao916.github.io/tags/Computer-Vision/"}],"author":"LiuXiao"},{"title":"Brave New World!","slug":"Brave-New-World","date":"2022-02-12T03:34:07.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/12/Brave-New-World/","link":"","permalink":"https://liuxiao916.github.io/2022/02/12/Brave-New-World/","excerpt":"è¿™é‡Œæ˜¯ç¬‘çš„åšå®¢ï¼Œä¹‹å‰çš„ä¸ªäººä¸»é¡µå·²ç»å‡çº§æˆäº†åšå®¢ï¼Œå˜æˆäº†å†™å­—çš„åœ°æ–¹ï¼Œæ¬¢è¿å¸¸æ¥çœ‹çœ‹ã€‚","text":"è¿™é‡Œæ˜¯ç¬‘çš„åšå®¢ï¼Œä¹‹å‰çš„ä¸ªäººä¸»é¡µå·²ç»å‡çº§æˆäº†åšå®¢ï¼Œå˜æˆäº†å†™å­—çš„åœ°æ–¹ï¼Œæ¬¢è¿å¸¸æ¥çœ‹çœ‹ã€‚ æœ¬ç«™å†å² 2021-01-12 å®Œæˆä¸ªäººä¸»é¡µçš„æ­å»ºï¼ŒæŠ•å…¥ä½¿ç”¨ 2022-02-07 é€‰ç”¨Hexoæ¡†æ¶ï¼Œé…åˆvolantisä¸»é¢˜ï¼Œå¼€å§‹æ­å»ºä¸ªäººåšå®¢ 2022-02-12 åšå®¢æ­å»ºå®Œæˆï¼Œå¼€å§‹è¿›ä¸€æ­¥å®Œå–„å†…å®¹ã€‚","categories":[],"tags":[],"author":"LiuXiao"},{"title":"Hexo+volantisæ­å»ºåšå®¢","slug":"Hexo-volantisæ­å»ºåšå®¢","date":"2022-02-12T03:16:37.000Z","updated":"2022-05-06T11:56:25.899Z","comments":true,"path":"2022/02/12/Hexo-volantisæ­å»ºåšå®¢/","link":"","permalink":"https://liuxiao916.github.io/2022/02/12/Hexo-volantis%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","excerpt":"è®°å½•å¦‚ä½•ä½¿ç”¨Hexo+volantisæ­å»ºè‡ªå·±çš„åšå®¢","text":"è®°å½•å¦‚ä½•ä½¿ç”¨Hexo+volantisæ­å»ºè‡ªå·±çš„åšå®¢ Hexoä»€ä¹ˆæ˜¯HexoHexo æ˜¯ä¸€ä¸ªå¿«é€Ÿã€ç®€å•ã€å¼ºå¤§çš„åšå®¢æ¡†æ¶ã€‚ ç”¨ Markdownå†™å¥½å¸–å­åï¼ŒHexo ä¼šåœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆå¸¦æœ‰æ¼‚äº®ä¸»é¢˜çš„é™æ€æ–‡ä»¶ã€‚ ç¯å¢ƒé…ç½® å®‰è£…Node.js å®‰è£…Hexo 1npm install -g hexo-cli å»ºç«™1234mkdir &lt;folder&gt;hexo init &lt;folder&gt;cd &lt;folder&gt;npm install Hexoç›¸å…³æŒ‡ä»¤è¯·å‚è€ƒHexoæŒ‡ä»¤ 1234hexo clean # æ¸…é™¤ç¼“å­˜æ–‡ä»¶ (db.json) å’Œå·²ç”Ÿæˆçš„é™æ€æ–‡ä»¶ (public)hexo g # ç”Ÿæˆæ™¯æ³°æ–‡ä»¶hexo s # éƒ¨ç½²åˆ°æœ¬åœ°hexo d # éƒ¨ç½²åˆ°è¿œç¨‹ æ­¤æ—¶ä½¿ç”¨hexo g &amp;&amp; hexo sï¼Œè®¿é—®http://localhost:4000/ volantisä¸»é¢˜ç»¼åˆè€ƒè™‘ï¼Œå†³å®šä½¿ç”¨ç¨³å®šç‰ˆæœ¬çš„volantisï¼Œ ä¿®æ”¹ç«™ç‚¹é…ç½®æ–‡ä»¶åœ¨ blog&#x2F;_config.yml æ–‡ä»¶ä¸­æ‰¾åˆ°å¹¶ä¿®æ”¹theme: volantis ä¸‹è½½ä¸»é¢˜npm i hexo-theme-volantis æ­¤æ—¶ç½‘ç«™å˜æˆè¿™ä¸ªæ ·å­ æ–°å»ºåšå®¢123hexo new hellohexo ghexo s æ­¤æ—¶åœ¨source\\_postsä¸­ä¼šæ–°å»ºä¸€ä¸ªhello.mdï¼Œæˆ‘ä»¬è®¿é—®ç½‘é¡µå¯ä»¥çœ‹åˆ°ç¬¬ä¸€ç¯‡åšæ–‡å·²ç»æ·»åŠ ã€‚ è¿œç¨‹éƒ¨ç½²å®‰è£…éƒ¨ç½²æ’ä»¶ï¼š 1npm install hexo-deployer-git --save å®Œæˆéƒ¨ç½² 1234deploy: type: git repo: git@github.com:liuxiao916/liuxiao916.github.io.git branch: master è®¿é—®liuxiao916.github.ioï¼Œå¯ä»¥æ­£å¸¸è®¿é—®ã€‚ é…ç½®Hexoé…ç½®å‚è€ƒHexoé…ç½®ï¼Œé‰´äºæˆ‘æ˜¯æ–°äººï¼Œä»…å¯¹Siteéƒ¨åˆ†è¿›è¡Œä¿®æ”¹ã€‚ 123456789# Sitetitle: XiaoBlogsubtitle: &#x27;&#x27;description: &#x27;The homepage for Xiao&#x27;keywords: Blog, Xiao, LiuXiao, Roboticsauthor: Xiao Liulanguage: zh-CNtimezone: &#x27;Asia/Shanghai&#x27;favicon: https://xiao-pic.oss-cn-shenzhen.aliyuncs.com/pic/img/favicon.png ä¸»é¢˜é…ç½®å‚è€ƒvolantisä¸»é¢˜è®¾ç½® å¤åˆ¶é…ç½®æ–‡ä»¶ ä½¿ç”¨npm i hexo-&gt;theme-volantisæ–¹å¼å®‰è£…çš„ä¸»é¢˜ï¼Œä¸»é¢˜é…ç½®æ–‡ä»¶åœ¨blog/node_modules/hexo-theme-volantis/_config.ymlã€‚ å¤åˆ¶~Blog/node_modules/hexo-theme-volantis/_config.ymlä¸º ~/Blog/_config.volantis.ymlï¼Œè¿™ä¸ªæ–‡ä»¶ä¸­çš„é…ç½®ä¿¡æ¯ä¼˜å…ˆçº§é«˜äºä¸»é¢˜æ–‡ä»¶å¤¹ä¸­çš„é…ç½®æ–‡ä»¶ã€‚ ä¿®æ”¹_config.volantis.yml å…³é—­è‡ªå®šä¹‰é¼ æ ‡ 123custom_css: cursor: enable: false å›¾æ ‡åˆ›å»ºç½‘ç«™favicon.icoï¼Œè‰²å·#0055AAï¼Œæœ‰è¶£çš„è‰²å·ç½‘ç«™color å…³é—­è‡ªå®šä¹‰å³é”®èœå• 123# è‡ªå®šä¹‰å³é”®èœå•rightmenu: enable: false å¯¼èˆªæ è®¾ç½®å›¾æ ‡åº“é‡‡ç”¨font awesomeã€‚ä¸ºäº†è·å¾—æ›´å…¨çš„å›¾æ ‡åº“ï¼Œæˆ‘ä»¬å®‰è£…æœ€æ–°çš„6.0.0ç‰ˆæœ¬ 1npm i @fortawesome/fontawesome-free ç”¨/home/liuxiao/Blog/node_modules/@fortawesomeæ›¿æ¢/home/liuxiao/Blog/node_modules/hexo-theme-volantis/source/libs/@fortawesomeã€‚ è‡ªå®šä¹‰äº†ä¸€äº›åŠŸèƒ½ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354navbar: visiable: auto # always, auto logo: # choose [img] or [icon + title] img: https://xiao-pic.oss-cn-shenzhen.aliyuncs.com/pic/img/logo1.png # https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png icon: # title: #ç¬‘ menu: - name: ä¸»é¡µ icon: fas fa-home url: / - name: æ–‡ç«  icon: fas fa-newspaper rows: - name: åˆ†ç±» icon: fas fa-folder-open url: categories/ - name: å½’æ¡£ icon: fas fa-archive url: archives/ - name: æ—¥å¸¸ icon: fas fa-icons rows: - name: ç›¸å†Œ icon: fas fa-camera url: photos/ - name: ä¹¦å• icon: fas fa-book url: books/ - name: ç•™è¨€æ¿ icon: fas fa-comments url: comments/ - name: å‹é“¾ icon: fas fa-mars url: friends/ - name: å…³äºæˆ‘ icon: fas fa-user-circle url: about/ - name: é“¾æ¥ icon: fas fa-link rows: - name: Github icon: fab fa-github url: https://github.com/liuxiao916 - name: Bilibili icon: fab fa-bilibili url: https://space.bilibili.com/131329867 - name: Zhihu icon: fab fa-zhihu url: https://www.zhihu.com/people/wen-dao-zhu-yao-33 - name: æš—é»‘æ¨¡å¼ # å¯è‡ªå®šä¹‰ icon: fas fa-moon # å¯è‡ªå®šä¹‰ toggle: darkmode search: Search... # Search bar placeholder å°é¢è®¾ç½®è®¾ç½®å°é¢å¤§å°ä¸ºä¸€åŠï¼Œåˆ å»åŠŸèƒ½æ ï¼Œçœ‹èµ·æ¥æ¸…çˆ½äº†ä¸å°‘ã€‚ 12345678910111213cover: height_scheme: half # full, half layout_scheme: featured # blank (ç•™ç™½), search (æœç´¢), dock (å), featured (ç²¾é€‰), focus (ç„¦ç‚¹) display: home: true archive: true others: false # can be written in front-matter &#x27;cover: true&#x27; background: https://bing.ioliu.cn/v1/rand?w=1920&amp;h=1200 logo: https://xiao-pic.oss-cn-shenzhen.aliyuncs.com/pic/img/apple-touch-icon.png title: &#x27;Xiao Blog&#x27; subtitle: &#x27;The stars, my destination&#x27; search: A Wonderful Theme for Hexo # search bar placeholder features: é¡µè„šè®¾ç½® æ¢æˆæ›´å¥½çœ‹çš„æ ·å¼ã€‚ 123456789101112131415161718site_footer: # layout of footer: [aplayer, social, license, info, copyright] layout: [analytics, custom] custom: &#x27;&lt;a style=&quot;padding-right: 1%;&quot; href=&quot;https://hexo.io/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Powered-Hexo-blue&quot;&gt;&lt;/a&gt;&lt;a style=&quot;padding-right: 1%;&quot; href=&quot;https://volantis.js.org/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Theme-Volantis-cyan&quot;&gt;&lt;/a&gt;&lt;a style=&quot;padding-right: 1%;&quot; href=&quot;https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-success&quot;&gt;&lt;/a&gt;&lt;a style=&quot;padding-right: 1%;&quot; href=&quot;https://liuxiao916.github.io&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Copyright-2019--2022%20LiuXiao-orange&quot;&gt;&lt;/a&gt;&#x27; social: - icon: fas fa-rss url: https://github.com/volantis-x/volantis-docs/ # site source source: https://github.com/volantis-x/volantis-docs/ # analytics using leancloud analytics: &gt; &lt;span id=&quot;lc-sv&quot;&gt;æœ¬ç«™æ€»è®¿é—®é‡ä¸º &lt;span id=&#x27;number&#x27;&gt;&lt;i class=&quot;fas fa-circle-notch fa-spin fa-fw&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt; æ¬¡&lt;/span&gt; &lt;span id=&quot;lc-uv&quot;&gt;è®¿å®¢æ•°ä¸º &lt;span id=&#x27;number&#x27;&gt;&lt;i class=&quot;fas fa-circle-notch fa-spin fa-fw&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt; äºº&lt;/span&gt; # site copyright copyright: &#x27;[Copyright Â© 2017-2020 XXX](/)&#x27; # You can add your own property here. (Support markdown, for example: br: &#x27;&lt;br&gt;&#x27;) br: &#x27;&lt;br&gt;&#x27; hello: &#x27;[Hello World](/)&#x27; æ–°å»ºæ ‡ç­¾ä¸åˆ†ç±»ç•Œé¢è¿™é‡Œæ¯”è¾ƒéº»çƒ¦ï¼Œä»¥æ ‡ç­¾èŠ‚ç›®ä¸ºä¾‹ã€‚ åœ¨hexoæ ¹ç›®å½•çš„sourceæ–‡ä»¶å¤¹ä¸‹æ–°å»ºä¸€ä¸ªtagsæ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨tagsæ–‡ä»¶å¤¹é‡Œé¢æ–°å»ºä¸€ä¸ªindex.mdæ–‡ä»¶ã€‚ 1hexo new page &quot;tags&quot; ç¼–è¾‘index.mdæ–‡ä»¶ï¼Œå…¶ä¸­layoutåé¢çš„å‚æ•°å¯¹åº”çš„æ˜¯ä¸»é¢˜æ–‡ä»¶å¤¹ä¸‹ layoutæ–‡ä»¶å¤¹ä¸‹ç¬¬ä¸€çº§çš„å¸ƒå±€æ–‡ä»¶/home/liuxiao/Blog/node_modules/hexo-theme-volantis/layout/tag.ejsã€‚ 123title: &quot;tags&quot;type: tags layout: &quot;tag&quot; ä¾§è¾¹æ è®¾ç½®æ‰“å¼€äº†ç«™ç‚¹ä¿¡æ¯ï¼Œå…³é—­äº†èµèµã€‚ è®¾ç½®æ–‡ç« è¯„è®º 1234567891011121314# giscus# https://giscus.app# https://github.com/laymonage/giscusgiscus: theme: light: https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/css/giscus/light.css dark: https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/css/giscus/dark.css repo: liuxiao916/liuxiao916.github.io repo-id: MDEwOlJlcG9zaXRvcnkyOTI3OTg1NDg= category: Announcements category-id: DIC_kwDOEXPAVM4CBGFP mapping: &quot;pathname&quot; reactions-enabled: &quot;1&quot; emit-metadata: &quot;0&quot; çƒŸèŠ±æ•ˆæœåœ¨node_modules/hexo-theme-volantis/layout/layout.ejsæœ«å°¾æ·»åŠ  1&lt;script src=&quot;https://cdn.jsdelivr.net/gh/zyoushuo/Blog/hexo/js/mouse_click.js&quot;&gt;&lt;/script&gt; æŸäº›ç•Œé¢çš„ä¾§è¾¹æ è®¾ç½® è¿™ç§è®¾ç½®æ˜¯å¯ä»¥è°ƒå‡ºæ¥ä¾§è¾¹æ è®¾ç½®çš„ï¼Œæ•ˆæœå¦‚å›¾ã€‚ 1234567---layout: pageseo_title: å…³äºbottom_meta: falsecomments: falsesidebar: [blogger]--- ä»¥ä¸‹è®¾ç½®æ˜¯ä¸æ˜¾ç¤ºä¾§è¾¹æ çš„è®¾ç½® 1234567---layout: docsseo_title: å…³äºbottom_meta: falsecomments: falsesidebar: []--- å¯ç”¨å­—æ•°ç»Ÿè®¡å’Œé˜…è¯»æ—¶é•¿ é…ç½®Leancloudï¼Œç”¨äºç»Ÿè®¡è®¿é—®äººæ•°ã€‚ ç›¸å†Œæ­å»º ä½¿ç”¨volantisçš„æ ‡ç­¾åŠŸèƒ½ button å¯Œæ–‡æœ¬æŒ‰é’® span note gallery è®¡åˆ’ä½¿ç”¨githubå›¾åºŠé…åˆCDNjsdelivrä½¿ç”¨ åŸŸåè®¾ç½®ç°åœ¨é˜¿é‡Œäº‘ä¸‡ç½‘å®ŒæˆåŸŸåçš„è´­ä¹°ï¼Œæˆ‘è´­ä¹°çš„æ˜¯liuxiao916.xyzã€‚ ç‚¹å‡»è§£æï¼Œ pingæˆ‘ä»¬çš„githubä¸»é¡µï¼ŒæŸ¥çœ‹ipã€‚ è®¾ç½®å¦‚ä¸‹çš„è§£æã€‚ ç¬¬äºŒæ­¥åœ¨æˆ‘ä»¬çš„githubä»“åº“ä¸­è¿›è¡Œè®¾ç½®ï¼Œåœ¨Settings-&gt;Pagesä¸­æ‰¾åˆ°Custom domainï¼Œè®¾ç½®æˆè‡ªå·±çš„åŸŸåã€‚ ç¬¬ä¸‰æ­¥ï¼Œåœ¨åšå®¢çš„blog/sourceæ–‡ä»¶å¤¹ä¸‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶CNAMEï¼Œè¾“å…¥è‡ªå·±çš„åŸŸåã€‚ å†æ¬¡éƒ¨ç½²å³å¯ã€‚","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://liuxiao916.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://liuxiao916.github.io/tags/Hexo/"},{"name":"volantis","slug":"volantis","permalink":"https://liuxiao916.github.io/tags/volantis/"}],"author":"LiuXiao"},{"title":"Hello World","slug":"hello-world","date":"2022-02-07T16:00:00.000Z","updated":"2022-02-08T16:00:00.000Z","comments":true,"path":"2022/02/08/hello-world/","link":"","permalink":"https://liuxiao916.github.io/2022/02/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[],"author":"LiuXiao"}],"categories":[{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/categories/SLAM/"},{"name":"Programming","slug":"Programming","permalink":"https://liuxiao916.github.io/categories/Programming/"},{"name":"Courese","slug":"Courese","permalink":"https://liuxiao916.github.io/categories/Courese/"},{"name":"Course","slug":"Course","permalink":"https://liuxiao916.github.io/categories/Course/"},{"name":"Tool","slug":"Tool","permalink":"https://liuxiao916.github.io/categories/Tool/"},{"name":"Hexo","slug":"Hexo","permalink":"https://liuxiao916.github.io/categories/Hexo/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://liuxiao916.github.io/tags/C/"},{"name":"SLAM","slug":"SLAM","permalink":"https://liuxiao916.github.io/tags/SLAM/"},{"name":"Computer Visoon","slug":"Computer-Visoon","permalink":"https://liuxiao916.github.io/tags/Computer-Visoon/"},{"name":"Robotics","slug":"Robotics","permalink":"https://liuxiao916.github.io/tags/Robotics/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://liuxiao916.github.io/tags/Computer-Vision/"},{"name":"Qt","slug":"Qt","permalink":"https://liuxiao916.github.io/tags/Qt/"},{"name":"Hexo","slug":"Hexo","permalink":"https://liuxiao916.github.io/tags/Hexo/"},{"name":"volantis","slug":"volantis","permalink":"https://liuxiao916.github.io/tags/volantis/"}]}